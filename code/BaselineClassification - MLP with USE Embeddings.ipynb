{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "137b3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/abs/1909.02027\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bb2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/clinic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5b6efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/clinic/data_imbalanced/val.csv',\n",
       " '../data/clinic/data_imbalanced/oos_test.csv',\n",
       " '../data/clinic/data_imbalanced/test.csv',\n",
       " '../data/clinic/data_imbalanced/oos_train.csv',\n",
       " '../data/clinic/data_imbalanced/oos_val.csv',\n",
       " '../data/clinic/data_imbalanced/train.csv',\n",
       " '../data/clinic/data_small/val.csv',\n",
       " '../data/clinic/data_small/oos_test.csv',\n",
       " '../data/clinic/data_small/test.csv',\n",
       " '../data/clinic/data_small/oos_train.csv',\n",
       " '../data/clinic/data_small/oos_val.csv',\n",
       " '../data/clinic/data_small/train.csv',\n",
       " '../data/clinic/data_full/val.csv',\n",
       " '../data/clinic/data_full/oos_test.csv',\n",
       " '../data/clinic/data_full/test.csv',\n",
       " '../data/clinic/data_full/oos_train.csv',\n",
       " '../data/clinic/data_full/oos_val.csv',\n",
       " '../data/clinic/data_full/train.csv',\n",
       " '../data/clinic/data_oos_plus/val.csv',\n",
       " '../data/clinic/data_oos_plus/oos_test.csv',\n",
       " '../data/clinic/data_oos_plus/test.csv',\n",
       " '../data/clinic/data_oos_plus/oos_train.csv',\n",
       " '../data/clinic/data_oos_plus/oos_val.csv',\n",
       " '../data/clinic/data_oos_plus/train.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(DATA_FOLDER+ '*/*.csv*')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "527e4c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['change_accent', 'who_do_you_work_for', 'bill_balance',\n",
       "       'next_song', 'calories', 'change_user_name', 'confirm_reservation',\n",
       "       'jump_start', 'card_declined', 'cook_time', 'nutrition_info',\n",
       "       'greeting', 'calendar', 'schedule_maintenance', 'balance',\n",
       "       'tire_pressure', 'shopping_list', 'ingredients_list',\n",
       "       'whisper_mode', 'meal_suggestion', 'travel_alert', 'lost_luggage',\n",
       "       'weather', 'pin_change', 'pto_request', 'change_speed', 'no',\n",
       "       'user_name', 'taxes', 'book_flight', 'yes', 'timezone', 'fun_fact',\n",
       "       'order', 'traffic', 'pay_bill', 'report_fraud', 'vaccines',\n",
       "       'recipe', 'report_lost_card', 'transfer', 'redeem_rewards',\n",
       "       'exchange_rate', 'expiration_date', 'order_status',\n",
       "       'reset_settings', 'cancel_reservation', 'goodbye',\n",
       "       'restaurant_reviews', 'tell_joke', 'current_location', 'pto_used',\n",
       "       'international_visa', 'restaurant_suggestion', 'pto_balance',\n",
       "       'payday', 'flight_status', 'distance', 'routing', 'translate',\n",
       "       'text', 'carry_on', 'interest_rate', 'min_payment', 'roll_dice',\n",
       "       'measurement_conversion', 'book_hotel', 'travel_suggestion',\n",
       "       'cancel', 'credit_limit_change', 'apr', 'time', 'direct_deposit',\n",
       "       'repeat', 'how_busy', 'rollover_401k', 'travel_notification',\n",
       "       'calendar_update', 'international_fees', 'account_blocked',\n",
       "       'improve_credit_score', 'uber', 'tire_change', 'gas_type',\n",
       "       'do_you_have_pets', 'application_status',\n",
       "       'replacement_card_duration', 'play_music', 'where_are_you_from',\n",
       "       'credit_limit', 'date', 'share_location', 'who_made_you',\n",
       "       'spelling', 'maybe', 'accept_reservations', 'spending_history',\n",
       "       'meaning_of_life', 'gas', 'todo_list_update', 'plug_type',\n",
       "       'update_playlist', 'ingredient_substitution', 'reminder_update',\n",
       "       'what_is_your_name', 'todo_list', 'income', 'transactions',\n",
       "       'shopping_list_update', 'what_are_your_hobbies', 'make_call',\n",
       "       'definition', 'change_ai_name', 'change_language',\n",
       "       'oil_change_how', 'what_song', 'freeze_account', 'thank_you',\n",
       "       'mpg', 'rewards_balance', 'find_phone', 'flip_coin', 'car_rental',\n",
       "       'food_last', 'insurance_change', 'credit_score',\n",
       "       'pto_request_status', 'reminder', 'what_can_i_ask_you',\n",
       "       'next_holiday', 'order_checks', 'how_old_are_you', 'calculator',\n",
       "       'directions', 'damaged_card', 'new_card', 'are_you_a_bot',\n",
       "       'insurance', 'bill_due', 'smart_home', 'timer', 'sync_device',\n",
       "       'w2', 'schedule_meeting', 'oil_change_when', 'alarm',\n",
       "       'change_volume', 'restaurant_reservation', 'meeting_schedule',\n",
       "       'last_maintenance'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/clinic/data_full/train.csv')\n",
    "df_train['intent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7978a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {k:i for i,k in enumerate(set(df_train['intent'].tolist()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c3bf520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meaning_of_life': 0,\n",
       " 'who_do_you_work_for': 1,\n",
       " 'pto_request': 2,\n",
       " 'restaurant_reservation': 3,\n",
       " 'gas_type': 4,\n",
       " 'update_playlist': 5,\n",
       " 'restaurant_suggestion': 6,\n",
       " 'book_flight': 7,\n",
       " 'date': 8,\n",
       " 'mpg': 9,\n",
       " 'play_music': 10,\n",
       " 'new_card': 11,\n",
       " 'timezone': 12,\n",
       " 'jump_start': 13,\n",
       " 'schedule_meeting': 14,\n",
       " 'flight_status': 15,\n",
       " 'weather': 16,\n",
       " 'transfer': 17,\n",
       " 'recipe': 18,\n",
       " 'reset_settings': 19,\n",
       " 'schedule_maintenance': 20,\n",
       " 'international_fees': 21,\n",
       " 'income': 22,\n",
       " 'cook_time': 23,\n",
       " 'redeem_rewards': 24,\n",
       " 'calories': 25,\n",
       " 'shopping_list': 26,\n",
       " 'change_language': 27,\n",
       " 'alarm': 28,\n",
       " 'flip_coin': 29,\n",
       " 'no': 30,\n",
       " 'whisper_mode': 31,\n",
       " 'insurance_change': 32,\n",
       " 'payday': 33,\n",
       " 'what_are_your_hobbies': 34,\n",
       " 'damaged_card': 35,\n",
       " 'definition': 36,\n",
       " 'insurance': 37,\n",
       " 'share_location': 38,\n",
       " 'next_song': 39,\n",
       " 'report_fraud': 40,\n",
       " 'vaccines': 41,\n",
       " 'next_holiday': 42,\n",
       " 'carry_on': 43,\n",
       " 'cancel_reservation': 44,\n",
       " 'what_can_i_ask_you': 45,\n",
       " 'how_old_are_you': 46,\n",
       " 'what_song': 47,\n",
       " 'where_are_you_from': 48,\n",
       " 'directions': 49,\n",
       " 'user_name': 50,\n",
       " 'do_you_have_pets': 51,\n",
       " 'find_phone': 52,\n",
       " 'car_rental': 53,\n",
       " 'roll_dice': 54,\n",
       " 'order_status': 55,\n",
       " 'who_made_you': 56,\n",
       " 'greeting': 57,\n",
       " 'calculator': 58,\n",
       " 'distance': 59,\n",
       " 'pay_bill': 60,\n",
       " 'make_call': 61,\n",
       " 'report_lost_card': 62,\n",
       " 'improve_credit_score': 63,\n",
       " 'sync_device': 64,\n",
       " 'calendar': 65,\n",
       " 'expiration_date': 66,\n",
       " 'change_volume': 67,\n",
       " 'order_checks': 68,\n",
       " 'spending_history': 69,\n",
       " 'change_ai_name': 70,\n",
       " 'lost_luggage': 71,\n",
       " 'replacement_card_duration': 72,\n",
       " 'credit_limit': 73,\n",
       " 'min_payment': 74,\n",
       " 'cancel': 75,\n",
       " 'calendar_update': 76,\n",
       " 'tire_change': 77,\n",
       " 'goodbye': 78,\n",
       " 'application_status': 79,\n",
       " 'repeat': 80,\n",
       " 'text': 81,\n",
       " 'direct_deposit': 82,\n",
       " 'meal_suggestion': 83,\n",
       " 'measurement_conversion': 84,\n",
       " 'what_is_your_name': 85,\n",
       " 'restaurant_reviews': 86,\n",
       " 'taxes': 87,\n",
       " 'interest_rate': 88,\n",
       " 'travel_suggestion': 89,\n",
       " 'plug_type': 90,\n",
       " 'yes': 91,\n",
       " 'book_hotel': 92,\n",
       " 'smart_home': 93,\n",
       " 'ingredient_substitution': 94,\n",
       " 'pto_balance': 95,\n",
       " 'gas': 96,\n",
       " 'todo_list_update': 97,\n",
       " 'last_maintenance': 98,\n",
       " 'apr': 99,\n",
       " 'shopping_list_update': 100,\n",
       " 'oil_change_when': 101,\n",
       " 'thank_you': 102,\n",
       " 'w2': 103,\n",
       " 'balance': 104,\n",
       " 'credit_limit_change': 105,\n",
       " 'current_location': 106,\n",
       " 'uber': 107,\n",
       " 'travel_notification': 108,\n",
       " 'confirm_reservation': 109,\n",
       " 'card_declined': 110,\n",
       " 'bill_due': 111,\n",
       " 'traffic': 112,\n",
       " 'maybe': 113,\n",
       " 'bill_balance': 114,\n",
       " 'change_accent': 115,\n",
       " 'food_last': 116,\n",
       " 'account_blocked': 117,\n",
       " 'timer': 118,\n",
       " 'reminder_update': 119,\n",
       " 'reminder': 120,\n",
       " 'rollover_401k': 121,\n",
       " 'pin_change': 122,\n",
       " 'todo_list': 123,\n",
       " 'fun_fact': 124,\n",
       " 'meeting_schedule': 125,\n",
       " 'rewards_balance': 126,\n",
       " 'time': 127,\n",
       " 'travel_alert': 128,\n",
       " 'pto_request_status': 129,\n",
       " 'change_speed': 130,\n",
       " 'accept_reservations': 131,\n",
       " 'tell_joke': 132,\n",
       " 'translate': 133,\n",
       " 'tire_pressure': 134,\n",
       " 'oil_change_how': 135,\n",
       " 'how_busy': 136,\n",
       " 'spelling': 137,\n",
       " 'transactions': 138,\n",
       " 'routing': 139,\n",
       " 'order': 140,\n",
       " 'change_user_name': 141,\n",
       " 'freeze_account': 142,\n",
       " 'credit_score': 143,\n",
       " 'are_you_a_bot': 144,\n",
       " 'exchange_rate': 145,\n",
       " 'pto_used': 146,\n",
       " 'international_visa': 147,\n",
       " 'nutrition_info': 148,\n",
       " 'ingredients_list': 149}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a927a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['oos']=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62284f",
   "metadata": {},
   "source": [
    "## ADD USE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ba02016",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2521835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guse_embedings_with_batch(sentences,batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0,len(sentences),batch_size)):\n",
    "      embeddings_batch = embed(sentences[i:i+batch_size])\n",
    "      embeddings.extend(embeddings_batch)\n",
    "    return embeddings\n",
    "\n",
    "def add_embeddings(dt, column= 'text'):\n",
    "    embeddings = get_guse_embedings_with_batch(dt[column])\n",
    "    embs = np.array(embeddings).tolist()\n",
    "    df = pd.DataFrame([pd.Series(x) for x in embs])\n",
    "    df.columns = ['emb_{}'.format(x+1) for x in df.columns]\n",
    "    dt = pd.concat([dt,df], axis=1).reindex(dt.index)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d29c34dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:10<00:00,  6.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>emb_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set the alarm now</td>\n",
       "      <td>alarm</td>\n",
       "      <td>28</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>-0.049194</td>\n",
       "      <td>-0.041635</td>\n",
       "      <td>-0.031951</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>0.089107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107635</td>\n",
       "      <td>0.081210</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>-0.046487</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>-0.031242</td>\n",
       "      <td>-0.072224</td>\n",
       "      <td>-0.108159</td>\n",
       "      <td>-0.009890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please tell me what subjects you like</td>\n",
       "      <td>what_can_i_ask_you</td>\n",
       "      <td>45</td>\n",
       "      <td>0.059729</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.046124</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.068866</td>\n",
       "      <td>-0.017350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023217</td>\n",
       "      <td>-0.049913</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>-0.017940</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.031345</td>\n",
       "      <td>-0.029549</td>\n",
       "      <td>0.023903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is there an uber that drives to the bank on 5t...</td>\n",
       "      <td>uber</td>\n",
       "      <td>107</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>-0.014766</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>0.059949</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>0.052119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041092</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.085444</td>\n",
       "      <td>-0.068558</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.055524</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.049110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>change to something that's not whisper mode</td>\n",
       "      <td>whisper_mode</td>\n",
       "      <td>31</td>\n",
       "      <td>0.042140</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>-0.035960</td>\n",
       "      <td>-0.013485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072704</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>-0.028814</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>-0.088805</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.030570</td>\n",
       "      <td>0.069152</td>\n",
       "      <td>0.026542</td>\n",
       "      <td>-0.011627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer, call alexa</td>\n",
       "      <td>make_call</td>\n",
       "      <td>61</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.032199</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>-0.087309</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064405</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>-0.066277</td>\n",
       "      <td>-0.019167</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>-0.003916</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>-0.047592</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>-0.027060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              intent  \\\n",
       "0                                  set the alarm now               alarm   \n",
       "1              please tell me what subjects you like  what_can_i_ask_you   \n",
       "2  is there an uber that drives to the bank on 5t...                uber   \n",
       "3        change to something that's not whisper mode        whisper_mode   \n",
       "4                               computer, call alexa           make_call   \n",
       "\n",
       "   label     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0     28  0.004335  0.044460 -0.049194 -0.041635 -0.031951 -0.015406   \n",
       "1     45  0.059729  0.032617  0.046124 -0.002091  0.007193  0.068866   \n",
       "2    107  0.064134 -0.014766 -0.007532  0.059949  0.043445  0.056851   \n",
       "3     31  0.042140  0.019140  0.011681  0.033907  0.013733 -0.035960   \n",
       "4     61  0.016042  0.037868 -0.002721  0.032199  0.036126 -0.087309   \n",
       "\n",
       "      emb_7  ...   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508  \\\n",
       "0  0.089107  ...  0.107635  0.081210  0.005851  0.016944 -0.046487  0.004882   \n",
       "1 -0.017350  ... -0.023217 -0.049913  0.011365  0.036991 -0.017940 -0.011743   \n",
       "2  0.052119  ... -0.041092  0.015019  0.085444 -0.068558  0.004263  0.014379   \n",
       "3 -0.013485  ... -0.072704  0.053845 -0.028814  0.015518 -0.088805  0.007782   \n",
       "4  0.003662  ... -0.064405  0.019637 -0.066277 -0.019167  0.029189 -0.003916   \n",
       "\n",
       "    emb_509   emb_510   emb_511   emb_512  \n",
       "0 -0.031242 -0.072224 -0.108159 -0.009890  \n",
       "1  0.018322  0.031345 -0.029549  0.023903  \n",
       "2 -0.000778 -0.055524  0.028536  0.049110  \n",
       "3  0.030570  0.069152  0.026542 -0.011627  \n",
       "4  0.017222 -0.047592  0.011032 -0.027060  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['label'] = dt['intent'].apply(lambda x: labels.get(x,150))\n",
    "dt = add_embeddings(dt)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c927394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  6.41it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.06it/s]\n",
      "100%|██████████| 71/71 [00:12<00:00,  5.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.63it/s]\n",
      "100%|██████████| 165/165 [00:24<00:00,  6.79it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.57it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.07it/s]\n",
      "100%|██████████| 71/71 [00:11<00:00,  6.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.64it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.54it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.01it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.69it/s]\n",
      "100%|██████████| 71/71 [00:10<00:00,  6.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.28it/s]\n",
      "100%|██████████| 235/235 [00:32<00:00,  7.24it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.00it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.86it/s]\n",
      "100%|██████████| 71/71 [00:10<00:00,  6.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.85it/s]\n",
      "100%|██████████| 235/235 [00:34<00:00,  6.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2703.8341739177704"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time()\n",
    "for file_name in files:\n",
    "    dt = pd.read_csv(file_name)\n",
    "    dt['label'] = dt['intent'].apply(lambda x: labels.get(x,150))\n",
    "    add_embeddings(dt).to_csv(file_name.replace('.csv','_with_use_emb.csv'))\n",
    "time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b49e7a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/clinic/data_imbalanced/oos_train_with_use_emb.csv',\n",
       " '../data/clinic/data_imbalanced/test_with_use_emb.csv',\n",
       " '../data/clinic/data_imbalanced/val_with_use_emb.csv',\n",
       " '../data/clinic/data_imbalanced/train_with_use_emb.csv',\n",
       " '../data/clinic/data_imbalanced/oos_test_with_use_emb.csv',\n",
       " '../data/clinic/data_imbalanced/oos_val_with_use_emb.csv',\n",
       " '../data/clinic/data_small/oos_train_with_use_emb.csv',\n",
       " '../data/clinic/data_small/test_with_use_emb.csv',\n",
       " '../data/clinic/data_small/val_with_use_emb.csv',\n",
       " '../data/clinic/data_small/train_with_use_emb.csv',\n",
       " '../data/clinic/data_small/oos_test_with_use_emb.csv',\n",
       " '../data/clinic/data_small/oos_val_with_use_emb.csv',\n",
       " '../data/clinic/data_full/oos_train_with_use_emb.csv',\n",
       " '../data/clinic/data_full/test_with_use_emb.csv',\n",
       " '../data/clinic/data_full/val_with_use_emb.csv',\n",
       " '../data/clinic/data_full/train_with_use_emb.csv',\n",
       " '../data/clinic/data_full/oos_test_with_use_emb.csv',\n",
       " '../data/clinic/data_full/oos_val_with_use_emb.csv',\n",
       " '../data/clinic/data_oos_plus/oos_train_with_use_emb.csv',\n",
       " '../data/clinic/data_oos_plus/test_with_use_emb.csv',\n",
       " '../data/clinic/data_oos_plus/val_with_use_emb.csv',\n",
       " '../data/clinic/data_oos_plus/train_with_use_emb.csv',\n",
       " '../data/clinic/data_oos_plus/oos_test_with_use_emb.csv',\n",
       " '../data/clinic/data_oos_plus/oos_val_with_use_emb.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(DATA_FOLDER+ '*/*_with_use_emb.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b837d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "try:\n",
    "    import zlib\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "except:\n",
    "    compression = zipfile.ZIP_STORED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32a56a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "for file_name in files:\n",
    "    with ZipFile(file_name.replace('.csv','.zip'),'w') as zip:\n",
    "           zip.write(file_name, compress_type=compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ee5e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_full = MLPClassifier(hidden_layer_sizes=(400), \n",
    "                         max_iter=300,\n",
    "                         activation = 'relu',\n",
    "                         solver='adam',\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a26a4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MLP_Model(num_labels=2, \n",
    "                         dense_dropout=0.5, \n",
    "                         input_size = 512, \n",
    "                         hidden_size = 512,\n",
    "                        hidden_activation = 'tanh',\n",
    "                         output_activation = 'softmax',\n",
    "                         num_layers = 2):\n",
    "    features = Input(shape=(input_size,), name=\"first\")\n",
    "    hidden = Dropout(dense_dropout)(features)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        name = 'dense{}'.format(i) if i != num_layers - 1 else 'hidden'\n",
    "        if dense_dropout>0:\n",
    "            hidden = Dense(units=hidden_size, activation=\"relu\", name=name)(hidden)\n",
    "            hidden = Dropout(dense_dropout)(hidden)\n",
    "        else:\n",
    "            hidden = Dense(units=hidden_size, activation=\"relu\", name=name)(features)\n",
    "\n",
    "    logits = hidden\n",
    "    outputs = Dense(units=num_labels, activation=output_activation, name=\"output_1\")(logits)\n",
    "    model = keras.Model(inputs=features, outputs=outputs)\n",
    "    model.compile(optimizer='adam',  \n",
    "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  #optimizer='sgd',  loss='mse',\n",
    "                  #loss='binary_crossentropy',\n",
    "                  #metrics=['accuracy'],\n",
    "                  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "                  #metrics=[keras.metrics.PrecisionAtRecall(recall=0.8)],\n",
    "                  run_eagerly = False)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f03c070c",
   "metadata": {},
   "source": [
    "# Parameters:\n",
    "#https://github.com/clinc/oos-eval/blob/master/hyperparameters.csv\n",
    "\n",
    "Full\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       400\t       use\t        1\t      0\t\n",
    "           \n",
    "Small\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        1\t      0.1\n",
    "           \n",
    "Imbalanced\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        64      \t0\n",
    "           \n",
    "OOS+\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        16      \t0.1\t\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61663457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (InputLayer)           [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 400)               205200    \n",
      "_________________________________________________________________\n",
      "output_1 (Dense)             (None, 151)               60551     \n",
      "=================================================================\n",
      "Total params: 265,751\n",
      "Trainable params: 265,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_full = generate_MLP_Model(num_labels= 151, \n",
    "                     num_layers=1, \n",
    "                     hidden_size = 400, \n",
    "                     hidden_activation = 'tanh',\n",
    "                     output_activation = 'softmax',\n",
    "                     dense_dropout=0)\n",
    "mlp_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c3a1783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (InputLayer)           [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "output_1 (Dense)             (None, 151)               30351     \n",
      "=================================================================\n",
      "Total params: 132,951\n",
      "Trainable params: 132,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_small = generate_MLP_Model(num_labels= 151, \n",
    "                     num_layers=1, \n",
    "                     hidden_size = 200, \n",
    "                     hidden_activation = 'tanh',\n",
    "                     output_activation = 'softmax',\n",
    "                     dense_dropout=0.1)\n",
    "mlp_small.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "992c77c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (InputLayer)           [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "output_1 (Dense)             (None, 151)               30351     \n",
      "=================================================================\n",
      "Total params: 132,951\n",
      "Trainable params: 132,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_imbalanced = generate_MLP_Model(num_labels= 151, \n",
    "                     num_layers=1, \n",
    "                     hidden_size = 200, \n",
    "                     hidden_activation = 'tanh',\n",
    "                     output_activation = 'softmax',\n",
    "                     dense_dropout=0)\n",
    "mlp_imbalanced.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "96fdd952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first (InputLayer)           [(None, 512)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "output_1 (Dense)             (None, 151)               30351     \n",
      "=================================================================\n",
      "Total params: 132,951\n",
      "Trainable params: 132,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_oss_plus = generate_MLP_Model(num_labels= 151, \n",
    "                     num_layers=1, \n",
    "                     hidden_size = 200, \n",
    "                     hidden_activation = 'tanh',\n",
    "                     output_activation = 'softmax',\n",
    "                     dense_dropout=0.1)\n",
    "mlp_oss_plus.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807acc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Small Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "60928810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/clinic/data_imbalanced/',\n",
       " '../data/clinic/data_small/',\n",
       " '../data/clinic/data_full/',\n",
       " '../data/clinic/data_oos_plus/']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs = glob(DATA_FOLDER +\"*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecea9b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/clinic/data_small/oos_train_with_use_emb.csv',\n",
       " '../data/clinic/data_small/test_with_use_emb.csv',\n",
       " '../data/clinic/data_small/val_with_use_emb.csv',\n",
       " '../data/clinic/data_small/train_with_use_emb.csv',\n",
       " '../data/clinic/data_small/oos_test_with_use_emb.csv',\n",
       " '../data/clinic/data_small/oos_val_with_use_emb.csv']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(DATA_FOLDER+ 'data_small/*_with_use_emb.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f96bf953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>emb_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tell me the expiration date for my current cre...</td>\n",
       "      <td>expiration_date</td>\n",
       "      <td>66</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>-0.013376</td>\n",
       "      <td>-0.020924</td>\n",
       "      <td>-0.054085</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088208</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>-0.053102</td>\n",
       "      <td>-0.032048</td>\n",
       "      <td>-0.054841</td>\n",
       "      <td>-0.077261</td>\n",
       "      <td>0.060321</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>0.010952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>would you disconnect from my phone</td>\n",
       "      <td>sync_device</td>\n",
       "      <td>64</td>\n",
       "      <td>0.023302</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>0.044546</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>-0.024340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.052699</td>\n",
       "      <td>-0.001177</td>\n",
       "      <td>-0.057279</td>\n",
       "      <td>0.054607</td>\n",
       "      <td>0.014677</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>-0.028955</td>\n",
       "      <td>0.014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>could you please track my package</td>\n",
       "      <td>order_status</td>\n",
       "      <td>55</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.050021</td>\n",
       "      <td>0.086985</td>\n",
       "      <td>0.059008</td>\n",
       "      <td>-0.074861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044992</td>\n",
       "      <td>-0.026583</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>-0.055511</td>\n",
       "      <td>-0.076384</td>\n",
       "      <td>-0.034246</td>\n",
       "      <td>-0.016082</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>0.041905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>any travel alerts for canada</td>\n",
       "      <td>travel_alert</td>\n",
       "      <td>128</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.054119</td>\n",
       "      <td>-0.004863</td>\n",
       "      <td>0.063580</td>\n",
       "      <td>0.014945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.155747</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>-0.051993</td>\n",
       "      <td>-0.018311</td>\n",
       "      <td>0.030164</td>\n",
       "      <td>-0.067230</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.005654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>i want to report fraudulent activity on my ame...</td>\n",
       "      <td>report_fraud</td>\n",
       "      <td>40</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.061849</td>\n",
       "      <td>0.087114</td>\n",
       "      <td>0.062906</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015909</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.049547</td>\n",
       "      <td>-0.001585</td>\n",
       "      <td>-0.035708</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>-0.008624</td>\n",
       "      <td>0.025522</td>\n",
       "      <td>-0.034451</td>\n",
       "      <td>-0.011826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0                                               text  \\\n",
       "0      0           0  tell me the expiration date for my current cre...   \n",
       "1      1           1                 would you disconnect from my phone   \n",
       "2      2           2                  could you please track my package   \n",
       "3      3           3                       any travel alerts for canada   \n",
       "4      4           4  i want to report fraudulent activity on my ame...   \n",
       "\n",
       "            intent  label     emb_1     emb_2     emb_3     emb_4     emb_5  \\\n",
       "0  expiration_date     66  0.014531 -0.013376 -0.020924 -0.054085  0.047414   \n",
       "1      sync_device     64  0.023302  0.037649  0.044546  0.014734 -0.024340   \n",
       "2     order_status     55  0.015873  0.050021  0.086985  0.059008 -0.074861   \n",
       "3     travel_alert    128  0.011174  0.054119 -0.004863  0.063580  0.014945   \n",
       "4     report_fraud     40  0.020169  0.024297  0.061849  0.087114  0.062906   \n",
       "\n",
       "   ...   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508   emb_509  \\\n",
       "0  ...  0.088208  0.012695  0.015281 -0.053102 -0.032048 -0.054841 -0.077261   \n",
       "1  ...  0.000245  0.052699 -0.001177 -0.057279  0.054607  0.014677  0.042166   \n",
       "2  ...  0.044992 -0.026583  0.050293 -0.055511 -0.076384 -0.034246 -0.016082   \n",
       "3  ...  0.001516  0.044681  0.155747  0.006182 -0.051993 -0.018311  0.030164   \n",
       "4  ... -0.015909  0.014219  0.049547 -0.001585 -0.035708  0.011871 -0.008624   \n",
       "\n",
       "    emb_510   emb_511   emb_512  \n",
       "0  0.060321  0.012595  0.010952  \n",
       "1  0.024942 -0.028955  0.014179  \n",
       "2  0.014663  0.010821  0.041905  \n",
       "3 -0.067230  0.000345 -0.005654  \n",
       "4  0.025522 -0.034451 -0.011826  \n",
       "\n",
       "[5 rows x 517 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([ pd.read_csv('../data/clinic/data_small/train_with_use_emb.csv'),\n",
    "                        pd.read_csv('../data/clinic/data_small/oos_train_with_use_emb.csv')]\n",
    "                    ).reset_index()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5771fd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7600"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a825c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>emb_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey</td>\n",
       "      <td>greeting</td>\n",
       "      <td>57</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>-0.068319</td>\n",
       "      <td>-0.025212</td>\n",
       "      <td>-0.023325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046287</td>\n",
       "      <td>-0.008467</td>\n",
       "      <td>-0.021427</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>-0.018389</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.032133</td>\n",
       "      <td>-0.013732</td>\n",
       "      <td>-0.048603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>put laundry on my chore list</td>\n",
       "      <td>todo_list_update</td>\n",
       "      <td>97</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>-0.021964</td>\n",
       "      <td>0.044780</td>\n",
       "      <td>0.029989</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036820</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>-0.055528</td>\n",
       "      <td>-0.007398</td>\n",
       "      <td>-0.068883</td>\n",
       "      <td>-0.047780</td>\n",
       "      <td>-0.019560</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>0.025329</td>\n",
       "      <td>-0.060718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>go into whisper mode</td>\n",
       "      <td>whisper_mode</td>\n",
       "      <td>31</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>-0.054590</td>\n",
       "      <td>0.010793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023386</td>\n",
       "      <td>0.031051</td>\n",
       "      <td>-0.037808</td>\n",
       "      <td>-0.006632</td>\n",
       "      <td>-0.066107</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>0.026769</td>\n",
       "      <td>0.064020</td>\n",
       "      <td>0.030081</td>\n",
       "      <td>0.008039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>when do i need to change my motor oil again</td>\n",
       "      <td>oil_change_when</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.011529</td>\n",
       "      <td>-0.122637</td>\n",
       "      <td>-0.010257</td>\n",
       "      <td>0.088041</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049257</td>\n",
       "      <td>0.041907</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>0.029947</td>\n",
       "      <td>0.063522</td>\n",
       "      <td>-0.080513</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>-0.038446</td>\n",
       "      <td>0.005971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the insurance plan i am enrolled in</td>\n",
       "      <td>insurance</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.020582</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.067927</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064865</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>0.118396</td>\n",
       "      <td>0.055625</td>\n",
       "      <td>-0.062134</td>\n",
       "      <td>0.032670</td>\n",
       "      <td>-0.065479</td>\n",
       "      <td>0.033913</td>\n",
       "      <td>-0.021524</td>\n",
       "      <td>0.056304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0                                         text  \\\n",
       "0      0           0                                          hey   \n",
       "1      1           1                 put laundry on my chore list   \n",
       "2      2           2                         go into whisper mode   \n",
       "3      3           3  when do i need to change my motor oil again   \n",
       "4      4           4  what is the insurance plan i am enrolled in   \n",
       "\n",
       "             intent  label     emb_1     emb_2     emb_3     emb_4     emb_5  \\\n",
       "0          greeting     57 -0.011563  0.063238 -0.068319 -0.025212 -0.023325   \n",
       "1  todo_list_update     97  0.015696 -0.021964  0.044780  0.029989  0.043906   \n",
       "2      whisper_mode     31  0.014585  0.000869  0.004636 -0.054590  0.010793   \n",
       "3   oil_change_when    101 -0.011529 -0.122637 -0.010257  0.088041  0.041229   \n",
       "4         insurance     37 -0.020582  0.007809  0.067927 -0.014423  0.001521   \n",
       "\n",
       "   ...   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508   emb_509  \\\n",
       "0  ... -0.046287 -0.008467 -0.021427  0.024754  0.003913 -0.018389 -0.000087   \n",
       "1  ...  0.036820  0.043889 -0.055528 -0.007398 -0.068883 -0.047780 -0.019560   \n",
       "2  ... -0.023386  0.031051 -0.037808 -0.006632 -0.066107 -0.000482  0.026769   \n",
       "3  ...  0.049257  0.041907 -0.002899  0.014342  0.029947  0.063522 -0.080513   \n",
       "4  ... -0.064865 -0.003429  0.118396  0.055625 -0.062134  0.032670 -0.065479   \n",
       "\n",
       "    emb_510   emb_511   emb_512  \n",
       "0 -0.032133 -0.013732 -0.048603  \n",
       "1 -0.013006  0.025329 -0.060718  \n",
       "2  0.064020  0.030081  0.008039  \n",
       "3  0.028871 -0.038446  0.005971  \n",
       "4  0.033913 -0.021524  0.056304  \n",
       "\n",
       "[5 rows x 517 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.concat([ pd.read_csv('../data/clinic/data_small/val_with_use_emb.csv'),\n",
    "                        pd.read_csv('../data/clinic/data_small/oos_val_with_use_emb.csv')]\n",
    "                    ).reset_index()\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe23001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>emb_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks so much ai</td>\n",
       "      <td>thank_you</td>\n",
       "      <td>102</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.059464</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>-0.017123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010038</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>-0.049697</td>\n",
       "      <td>-0.065069</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>-0.050302</td>\n",
       "      <td>-0.044270</td>\n",
       "      <td>-0.045624</td>\n",
       "      <td>-0.065646</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i will be traveling to lima alert my bank</td>\n",
       "      <td>travel_notification</td>\n",
       "      <td>108</td>\n",
       "      <td>0.054223</td>\n",
       "      <td>0.063313</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>0.041752</td>\n",
       "      <td>0.048430</td>\n",
       "      <td>-0.083786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023788</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>0.053736</td>\n",
       "      <td>-0.017803</td>\n",
       "      <td>-0.025193</td>\n",
       "      <td>-0.027257</td>\n",
       "      <td>-0.018353</td>\n",
       "      <td>-0.005030</td>\n",
       "      <td>-0.039395</td>\n",
       "      <td>-0.034530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>say again please</td>\n",
       "      <td>repeat</td>\n",
       "      <td>80</td>\n",
       "      <td>0.005553</td>\n",
       "      <td>-0.055113</td>\n",
       "      <td>-0.010114</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>-0.040321</td>\n",
       "      <td>-0.043057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.031482</td>\n",
       "      <td>-0.066517</td>\n",
       "      <td>-0.011970</td>\n",
       "      <td>-0.054692</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>-0.029508</td>\n",
       "      <td>0.026939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what is needed to cook lasagna</td>\n",
       "      <td>ingredients_list</td>\n",
       "      <td>149</td>\n",
       "      <td>0.054684</td>\n",
       "      <td>-0.031352</td>\n",
       "      <td>0.060740</td>\n",
       "      <td>-0.075713</td>\n",
       "      <td>0.053304</td>\n",
       "      <td>0.027382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>-0.045377</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>-0.064737</td>\n",
       "      <td>-0.014584</td>\n",
       "      <td>-0.036439</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>-0.037485</td>\n",
       "      <td>0.022826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>give me the pressure for the tires on my car</td>\n",
       "      <td>tire_pressure</td>\n",
       "      <td>134</td>\n",
       "      <td>-0.035105</td>\n",
       "      <td>-0.106616</td>\n",
       "      <td>0.012198</td>\n",
       "      <td>0.022960</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>-0.003959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039068</td>\n",
       "      <td>0.040910</td>\n",
       "      <td>-0.019446</td>\n",
       "      <td>-0.061237</td>\n",
       "      <td>-0.055356</td>\n",
       "      <td>-0.017614</td>\n",
       "      <td>-0.010838</td>\n",
       "      <td>0.033609</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>-0.062180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          text  \\\n",
       "0           0                             thanks so much ai   \n",
       "1           1     i will be traveling to lima alert my bank   \n",
       "2           2                              say again please   \n",
       "3           3                what is needed to cook lasagna   \n",
       "4           4  give me the pressure for the tires on my car   \n",
       "\n",
       "                intent  label     emb_1     emb_2     emb_3     emb_4  \\\n",
       "0            thank_you    102  0.025073  0.015043  0.026919  0.059464   \n",
       "1  travel_notification    108  0.054223  0.063313  0.037354  0.041752   \n",
       "2               repeat     80  0.005553 -0.055113 -0.010114  0.025761   \n",
       "3     ingredients_list    149  0.054684 -0.031352  0.060740 -0.075713   \n",
       "4        tire_pressure    134 -0.035105 -0.106616  0.012198  0.022960   \n",
       "\n",
       "      emb_5     emb_6  ...   emb_503   emb_504   emb_505   emb_506   emb_507  \\\n",
       "0 -0.009611 -0.017123  ...  0.010038  0.019088 -0.049697 -0.065069  0.010041   \n",
       "1  0.048430 -0.083786  ... -0.023788  0.046185  0.053736 -0.017803 -0.025193   \n",
       "2 -0.040321 -0.043057  ...  0.014537  0.025975  0.006717  0.031482 -0.066517   \n",
       "3  0.053304  0.027382  ...  0.018304  0.007477 -0.045377  0.012741 -0.064737   \n",
       "4  0.012429 -0.003959  ... -0.039068  0.040910 -0.019446 -0.061237 -0.055356   \n",
       "\n",
       "    emb_508   emb_509   emb_510   emb_511   emb_512  \n",
       "0 -0.050302 -0.044270 -0.045624 -0.065646  0.004654  \n",
       "1 -0.027257 -0.018353 -0.005030 -0.039395 -0.034530  \n",
       "2 -0.011970 -0.054692  0.013403 -0.029508  0.026939  \n",
       "3 -0.014584 -0.036439 -0.026360 -0.037485  0.022826  \n",
       "4 -0.017614 -0.010838  0.033609 -0.015182 -0.062180  \n",
       "\n",
       "[5 rows x 516 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_inscope = pd.read_csv('../data/clinic/data_small/test_with_use_emb.csv')\n",
    "df_test_inscope.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0e84a084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>emb_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>can i get a sear's appliance repairman</td>\n",
       "      <td>oos</td>\n",
       "      <td>150</td>\n",
       "      <td>0.063763</td>\n",
       "      <td>-0.083389</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>0.029875</td>\n",
       "      <td>0.062481</td>\n",
       "      <td>-0.048170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055654</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>0.041753</td>\n",
       "      <td>-0.066075</td>\n",
       "      <td>-0.010990</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>-0.051586</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.014396</td>\n",
       "      <td>0.067789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>what do you do if you can't stop vomiting</td>\n",
       "      <td>oos</td>\n",
       "      <td>150</td>\n",
       "      <td>0.067390</td>\n",
       "      <td>-0.049942</td>\n",
       "      <td>0.060520</td>\n",
       "      <td>0.041764</td>\n",
       "      <td>-0.032410</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061177</td>\n",
       "      <td>0.067160</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.114446</td>\n",
       "      <td>-0.041907</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>-0.017072</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>how many ppm of particulate is in my local water</td>\n",
       "      <td>oos</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.011204</td>\n",
       "      <td>-0.075099</td>\n",
       "      <td>0.056254</td>\n",
       "      <td>0.019079</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068538</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.032535</td>\n",
       "      <td>-0.041910</td>\n",
       "      <td>-0.042781</td>\n",
       "      <td>0.054235</td>\n",
       "      <td>-0.009878</td>\n",
       "      <td>-0.019642</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.033913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>get me a list of divorce attorneys in the new ...</td>\n",
       "      <td>oos</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.067331</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>0.054819</td>\n",
       "      <td>0.050415</td>\n",
       "      <td>0.087959</td>\n",
       "      <td>0.036031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051748</td>\n",
       "      <td>0.040872</td>\n",
       "      <td>0.105509</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>-0.009358</td>\n",
       "      <td>-0.032585</td>\n",
       "      <td>-0.025125</td>\n",
       "      <td>0.038075</td>\n",
       "      <td>-0.066352</td>\n",
       "      <td>-0.024866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>clear my search history</td>\n",
       "      <td>oos</td>\n",
       "      <td>150</td>\n",
       "      <td>-0.040048</td>\n",
       "      <td>-0.057774</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>-0.028530</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.057833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025218</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>-0.024022</td>\n",
       "      <td>-0.011786</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>-0.059307</td>\n",
       "      <td>0.007647</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>-0.001198</td>\n",
       "      <td>0.038130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text intent  \\\n",
       "0           0             can i get a sear's appliance repairman    oos   \n",
       "1           1          what do you do if you can't stop vomiting    oos   \n",
       "2           2   how many ppm of particulate is in my local water    oos   \n",
       "3           3  get me a list of divorce attorneys in the new ...    oos   \n",
       "4           4                            clear my search history    oos   \n",
       "\n",
       "   label     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  ...  \\\n",
       "0    150  0.063763 -0.083389  0.041397  0.029875  0.062481 -0.048170  ...   \n",
       "1    150  0.067390 -0.049942  0.060520  0.041764 -0.032410 -0.000165  ...   \n",
       "2    150 -0.011204 -0.075099  0.056254  0.019079  0.003711  0.032722  ...   \n",
       "3    150 -0.067331  0.003313  0.054819  0.050415  0.087959  0.036031  ...   \n",
       "4    150 -0.040048 -0.057774  0.023027 -0.028530 -0.034821 -0.057833  ...   \n",
       "\n",
       "    emb_503   emb_504   emb_505   emb_506   emb_507   emb_508   emb_509  \\\n",
       "0 -0.055654  0.009555  0.041753 -0.066075 -0.010990  0.005024 -0.051586   \n",
       "1  0.061177  0.067160  0.002748  0.114446 -0.041907  0.006750 -0.017072   \n",
       "2 -0.068538  0.020465  0.032535 -0.041910 -0.042781  0.054235 -0.009878   \n",
       "3 -0.051748  0.040872  0.105509 -0.004875 -0.009358 -0.032585 -0.025125   \n",
       "4 -0.025218  0.004158 -0.024022 -0.011786  0.040685 -0.059307  0.007647   \n",
       "\n",
       "    emb_510   emb_511   emb_512  \n",
       "0  0.021008  0.014396  0.067789  \n",
       "1  0.002755  0.008661  0.005566  \n",
       "2 -0.019642  0.000677  0.033913  \n",
       "3  0.038075 -0.066352 -0.024866  \n",
       "4  0.015519 -0.001198  0.038130  \n",
       "\n",
       "[5 rows x 516 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_oos = pd.read_csv('../data/clinic/data_small/oos_test_with_use_emb.csv')\n",
    "df_test_oos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "247bc0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emb_1',\n",
       " 'emb_2',\n",
       " 'emb_3',\n",
       " 'emb_4',\n",
       " 'emb_5',\n",
       " 'emb_6',\n",
       " 'emb_7',\n",
       " 'emb_8',\n",
       " 'emb_9',\n",
       " 'emb_10',\n",
       " 'emb_11',\n",
       " 'emb_12',\n",
       " 'emb_13',\n",
       " 'emb_14',\n",
       " 'emb_15',\n",
       " 'emb_16',\n",
       " 'emb_17',\n",
       " 'emb_18',\n",
       " 'emb_19',\n",
       " 'emb_20',\n",
       " 'emb_21',\n",
       " 'emb_22',\n",
       " 'emb_23',\n",
       " 'emb_24',\n",
       " 'emb_25',\n",
       " 'emb_26',\n",
       " 'emb_27',\n",
       " 'emb_28',\n",
       " 'emb_29',\n",
       " 'emb_30',\n",
       " 'emb_31',\n",
       " 'emb_32',\n",
       " 'emb_33',\n",
       " 'emb_34',\n",
       " 'emb_35',\n",
       " 'emb_36',\n",
       " 'emb_37',\n",
       " 'emb_38',\n",
       " 'emb_39',\n",
       " 'emb_40',\n",
       " 'emb_41',\n",
       " 'emb_42',\n",
       " 'emb_43',\n",
       " 'emb_44',\n",
       " 'emb_45',\n",
       " 'emb_46',\n",
       " 'emb_47',\n",
       " 'emb_48',\n",
       " 'emb_49',\n",
       " 'emb_50',\n",
       " 'emb_51',\n",
       " 'emb_52',\n",
       " 'emb_53',\n",
       " 'emb_54',\n",
       " 'emb_55',\n",
       " 'emb_56',\n",
       " 'emb_57',\n",
       " 'emb_58',\n",
       " 'emb_59',\n",
       " 'emb_60',\n",
       " 'emb_61',\n",
       " 'emb_62',\n",
       " 'emb_63',\n",
       " 'emb_64',\n",
       " 'emb_65',\n",
       " 'emb_66',\n",
       " 'emb_67',\n",
       " 'emb_68',\n",
       " 'emb_69',\n",
       " 'emb_70',\n",
       " 'emb_71',\n",
       " 'emb_72',\n",
       " 'emb_73',\n",
       " 'emb_74',\n",
       " 'emb_75',\n",
       " 'emb_76',\n",
       " 'emb_77',\n",
       " 'emb_78',\n",
       " 'emb_79',\n",
       " 'emb_80',\n",
       " 'emb_81',\n",
       " 'emb_82',\n",
       " 'emb_83',\n",
       " 'emb_84',\n",
       " 'emb_85',\n",
       " 'emb_86',\n",
       " 'emb_87',\n",
       " 'emb_88',\n",
       " 'emb_89',\n",
       " 'emb_90',\n",
       " 'emb_91',\n",
       " 'emb_92',\n",
       " 'emb_93',\n",
       " 'emb_94',\n",
       " 'emb_95',\n",
       " 'emb_96',\n",
       " 'emb_97',\n",
       " 'emb_98',\n",
       " 'emb_99',\n",
       " 'emb_100',\n",
       " 'emb_101',\n",
       " 'emb_102',\n",
       " 'emb_103',\n",
       " 'emb_104',\n",
       " 'emb_105',\n",
       " 'emb_106',\n",
       " 'emb_107',\n",
       " 'emb_108',\n",
       " 'emb_109',\n",
       " 'emb_110',\n",
       " 'emb_111',\n",
       " 'emb_112',\n",
       " 'emb_113',\n",
       " 'emb_114',\n",
       " 'emb_115',\n",
       " 'emb_116',\n",
       " 'emb_117',\n",
       " 'emb_118',\n",
       " 'emb_119',\n",
       " 'emb_120',\n",
       " 'emb_121',\n",
       " 'emb_122',\n",
       " 'emb_123',\n",
       " 'emb_124',\n",
       " 'emb_125',\n",
       " 'emb_126',\n",
       " 'emb_127',\n",
       " 'emb_128',\n",
       " 'emb_129',\n",
       " 'emb_130',\n",
       " 'emb_131',\n",
       " 'emb_132',\n",
       " 'emb_133',\n",
       " 'emb_134',\n",
       " 'emb_135',\n",
       " 'emb_136',\n",
       " 'emb_137',\n",
       " 'emb_138',\n",
       " 'emb_139',\n",
       " 'emb_140',\n",
       " 'emb_141',\n",
       " 'emb_142',\n",
       " 'emb_143',\n",
       " 'emb_144',\n",
       " 'emb_145',\n",
       " 'emb_146',\n",
       " 'emb_147',\n",
       " 'emb_148',\n",
       " 'emb_149',\n",
       " 'emb_150',\n",
       " 'emb_151',\n",
       " 'emb_152',\n",
       " 'emb_153',\n",
       " 'emb_154',\n",
       " 'emb_155',\n",
       " 'emb_156',\n",
       " 'emb_157',\n",
       " 'emb_158',\n",
       " 'emb_159',\n",
       " 'emb_160',\n",
       " 'emb_161',\n",
       " 'emb_162',\n",
       " 'emb_163',\n",
       " 'emb_164',\n",
       " 'emb_165',\n",
       " 'emb_166',\n",
       " 'emb_167',\n",
       " 'emb_168',\n",
       " 'emb_169',\n",
       " 'emb_170',\n",
       " 'emb_171',\n",
       " 'emb_172',\n",
       " 'emb_173',\n",
       " 'emb_174',\n",
       " 'emb_175',\n",
       " 'emb_176',\n",
       " 'emb_177',\n",
       " 'emb_178',\n",
       " 'emb_179',\n",
       " 'emb_180',\n",
       " 'emb_181',\n",
       " 'emb_182',\n",
       " 'emb_183',\n",
       " 'emb_184',\n",
       " 'emb_185',\n",
       " 'emb_186',\n",
       " 'emb_187',\n",
       " 'emb_188',\n",
       " 'emb_189',\n",
       " 'emb_190',\n",
       " 'emb_191',\n",
       " 'emb_192',\n",
       " 'emb_193',\n",
       " 'emb_194',\n",
       " 'emb_195',\n",
       " 'emb_196',\n",
       " 'emb_197',\n",
       " 'emb_198',\n",
       " 'emb_199',\n",
       " 'emb_200',\n",
       " 'emb_201',\n",
       " 'emb_202',\n",
       " 'emb_203',\n",
       " 'emb_204',\n",
       " 'emb_205',\n",
       " 'emb_206',\n",
       " 'emb_207',\n",
       " 'emb_208',\n",
       " 'emb_209',\n",
       " 'emb_210',\n",
       " 'emb_211',\n",
       " 'emb_212',\n",
       " 'emb_213',\n",
       " 'emb_214',\n",
       " 'emb_215',\n",
       " 'emb_216',\n",
       " 'emb_217',\n",
       " 'emb_218',\n",
       " 'emb_219',\n",
       " 'emb_220',\n",
       " 'emb_221',\n",
       " 'emb_222',\n",
       " 'emb_223',\n",
       " 'emb_224',\n",
       " 'emb_225',\n",
       " 'emb_226',\n",
       " 'emb_227',\n",
       " 'emb_228',\n",
       " 'emb_229',\n",
       " 'emb_230',\n",
       " 'emb_231',\n",
       " 'emb_232',\n",
       " 'emb_233',\n",
       " 'emb_234',\n",
       " 'emb_235',\n",
       " 'emb_236',\n",
       " 'emb_237',\n",
       " 'emb_238',\n",
       " 'emb_239',\n",
       " 'emb_240',\n",
       " 'emb_241',\n",
       " 'emb_242',\n",
       " 'emb_243',\n",
       " 'emb_244',\n",
       " 'emb_245',\n",
       " 'emb_246',\n",
       " 'emb_247',\n",
       " 'emb_248',\n",
       " 'emb_249',\n",
       " 'emb_250',\n",
       " 'emb_251',\n",
       " 'emb_252',\n",
       " 'emb_253',\n",
       " 'emb_254',\n",
       " 'emb_255',\n",
       " 'emb_256',\n",
       " 'emb_257',\n",
       " 'emb_258',\n",
       " 'emb_259',\n",
       " 'emb_260',\n",
       " 'emb_261',\n",
       " 'emb_262',\n",
       " 'emb_263',\n",
       " 'emb_264',\n",
       " 'emb_265',\n",
       " 'emb_266',\n",
       " 'emb_267',\n",
       " 'emb_268',\n",
       " 'emb_269',\n",
       " 'emb_270',\n",
       " 'emb_271',\n",
       " 'emb_272',\n",
       " 'emb_273',\n",
       " 'emb_274',\n",
       " 'emb_275',\n",
       " 'emb_276',\n",
       " 'emb_277',\n",
       " 'emb_278',\n",
       " 'emb_279',\n",
       " 'emb_280',\n",
       " 'emb_281',\n",
       " 'emb_282',\n",
       " 'emb_283',\n",
       " 'emb_284',\n",
       " 'emb_285',\n",
       " 'emb_286',\n",
       " 'emb_287',\n",
       " 'emb_288',\n",
       " 'emb_289',\n",
       " 'emb_290',\n",
       " 'emb_291',\n",
       " 'emb_292',\n",
       " 'emb_293',\n",
       " 'emb_294',\n",
       " 'emb_295',\n",
       " 'emb_296',\n",
       " 'emb_297',\n",
       " 'emb_298',\n",
       " 'emb_299',\n",
       " 'emb_300',\n",
       " 'emb_301',\n",
       " 'emb_302',\n",
       " 'emb_303',\n",
       " 'emb_304',\n",
       " 'emb_305',\n",
       " 'emb_306',\n",
       " 'emb_307',\n",
       " 'emb_308',\n",
       " 'emb_309',\n",
       " 'emb_310',\n",
       " 'emb_311',\n",
       " 'emb_312',\n",
       " 'emb_313',\n",
       " 'emb_314',\n",
       " 'emb_315',\n",
       " 'emb_316',\n",
       " 'emb_317',\n",
       " 'emb_318',\n",
       " 'emb_319',\n",
       " 'emb_320',\n",
       " 'emb_321',\n",
       " 'emb_322',\n",
       " 'emb_323',\n",
       " 'emb_324',\n",
       " 'emb_325',\n",
       " 'emb_326',\n",
       " 'emb_327',\n",
       " 'emb_328',\n",
       " 'emb_329',\n",
       " 'emb_330',\n",
       " 'emb_331',\n",
       " 'emb_332',\n",
       " 'emb_333',\n",
       " 'emb_334',\n",
       " 'emb_335',\n",
       " 'emb_336',\n",
       " 'emb_337',\n",
       " 'emb_338',\n",
       " 'emb_339',\n",
       " 'emb_340',\n",
       " 'emb_341',\n",
       " 'emb_342',\n",
       " 'emb_343',\n",
       " 'emb_344',\n",
       " 'emb_345',\n",
       " 'emb_346',\n",
       " 'emb_347',\n",
       " 'emb_348',\n",
       " 'emb_349',\n",
       " 'emb_350',\n",
       " 'emb_351',\n",
       " 'emb_352',\n",
       " 'emb_353',\n",
       " 'emb_354',\n",
       " 'emb_355',\n",
       " 'emb_356',\n",
       " 'emb_357',\n",
       " 'emb_358',\n",
       " 'emb_359',\n",
       " 'emb_360',\n",
       " 'emb_361',\n",
       " 'emb_362',\n",
       " 'emb_363',\n",
       " 'emb_364',\n",
       " 'emb_365',\n",
       " 'emb_366',\n",
       " 'emb_367',\n",
       " 'emb_368',\n",
       " 'emb_369',\n",
       " 'emb_370',\n",
       " 'emb_371',\n",
       " 'emb_372',\n",
       " 'emb_373',\n",
       " 'emb_374',\n",
       " 'emb_375',\n",
       " 'emb_376',\n",
       " 'emb_377',\n",
       " 'emb_378',\n",
       " 'emb_379',\n",
       " 'emb_380',\n",
       " 'emb_381',\n",
       " 'emb_382',\n",
       " 'emb_383',\n",
       " 'emb_384',\n",
       " 'emb_385',\n",
       " 'emb_386',\n",
       " 'emb_387',\n",
       " 'emb_388',\n",
       " 'emb_389',\n",
       " 'emb_390',\n",
       " 'emb_391',\n",
       " 'emb_392',\n",
       " 'emb_393',\n",
       " 'emb_394',\n",
       " 'emb_395',\n",
       " 'emb_396',\n",
       " 'emb_397',\n",
       " 'emb_398',\n",
       " 'emb_399',\n",
       " 'emb_400',\n",
       " 'emb_401',\n",
       " 'emb_402',\n",
       " 'emb_403',\n",
       " 'emb_404',\n",
       " 'emb_405',\n",
       " 'emb_406',\n",
       " 'emb_407',\n",
       " 'emb_408',\n",
       " 'emb_409',\n",
       " 'emb_410',\n",
       " 'emb_411',\n",
       " 'emb_412',\n",
       " 'emb_413',\n",
       " 'emb_414',\n",
       " 'emb_415',\n",
       " 'emb_416',\n",
       " 'emb_417',\n",
       " 'emb_418',\n",
       " 'emb_419',\n",
       " 'emb_420',\n",
       " 'emb_421',\n",
       " 'emb_422',\n",
       " 'emb_423',\n",
       " 'emb_424',\n",
       " 'emb_425',\n",
       " 'emb_426',\n",
       " 'emb_427',\n",
       " 'emb_428',\n",
       " 'emb_429',\n",
       " 'emb_430',\n",
       " 'emb_431',\n",
       " 'emb_432',\n",
       " 'emb_433',\n",
       " 'emb_434',\n",
       " 'emb_435',\n",
       " 'emb_436',\n",
       " 'emb_437',\n",
       " 'emb_438',\n",
       " 'emb_439',\n",
       " 'emb_440',\n",
       " 'emb_441',\n",
       " 'emb_442',\n",
       " 'emb_443',\n",
       " 'emb_444',\n",
       " 'emb_445',\n",
       " 'emb_446',\n",
       " 'emb_447',\n",
       " 'emb_448',\n",
       " 'emb_449',\n",
       " 'emb_450',\n",
       " 'emb_451',\n",
       " 'emb_452',\n",
       " 'emb_453',\n",
       " 'emb_454',\n",
       " 'emb_455',\n",
       " 'emb_456',\n",
       " 'emb_457',\n",
       " 'emb_458',\n",
       " 'emb_459',\n",
       " 'emb_460',\n",
       " 'emb_461',\n",
       " 'emb_462',\n",
       " 'emb_463',\n",
       " 'emb_464',\n",
       " 'emb_465',\n",
       " 'emb_466',\n",
       " 'emb_467',\n",
       " 'emb_468',\n",
       " 'emb_469',\n",
       " 'emb_470',\n",
       " 'emb_471',\n",
       " 'emb_472',\n",
       " 'emb_473',\n",
       " 'emb_474',\n",
       " 'emb_475',\n",
       " 'emb_476',\n",
       " 'emb_477',\n",
       " 'emb_478',\n",
       " 'emb_479',\n",
       " 'emb_480',\n",
       " 'emb_481',\n",
       " 'emb_482',\n",
       " 'emb_483',\n",
       " 'emb_484',\n",
       " 'emb_485',\n",
       " 'emb_486',\n",
       " 'emb_487',\n",
       " 'emb_488',\n",
       " 'emb_489',\n",
       " 'emb_490',\n",
       " 'emb_491',\n",
       " 'emb_492',\n",
       " 'emb_493',\n",
       " 'emb_494',\n",
       " 'emb_495',\n",
       " 'emb_496',\n",
       " 'emb_497',\n",
       " 'emb_498',\n",
       " 'emb_499',\n",
       " 'emb_500',\n",
       " 'emb_501',\n",
       " 'emb_502',\n",
       " 'emb_503',\n",
       " 'emb_504',\n",
       " 'emb_505',\n",
       " 'emb_506',\n",
       " 'emb_507',\n",
       " 'emb_508',\n",
       " 'emb_509',\n",
       " 'emb_510',\n",
       " 'emb_511',\n",
       " 'emb_512']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_cols = ['emb'+'_'+str(i+1) for i in range(512)]\n",
    "emb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9e9e3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                            mode =\"min\", patience = 20, \n",
    "                                            restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f21e8350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 3100 samples\n",
      "Epoch 1/100\n",
      "7600/7600 [==============================] - 0s 29us/sample - loss: 4.0879e-04 - acc: 0.9997 - val_loss: 0.4661 - val_acc: 0.9506\n",
      "Epoch 2/100\n",
      "7600/7600 [==============================] - 0s 33us/sample - loss: 2.6489e-04 - acc: 1.0000 - val_loss: 0.4670 - val_acc: 0.9497\n",
      "Epoch 3/100\n",
      "7600/7600 [==============================] - 0s 28us/sample - loss: 2.2869e-04 - acc: 0.9999 - val_loss: 0.4546 - val_acc: 0.9526\n",
      "Epoch 4/100\n",
      "7600/7600 [==============================] - 0s 30us/sample - loss: 8.6612e-05 - acc: 1.0000 - val_loss: 0.4546 - val_acc: 0.9523\n",
      "Epoch 5/100\n",
      "7600/7600 [==============================] - 0s 34us/sample - loss: 1.3002e-04 - acc: 1.0000 - val_loss: 0.4571 - val_acc: 0.9513\n",
      "Epoch 6/100\n",
      "7600/7600 [==============================] - 0s 27us/sample - loss: 2.5505e-04 - acc: 0.9999 - val_loss: 0.4559 - val_acc: 0.9519\n",
      "Epoch 7/100\n",
      "7600/7600 [==============================] - 0s 27us/sample - loss: 1.2803e-04 - acc: 1.0000 - val_loss: 0.4494 - val_acc: 0.9529\n",
      "Epoch 8/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 1.8363e-04 - acc: 1.0000 - val_loss: 0.4526 - val_acc: 0.9545\n",
      "Epoch 9/100\n",
      "7600/7600 [==============================] - 0s 29us/sample - loss: 9.0889e-05 - acc: 1.0000 - val_loss: 0.4614 - val_acc: 0.9519\n",
      "Epoch 10/100\n",
      "7600/7600 [==============================] - 0s 33us/sample - loss: 1.9172e-04 - acc: 1.0000 - val_loss: 0.4555 - val_acc: 0.9516\n",
      "Epoch 11/100\n",
      "7600/7600 [==============================] - 0s 26us/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.4586 - val_acc: 0.9542\n",
      "Epoch 12/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 2.3031e-04 - acc: 0.9999 - val_loss: 0.4612 - val_acc: 0.9516\n",
      "Epoch 13/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 9.2946e-05 - acc: 1.0000 - val_loss: 0.4541 - val_acc: 0.9526\n",
      "Epoch 14/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 6.1435e-05 - acc: 1.0000 - val_loss: 0.4468 - val_acc: 0.9552\n",
      "Epoch 15/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 1.4953e-04 - acc: 0.9999 - val_loss: 0.4518 - val_acc: 0.9535\n",
      "Epoch 16/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 2.3159e-04 - acc: 0.9999 - val_loss: 0.4578 - val_acc: 0.9532\n",
      "Epoch 17/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 2.3167e-05 - acc: 1.0000 - val_loss: 0.4671 - val_acc: 0.9516\n",
      "Epoch 18/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 1.2197e-04 - acc: 0.9999 - val_loss: 0.4586 - val_acc: 0.9529\n",
      "Epoch 19/100\n",
      "7600/7600 [==============================] - 0s 29us/sample - loss: 2.6493e-04 - acc: 0.9999 - val_loss: 0.4571 - val_acc: 0.9526\n",
      "Epoch 20/100\n",
      "7600/7600 [==============================] - 0s 28us/sample - loss: 1.3230e-04 - acc: 1.0000 - val_loss: 0.4653 - val_acc: 0.9513\n",
      "Epoch 21/100\n",
      "7600/7600 [==============================] - 0s 28us/sample - loss: 5.1483e-05 - acc: 1.0000 - val_loss: 0.4673 - val_acc: 0.9526\n",
      "Epoch 22/100\n",
      "7600/7600 [==============================] - 0s 31us/sample - loss: 9.5658e-05 - acc: 1.0000 - val_loss: 0.4587 - val_acc: 0.9513\n",
      "Epoch 23/100\n",
      "7600/7600 [==============================] - 0s 28us/sample - loss: 5.3037e-05 - acc: 1.0000 - val_loss: 0.4585 - val_acc: 0.9526\n",
      "Epoch 24/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 6.1466e-05 - acc: 1.0000 - val_loss: 0.4573 - val_acc: 0.9545\n",
      "Epoch 25/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 9.5571e-05 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.9532\n",
      "Epoch 26/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 3.8604e-05 - acc: 1.0000 - val_loss: 0.4604 - val_acc: 0.9535\n",
      "Epoch 27/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 9.9592e-05 - acc: 1.0000 - val_loss: 0.4611 - val_acc: 0.9535\n",
      "Epoch 28/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 1.0142e-04 - acc: 1.0000 - val_loss: 0.4633 - val_acc: 0.9539\n",
      "Epoch 29/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 3.2652e-04 - acc: 0.9999 - val_loss: 0.4571 - val_acc: 0.9532\n",
      "Epoch 30/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 2.5868e-04 - acc: 0.9999 - val_loss: 0.4663 - val_acc: 0.9516\n",
      "Epoch 31/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 1.0801e-04 - acc: 1.0000 - val_loss: 0.4711 - val_acc: 0.9519\n",
      "Epoch 32/100\n",
      "7600/7600 [==============================] - 0s 24us/sample - loss: 5.5634e-05 - acc: 1.0000 - val_loss: 0.4689 - val_acc: 0.9513\n",
      "Epoch 33/100\n",
      "7600/7600 [==============================] - 0s 25us/sample - loss: 8.6697e-05 - acc: 1.0000 - val_loss: 0.4691 - val_acc: 0.9513\n",
      "Epoch 34/100\n",
      "7600/7600 [==============================] - 0s 26us/sample - loss: 2.5889e-04 - acc: 1.0000 - val_loss: 0.4738 - val_acc: 0.9519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5d5b85320>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_small.fit(df_train[emb_cols].values, \n",
    "              df_train['label'].values,\n",
    "              batch_size = 100, \n",
    "              epochs=100, \n",
    "              validation_data=(df_valid[emb_cols].values, df_valid['label'].values),\n",
    "              callbacks =[earlystopping],            \n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "509066ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7600 samples, validate on 3100 samples\n",
      "Epoch 1/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0282 - acc: 0.9942 - val_loss: 0.4650 - val_acc: 0.9413\n",
      "Epoch 2/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0025 - acc: 0.9993 - val_loss: 0.4545 - val_acc: 0.9484\n",
      "Epoch 3/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0024 - acc: 0.9992 - val_loss: 0.4422 - val_acc: 0.9510\n",
      "Epoch 4/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0028 - acc: 0.9989 - val_loss: 0.4682 - val_acc: 0.9471\n",
      "Epoch 5/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 8.1679e-04 - acc: 0.9997 - val_loss: 0.4791 - val_acc: 0.9435\n",
      "Epoch 6/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0017 - acc: 0.9993 - val_loss: 0.4511 - val_acc: 0.9519\n",
      "Epoch 7/100\n",
      "7600/7600 [==============================] - 11s 1ms/sample - loss: 0.0057 - acc: 0.9986 - val_loss: 0.4569 - val_acc: 0.9513\n",
      "Epoch 8/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0029 - acc: 0.9995 - val_loss: 0.4633 - val_acc: 0.9500\n",
      "Epoch 9/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0032 - acc: 0.9993 - val_loss: 0.4548 - val_acc: 0.9529\n",
      "Epoch 10/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0031 - acc: 0.9991 - val_loss: 0.4606 - val_acc: 0.9490\n",
      "Epoch 11/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 4.7250e-04 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.9481\n",
      "Epoch 12/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0025 - acc: 0.9993 - val_loss: 0.4653 - val_acc: 0.9468\n",
      "Epoch 13/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 7.2102e-04 - acc: 0.9997 - val_loss: 0.4777 - val_acc: 0.9503\n",
      "Epoch 14/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 9.6117e-04 - acc: 0.9997 - val_loss: 0.4699 - val_acc: 0.9494\n",
      "Epoch 15/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0014 - acc: 0.9993 - val_loss: 0.5143 - val_acc: 0.9452\n",
      "Epoch 16/100\n",
      "7600/7600 [==============================] - 11s 1ms/sample - loss: 0.0024 - acc: 0.9993 - val_loss: 0.5097 - val_acc: 0.9484\n",
      "Epoch 17/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.5074 - val_acc: 0.9455\n",
      "Epoch 18/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0031 - acc: 0.9995 - val_loss: 0.5257 - val_acc: 0.9490\n",
      "Epoch 19/100\n",
      "7600/7600 [==============================] - 11s 1ms/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.5152 - val_acc: 0.9494\n",
      "Epoch 20/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.5146 - val_acc: 0.9519\n",
      "Epoch 21/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 8.5856e-04 - acc: 0.9996 - val_loss: 0.5060 - val_acc: 0.9529\n",
      "Epoch 22/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.5140 - val_acc: 0.9506\n",
      "Epoch 23/100\n",
      "7600/7600 [==============================] - 12s 2ms/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.5120 - val_acc: 0.9516\n",
      "Epoch 24/100\n",
      "7600/7600 [==============================] - 12s 2ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.5115 - val_acc: 0.9490\n",
      "Epoch 25/100\n",
      "7600/7600 [==============================] - 10s 1ms/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.5416 - val_acc: 0.9439\n",
      "Epoch 26/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.5368 - val_acc: 0.9516\n",
      "Epoch 27/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0038 - acc: 0.9989 - val_loss: 0.5223 - val_acc: 0.9510\n",
      "Epoch 28/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.5357 - val_acc: 0.9500\n",
      "Epoch 29/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 5.1944e-04 - acc: 0.9997 - val_loss: 0.5176 - val_acc: 0.9532\n",
      "Epoch 30/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0055 - acc: 0.9995 - val_loss: 0.5359 - val_acc: 0.9487\n",
      "Epoch 31/100\n",
      "7600/7600 [==============================] - 9s 1ms/sample - loss: 0.0012 - acc: 0.9996 - val_loss: 0.5481 - val_acc: 0.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb5d43a2668>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_small.fit(df_train[emb_cols].values, \n",
    "              df_train['label'].values,\n",
    "              batch_size = 1, \n",
    "              epochs=100, \n",
    "              validation_data=(df_valid[emb_cols].values, df_valid['label'].values),\n",
    "              callbacks =[earlystopping],            \n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76c86bf",
   "metadata": {},
   "source": [
    "## Inscope Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7820421e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9667    0.9831        30\n",
      "           1     1.0000    0.8667    0.9286        30\n",
      "           2     1.0000    0.9000    0.9474        30\n",
      "           3     0.9355    0.9667    0.9508        30\n",
      "           4     1.0000    1.0000    1.0000        30\n",
      "           5     0.9643    0.9000    0.9310        30\n",
      "           6     0.9667    0.9667    0.9667        30\n",
      "           7     1.0000    0.9667    0.9831        30\n",
      "           8     1.0000    0.9667    0.9831        30\n",
      "           9     1.0000    1.0000    1.0000        30\n",
      "          10     0.9032    0.9333    0.9180        30\n",
      "          11     0.9667    0.9667    0.9667        30\n",
      "          12     1.0000    0.9333    0.9655        30\n",
      "          13     1.0000    1.0000    1.0000        30\n",
      "          14     0.8824    1.0000    0.9375        30\n",
      "          15     1.0000    1.0000    1.0000        30\n",
      "          16     0.9667    0.9667    0.9667        30\n",
      "          17     1.0000    0.9000    0.9474        30\n",
      "          18     0.8182    0.9000    0.8571        30\n",
      "          19     1.0000    1.0000    1.0000        30\n",
      "          20     1.0000    0.9000    0.9474        30\n",
      "          21     0.9677    1.0000    0.9836        30\n",
      "          22     1.0000    0.9333    0.9655        30\n",
      "          23     1.0000    0.9667    0.9831        30\n",
      "          24     1.0000    0.8667    0.9286        30\n",
      "          25     1.0000    0.9667    0.9831        30\n",
      "          26     0.8667    0.8667    0.8667        30\n",
      "          27     1.0000    1.0000    1.0000        30\n",
      "          28     0.9677    1.0000    0.9836        30\n",
      "          29     1.0000    1.0000    1.0000        30\n",
      "          30     0.9677    1.0000    0.9836        30\n",
      "          31     0.9091    1.0000    0.9524        30\n",
      "          32     1.0000    0.9667    0.9831        30\n",
      "          33     1.0000    1.0000    1.0000        30\n",
      "          34     1.0000    1.0000    1.0000        30\n",
      "          35     0.9355    0.9667    0.9508        30\n",
      "          36     1.0000    0.9333    0.9655        30\n",
      "          37     0.9677    1.0000    0.9836        30\n",
      "          38     0.9667    0.9667    0.9667        30\n",
      "          39     1.0000    1.0000    1.0000        30\n",
      "          40     0.9667    0.9667    0.9667        30\n",
      "          41     1.0000    1.0000    1.0000        30\n",
      "          42     0.9677    1.0000    0.9836        30\n",
      "          43     1.0000    1.0000    1.0000        30\n",
      "          44     0.9677    1.0000    0.9836        30\n",
      "          45     0.9375    1.0000    0.9677        30\n",
      "          46     0.9677    1.0000    0.9836        30\n",
      "          47     1.0000    1.0000    1.0000        30\n",
      "          48     1.0000    0.9667    0.9831        30\n",
      "          49     0.9062    0.9667    0.9355        30\n",
      "          50     0.9000    0.9000    0.9000        30\n",
      "          51     1.0000    1.0000    1.0000        30\n",
      "          52     1.0000    1.0000    1.0000        30\n",
      "          53     1.0000    0.9333    0.9655        30\n",
      "          54     1.0000    1.0000    1.0000        30\n",
      "          55     0.9062    0.9667    0.9355        30\n",
      "          56     1.0000    1.0000    1.0000        30\n",
      "          57     0.9667    0.9667    0.9667        30\n",
      "          58     1.0000    0.9000    0.9474        30\n",
      "          59     0.9310    0.9000    0.9153        30\n",
      "          60     1.0000    0.9000    0.9474        30\n",
      "          61     0.9375    1.0000    0.9677        30\n",
      "          62     0.9655    0.9333    0.9492        30\n",
      "          63     0.9375    1.0000    0.9677        30\n",
      "          64     1.0000    1.0000    1.0000        30\n",
      "          65     0.9200    0.7667    0.8364        30\n",
      "          66     0.9355    0.9667    0.9508        30\n",
      "          67     0.9615    0.8333    0.8929        30\n",
      "          68     1.0000    0.9667    0.9831        30\n",
      "          69     0.8571    1.0000    0.9231        30\n",
      "          70     0.8966    0.8667    0.8814        30\n",
      "          71     1.0000    1.0000    1.0000        30\n",
      "          72     0.9231    0.8000    0.8571        30\n",
      "          73     0.9667    0.9667    0.9667        30\n",
      "          74     0.9677    1.0000    0.9836        30\n",
      "          75     0.9062    0.9667    0.9355        30\n",
      "          76     0.8286    0.9667    0.8923        30\n",
      "          77     1.0000    0.9667    0.9831        30\n",
      "          78     0.9655    0.9333    0.9492        30\n",
      "          79     1.0000    1.0000    1.0000        30\n",
      "          80     1.0000    1.0000    1.0000        30\n",
      "          81     1.0000    0.9000    0.9474        30\n",
      "          82     1.0000    1.0000    1.0000        30\n",
      "          83     0.9286    0.8667    0.8966        30\n",
      "          84     1.0000    1.0000    1.0000        30\n",
      "          85     0.8929    0.8333    0.8621        30\n",
      "          86     1.0000    0.8333    0.9091        30\n",
      "          87     1.0000    1.0000    1.0000        30\n",
      "          88     0.9333    0.9333    0.9333        30\n",
      "          89     1.0000    1.0000    1.0000        30\n",
      "          90     1.0000    0.9667    0.9831        30\n",
      "          91     0.9643    0.9000    0.9310        30\n",
      "          92     1.0000    1.0000    1.0000        30\n",
      "          93     0.9333    0.9333    0.9333        30\n",
      "          94     1.0000    0.9667    0.9831        30\n",
      "          95     0.8529    0.9667    0.9062        30\n",
      "          96     1.0000    0.9667    0.9831        30\n",
      "          97     0.9375    1.0000    0.9677        30\n",
      "          98     0.9677    1.0000    0.9836        30\n",
      "          99     0.9655    0.9333    0.9492        30\n",
      "         100     0.9062    0.9667    0.9355        30\n",
      "         101     0.9333    0.9333    0.9333        30\n",
      "         102     0.9032    0.9333    0.9180        30\n",
      "         103     1.0000    1.0000    1.0000        30\n",
      "         104     0.9091    1.0000    0.9524        30\n",
      "         105     0.9667    0.9667    0.9667        30\n",
      "         106     0.9677    1.0000    0.9836        30\n",
      "         107     1.0000    1.0000    1.0000        30\n",
      "         108     0.9667    0.9667    0.9667        30\n",
      "         109     0.9677    1.0000    0.9836        30\n",
      "         110     0.9655    0.9333    0.9492        30\n",
      "         111     0.8529    0.9667    0.9062        30\n",
      "         112     1.0000    0.9333    0.9655        30\n",
      "         113     1.0000    0.9667    0.9831        30\n",
      "         114     0.9643    0.9000    0.9310        30\n",
      "         115     1.0000    1.0000    1.0000        30\n",
      "         116     1.0000    0.9667    0.9831        30\n",
      "         117     1.0000    0.8667    0.9286        30\n",
      "         118     0.9643    0.9000    0.9310        30\n",
      "         119     0.9355    0.9667    0.9508        30\n",
      "         120     0.9667    0.9667    0.9667        30\n",
      "         121     1.0000    1.0000    1.0000        30\n",
      "         122     0.8333    0.8333    0.8333        30\n",
      "         123     1.0000    0.9000    0.9474        30\n",
      "         124     1.0000    0.9667    0.9831        30\n",
      "         125     0.9630    0.8667    0.9123        30\n",
      "         126     0.8824    1.0000    0.9375        30\n",
      "         127     0.9062    0.9667    0.9355        30\n",
      "         128     1.0000    1.0000    1.0000        30\n",
      "         129     0.9333    0.9333    0.9333        30\n",
      "         130     1.0000    1.0000    1.0000        30\n",
      "         131     0.9655    0.9333    0.9492        30\n",
      "         132     1.0000    1.0000    1.0000        30\n",
      "         133     0.9091    1.0000    0.9524        30\n",
      "         134     0.9677    1.0000    0.9836        30\n",
      "         135     0.9091    1.0000    0.9524        30\n",
      "         136     1.0000    0.9667    0.9831        30\n",
      "         137     1.0000    0.9667    0.9831        30\n",
      "         138     1.0000    0.8000    0.8889        30\n",
      "         139     1.0000    1.0000    1.0000        30\n",
      "         140     0.6875    0.7333    0.7097        30\n",
      "         141     0.7941    0.9000    0.8438        30\n",
      "         142     0.9677    1.0000    0.9836        30\n",
      "         143     1.0000    0.9667    0.9831        30\n",
      "         144     1.0000    1.0000    1.0000        30\n",
      "         145     0.9677    1.0000    0.9836        30\n",
      "         146     0.9630    0.8667    0.9123        30\n",
      "         147     1.0000    1.0000    1.0000        30\n",
      "         148     1.0000    1.0000    1.0000        30\n",
      "         149     0.9600    0.8000    0.8727        30\n",
      "         150     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9551      4500\n",
      "   macro avg     0.9569    0.9488    0.9518      4500\n",
      "weighted avg     0.9633    0.9551    0.9582      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X,y = df_test_inscope[emb_cols].values, df_test_inscope['label'].values\n",
    "pred_probs = mlp_small.predict(X)\n",
    "preds = [np. argmax(p) for p in pred_probs]\n",
    "print(classification_report(y, preds,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c0034f",
   "metadata": {},
   "source": [
    "## OutofScope Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b123dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         0\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "           7     0.0000    0.0000    0.0000         0\n",
      "           9     0.0000    0.0000    0.0000         0\n",
      "          10     0.0000    0.0000    0.0000         0\n",
      "          11     0.0000    0.0000    0.0000         0\n",
      "          14     0.0000    0.0000    0.0000         0\n",
      "          16     0.0000    0.0000    0.0000         0\n",
      "          17     0.0000    0.0000    0.0000         0\n",
      "          18     0.0000    0.0000    0.0000         0\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          22     0.0000    0.0000    0.0000         0\n",
      "          23     0.0000    0.0000    0.0000         0\n",
      "          25     0.0000    0.0000    0.0000         0\n",
      "          26     0.0000    0.0000    0.0000         0\n",
      "          27     0.0000    0.0000    0.0000         0\n",
      "          28     0.0000    0.0000    0.0000         0\n",
      "          32     0.0000    0.0000    0.0000         0\n",
      "          33     0.0000    0.0000    0.0000         0\n",
      "          34     0.0000    0.0000    0.0000         0\n",
      "          35     0.0000    0.0000    0.0000         0\n",
      "          36     0.0000    0.0000    0.0000         0\n",
      "          38     0.0000    0.0000    0.0000         0\n",
      "          39     0.0000    0.0000    0.0000         0\n",
      "          40     0.0000    0.0000    0.0000         0\n",
      "          41     0.0000    0.0000    0.0000         0\n",
      "          42     0.0000    0.0000    0.0000         0\n",
      "          43     0.0000    0.0000    0.0000         0\n",
      "          44     0.0000    0.0000    0.0000         0\n",
      "          45     0.0000    0.0000    0.0000         0\n",
      "          46     0.0000    0.0000    0.0000         0\n",
      "          47     0.0000    0.0000    0.0000         0\n",
      "          49     0.0000    0.0000    0.0000         0\n",
      "          50     0.0000    0.0000    0.0000         0\n",
      "          51     0.0000    0.0000    0.0000         0\n",
      "          52     0.0000    0.0000    0.0000         0\n",
      "          53     0.0000    0.0000    0.0000         0\n",
      "          55     0.0000    0.0000    0.0000         0\n",
      "          56     0.0000    0.0000    0.0000         0\n",
      "          57     0.0000    0.0000    0.0000         0\n",
      "          58     0.0000    0.0000    0.0000         0\n",
      "          59     0.0000    0.0000    0.0000         0\n",
      "          60     0.0000    0.0000    0.0000         0\n",
      "          61     0.0000    0.0000    0.0000         0\n",
      "          62     0.0000    0.0000    0.0000         0\n",
      "          63     0.0000    0.0000    0.0000         0\n",
      "          64     0.0000    0.0000    0.0000         0\n",
      "          65     0.0000    0.0000    0.0000         0\n",
      "          67     0.0000    0.0000    0.0000         0\n",
      "          69     0.0000    0.0000    0.0000         0\n",
      "          70     0.0000    0.0000    0.0000         0\n",
      "          73     0.0000    0.0000    0.0000         0\n",
      "          75     0.0000    0.0000    0.0000         0\n",
      "          76     0.0000    0.0000    0.0000         0\n",
      "          77     0.0000    0.0000    0.0000         0\n",
      "          79     0.0000    0.0000    0.0000         0\n",
      "          80     0.0000    0.0000    0.0000         0\n",
      "          81     0.0000    0.0000    0.0000         0\n",
      "          82     0.0000    0.0000    0.0000         0\n",
      "          83     0.0000    0.0000    0.0000         0\n",
      "          84     0.0000    0.0000    0.0000         0\n",
      "          86     0.0000    0.0000    0.0000         0\n",
      "          87     0.0000    0.0000    0.0000         0\n",
      "          88     0.0000    0.0000    0.0000         0\n",
      "          89     0.0000    0.0000    0.0000         0\n",
      "          90     0.0000    0.0000    0.0000         0\n",
      "          91     0.0000    0.0000    0.0000         0\n",
      "          92     0.0000    0.0000    0.0000         0\n",
      "          93     0.0000    0.0000    0.0000         0\n",
      "          94     0.0000    0.0000    0.0000         0\n",
      "          96     0.0000    0.0000    0.0000         0\n",
      "          97     0.0000    0.0000    0.0000         0\n",
      "          98     0.0000    0.0000    0.0000         0\n",
      "          99     0.0000    0.0000    0.0000         0\n",
      "         100     0.0000    0.0000    0.0000         0\n",
      "         103     0.0000    0.0000    0.0000         0\n",
      "         104     0.0000    0.0000    0.0000         0\n",
      "         106     0.0000    0.0000    0.0000         0\n",
      "         107     0.0000    0.0000    0.0000         0\n",
      "         111     0.0000    0.0000    0.0000         0\n",
      "         114     0.0000    0.0000    0.0000         0\n",
      "         116     0.0000    0.0000    0.0000         0\n",
      "         119     0.0000    0.0000    0.0000         0\n",
      "         120     0.0000    0.0000    0.0000         0\n",
      "         121     0.0000    0.0000    0.0000         0\n",
      "         122     0.0000    0.0000    0.0000         0\n",
      "         123     0.0000    0.0000    0.0000         0\n",
      "         124     0.0000    0.0000    0.0000         0\n",
      "         125     0.0000    0.0000    0.0000         0\n",
      "         126     0.0000    0.0000    0.0000         0\n",
      "         127     0.0000    0.0000    0.0000         0\n",
      "         128     0.0000    0.0000    0.0000         0\n",
      "         129     0.0000    0.0000    0.0000         0\n",
      "         132     0.0000    0.0000    0.0000         0\n",
      "         133     0.0000    0.0000    0.0000         0\n",
      "         135     0.0000    0.0000    0.0000         0\n",
      "         136     0.0000    0.0000    0.0000         0\n",
      "         137     0.0000    0.0000    0.0000         0\n",
      "         138     0.0000    0.0000    0.0000         0\n",
      "         140     0.0000    0.0000    0.0000         0\n",
      "         141     0.0000    0.0000    0.0000         0\n",
      "         142     0.0000    0.0000    0.0000         0\n",
      "         143     0.0000    0.0000    0.0000         0\n",
      "         145     0.0000    0.0000    0.0000         0\n",
      "         146     0.0000    0.0000    0.0000         0\n",
      "         148     0.0000    0.0000    0.0000         0\n",
      "         149     0.0000    0.0000    0.0000         0\n",
      "         150     1.0000    0.6410    0.7812      1000\n",
      "\n",
      "    accuracy                         0.6410      1000\n",
      "   macro avg     0.0090    0.0058    0.0070      1000\n",
      "weighted avg     1.0000    0.6410    0.7812      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X,y = df_test_oos[emb_cols].values, df_test_oos['label'].values\n",
    "pred_probs = mlp_small.predict(X)\n",
    "preds = [np. argmax(p) for p in pred_probs]\n",
    "print(classification_report(y, preds,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914d25e",
   "metadata": {},
   "source": [
    "# Automate All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3e4c8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/clinic/data_full/',\n",
       " '../data/clinic/data_imbalanced/',\n",
       " '../data/clinic/data_oos_plus/',\n",
       " '../data/clinic/data_small/']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs = sorted(glob(DATA_FOLDER +\"*/\"))\n",
    "dirs\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2775b07b",
   "metadata": {},
   "source": [
    "# Parameters:\n",
    "#https://github.com/clinc/oos-eval/blob/master/hyperparameters.csv\n",
    "\n",
    "Full\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       400\t       use\t        1\t      0\t\n",
    "\n",
    "Imbalanced\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        64      \t0\n",
    "            \n",
    "OOS+\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        16      \t0.1\t\n",
    "\n",
    "Small\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        1\t      0.1\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "59908529",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mlp_full, mlp_imbalanced, mlp_oss_plus, mlp_small]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "842deed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes =[1, 64,16,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "37dced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clf_report(model, dt):\n",
    "    X,y = dt[emb_cols].values, dt['label'].values\n",
    "    pred_probs = model.predict(X)\n",
    "    preds = [np. argmax(p) for p in pred_probs]\n",
    "    print(classification_report(y, preds,digits=4))\n",
    "\n",
    "def train_evaulate_model(directory, model, batch_size=1): \n",
    "    print(directory)\n",
    "    df_train = pd.concat([ pd.read_csv(directory + 'train_with_use_emb.csv'),\n",
    "                           pd.read_csv(directory + 'oos_train_with_use_emb.csv')]\n",
    "                    ).reset_index()\n",
    "    \n",
    "    df_valid = pd.concat([ pd.read_csv(directory + 'val_with_use_emb.csv'),\n",
    "                           pd.read_csv(directory + 'oos_val_with_use_emb.csv')]\n",
    "                    ).reset_index()\n",
    "    df_test_inscope = pd.read_csv(directory + 'test_with_use_emb.csv')\n",
    "    df_test_oos = pd.read_csv(directory + 'oos_test_with_use_emb.csv')\n",
    "    \n",
    "    model.fit(df_train[emb_cols].values, \n",
    "              df_train['label'].values,\n",
    "              batch_size = batch_size, \n",
    "              epochs=100, \n",
    "              validation_data=(df_valid[emb_cols].values, df_valid['label'].values),\n",
    "              callbacks =[earlystopping],            \n",
    "              verbose=0)\n",
    "   \n",
    "    print('Inscope')\n",
    "    print_clf_report(model, df_test_inscope)\n",
    "    \n",
    "    print('Out of Scope')\n",
    "    print_clf_report(model, df_test_oos)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c89b40f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/clinic/data_full/\n",
      "Inscope\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9667    0.9831        30\n",
      "           1     1.0000    0.9000    0.9474        30\n",
      "           2     1.0000    0.9000    0.9474        30\n",
      "           3     0.9667    0.9667    0.9667        30\n",
      "           4     1.0000    1.0000    1.0000        30\n",
      "           5     0.9667    0.9667    0.9667        30\n",
      "           6     1.0000    0.9333    0.9655        30\n",
      "           7     1.0000    1.0000    1.0000        30\n",
      "           8     1.0000    0.9000    0.9474        30\n",
      "           9     0.9091    1.0000    0.9524        30\n",
      "          10     0.9000    0.9000    0.9000        30\n",
      "          11     0.8788    0.9667    0.9206        30\n",
      "          12     1.0000    0.9667    0.9831        30\n",
      "          13     1.0000    1.0000    1.0000        30\n",
      "          14     0.8333    1.0000    0.9091        30\n",
      "          15     1.0000    1.0000    1.0000        30\n",
      "          16     0.9677    1.0000    0.9836        30\n",
      "          17     1.0000    0.9000    0.9474        30\n",
      "          18     0.8438    0.9000    0.8710        30\n",
      "          19     1.0000    1.0000    1.0000        30\n",
      "          20     0.9643    0.9000    0.9310        30\n",
      "          21     1.0000    1.0000    1.0000        30\n",
      "          22     0.9000    0.9000    0.9000        30\n",
      "          23     1.0000    0.9667    0.9831        30\n",
      "          24     0.8056    0.9667    0.8788        30\n",
      "          25     0.9677    1.0000    0.9836        30\n",
      "          26     0.9286    0.8667    0.8966        30\n",
      "          27     1.0000    1.0000    1.0000        30\n",
      "          28     0.9677    1.0000    0.9836        30\n",
      "          29     1.0000    1.0000    1.0000        30\n",
      "          30     0.9375    1.0000    0.9677        30\n",
      "          31     0.9677    1.0000    0.9836        30\n",
      "          32     1.0000    0.9667    0.9831        30\n",
      "          33     1.0000    1.0000    1.0000        30\n",
      "          34     1.0000    1.0000    1.0000        30\n",
      "          35     0.9333    0.9333    0.9333        30\n",
      "          36     1.0000    0.9667    0.9831        30\n",
      "          37     1.0000    1.0000    1.0000        30\n",
      "          38     0.9000    0.9000    0.9000        30\n",
      "          39     1.0000    1.0000    1.0000        30\n",
      "          40     0.9286    0.8667    0.8966        30\n",
      "          41     1.0000    1.0000    1.0000        30\n",
      "          42     0.9375    1.0000    0.9677        30\n",
      "          43     1.0000    1.0000    1.0000        30\n",
      "          44     0.9677    1.0000    0.9836        30\n",
      "          45     1.0000    0.9000    0.9474        30\n",
      "          46     1.0000    1.0000    1.0000        30\n",
      "          47     1.0000    0.9333    0.9655        30\n",
      "          48     1.0000    1.0000    1.0000        30\n",
      "          49     0.9091    1.0000    0.9524        30\n",
      "          50     0.8485    0.9333    0.8889        30\n",
      "          51     1.0000    1.0000    1.0000        30\n",
      "          52     0.9677    1.0000    0.9836        30\n",
      "          53     1.0000    0.9667    0.9831        30\n",
      "          54     0.9677    1.0000    0.9836        30\n",
      "          55     0.9355    0.9667    0.9508        30\n",
      "          56     0.9375    1.0000    0.9677        30\n",
      "          57     0.9355    0.9667    0.9508        30\n",
      "          58     0.9667    0.9667    0.9667        30\n",
      "          59     0.9630    0.8667    0.9123        30\n",
      "          60     1.0000    0.8667    0.9286        30\n",
      "          61     0.8571    1.0000    0.9231        30\n",
      "          62     0.9643    0.9000    0.9310        30\n",
      "          63     0.9375    1.0000    0.9677        30\n",
      "          64     1.0000    1.0000    1.0000        30\n",
      "          65     0.8519    0.7667    0.8070        30\n",
      "          66     0.9655    0.9333    0.9492        30\n",
      "          67     0.9286    0.8667    0.8966        30\n",
      "          68     1.0000    0.9667    0.9831        30\n",
      "          69     0.9032    0.9333    0.9180        30\n",
      "          70     0.8214    0.7667    0.7931        30\n",
      "          71     1.0000    1.0000    1.0000        30\n",
      "          72     0.9259    0.8333    0.8772        30\n",
      "          73     0.9333    0.9333    0.9333        30\n",
      "          74     0.9091    1.0000    0.9524        30\n",
      "          75     0.9032    0.9333    0.9180        30\n",
      "          76     0.8529    0.9667    0.9062        30\n",
      "          77     1.0000    1.0000    1.0000        30\n",
      "          78     0.9667    0.9667    0.9667        30\n",
      "          79     1.0000    0.9667    0.9831        30\n",
      "          80     0.9677    1.0000    0.9836        30\n",
      "          81     1.0000    0.8667    0.9286        30\n",
      "          82     1.0000    1.0000    1.0000        30\n",
      "          83     0.9091    1.0000    0.9524        30\n",
      "          84     1.0000    1.0000    1.0000        30\n",
      "          85     0.8333    0.8333    0.8333        30\n",
      "          86     0.9643    0.9000    0.9310        30\n",
      "          87     1.0000    0.9667    0.9831        30\n",
      "          88     0.9062    0.9667    0.9355        30\n",
      "          89     0.9375    1.0000    0.9677        30\n",
      "          90     1.0000    1.0000    1.0000        30\n",
      "          91     0.9286    0.8667    0.8966        30\n",
      "          92     0.9677    1.0000    0.9836        30\n",
      "          93     1.0000    0.9667    0.9831        30\n",
      "          94     1.0000    1.0000    1.0000        30\n",
      "          95     0.9062    0.9667    0.9355        30\n",
      "          96     1.0000    0.8667    0.9286        30\n",
      "          97     0.8485    0.9333    0.8889        30\n",
      "          98     0.8824    1.0000    0.9375        30\n",
      "          99     0.9310    0.9000    0.9153        30\n",
      "         100     0.8529    0.9667    0.9062        30\n",
      "         101     0.8929    0.8333    0.8621        30\n",
      "         102     0.9667    0.9667    0.9667        30\n",
      "         103     1.0000    1.0000    1.0000        30\n",
      "         104     0.9643    0.9000    0.9310        30\n",
      "         105     0.9667    0.9667    0.9667        30\n",
      "         106     0.9062    0.9667    0.9355        30\n",
      "         107     1.0000    1.0000    1.0000        30\n",
      "         108     1.0000    1.0000    1.0000        30\n",
      "         109     0.9667    0.9667    0.9667        30\n",
      "         110     1.0000    0.9667    0.9831        30\n",
      "         111     0.8235    0.9333    0.8750        30\n",
      "         112     0.9667    0.9667    0.9667        30\n",
      "         113     1.0000    0.9667    0.9831        30\n",
      "         114     0.9333    0.9333    0.9333        30\n",
      "         115     0.9677    1.0000    0.9836        30\n",
      "         116     1.0000    0.9667    0.9831        30\n",
      "         117     1.0000    0.9667    0.9831        30\n",
      "         118     0.9667    0.9667    0.9667        30\n",
      "         119     1.0000    0.8000    0.8889        30\n",
      "         120     0.9333    0.9333    0.9333        30\n",
      "         121     1.0000    1.0000    1.0000        30\n",
      "         122     1.0000    0.8333    0.9091        30\n",
      "         123     0.9091    1.0000    0.9524        30\n",
      "         124     1.0000    1.0000    1.0000        30\n",
      "         125     0.9600    0.8000    0.8727        30\n",
      "         126     0.9600    0.8000    0.8727        30\n",
      "         127     0.9655    0.9333    0.9492        30\n",
      "         128     1.0000    1.0000    1.0000        30\n",
      "         129     0.9286    0.8667    0.8966        30\n",
      "         130     0.9667    0.9667    0.9667        30\n",
      "         131     0.9375    1.0000    0.9677        30\n",
      "         132     1.0000    1.0000    1.0000        30\n",
      "         133     1.0000    1.0000    1.0000        30\n",
      "         134     1.0000    1.0000    1.0000        30\n",
      "         135     0.9375    1.0000    0.9677        30\n",
      "         136     1.0000    0.9333    0.9655        30\n",
      "         137     1.0000    0.9667    0.9831        30\n",
      "         138     0.7714    0.9000    0.8308        30\n",
      "         139     1.0000    1.0000    1.0000        30\n",
      "         140     0.8387    0.8667    0.8525        30\n",
      "         141     0.7297    0.9000    0.8060        30\n",
      "         142     0.9677    1.0000    0.9836        30\n",
      "         143     1.0000    0.9667    0.9831        30\n",
      "         144     1.0000    1.0000    1.0000        30\n",
      "         145     0.9677    1.0000    0.9836        30\n",
      "         146     1.0000    0.9333    0.9655        30\n",
      "         147     1.0000    1.0000    1.0000        30\n",
      "         148     1.0000    1.0000    1.0000        30\n",
      "         149     0.9231    0.8000    0.8571        30\n",
      "         150     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9531      4500\n",
      "   macro avg     0.9495    0.9468    0.9470      4500\n",
      "weighted avg     0.9559    0.9531    0.9533      4500\n",
      "\n",
      "Out of Scope\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         0\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         0\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "           7     0.0000    0.0000    0.0000         0\n",
      "           9     0.0000    0.0000    0.0000         0\n",
      "          10     0.0000    0.0000    0.0000         0\n",
      "          11     0.0000    0.0000    0.0000         0\n",
      "          13     0.0000    0.0000    0.0000         0\n",
      "          14     0.0000    0.0000    0.0000         0\n",
      "          16     0.0000    0.0000    0.0000         0\n",
      "          17     0.0000    0.0000    0.0000         0\n",
      "          18     0.0000    0.0000    0.0000         0\n",
      "          19     0.0000    0.0000    0.0000         0\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          22     0.0000    0.0000    0.0000         0\n",
      "          23     0.0000    0.0000    0.0000         0\n",
      "          24     0.0000    0.0000    0.0000         0\n",
      "          25     0.0000    0.0000    0.0000         0\n",
      "          26     0.0000    0.0000    0.0000         0\n",
      "          27     0.0000    0.0000    0.0000         0\n",
      "          28     0.0000    0.0000    0.0000         0\n",
      "          30     0.0000    0.0000    0.0000         0\n",
      "          31     0.0000    0.0000    0.0000         0\n",
      "          32     0.0000    0.0000    0.0000         0\n",
      "          34     0.0000    0.0000    0.0000         0\n",
      "          35     0.0000    0.0000    0.0000         0\n",
      "          36     0.0000    0.0000    0.0000         0\n",
      "          37     0.0000    0.0000    0.0000         0\n",
      "          38     0.0000    0.0000    0.0000         0\n",
      "          39     0.0000    0.0000    0.0000         0\n",
      "          40     0.0000    0.0000    0.0000         0\n",
      "          41     0.0000    0.0000    0.0000         0\n",
      "          42     0.0000    0.0000    0.0000         0\n",
      "          43     0.0000    0.0000    0.0000         0\n",
      "          46     0.0000    0.0000    0.0000         0\n",
      "          47     0.0000    0.0000    0.0000         0\n",
      "          48     0.0000    0.0000    0.0000         0\n",
      "          49     0.0000    0.0000    0.0000         0\n",
      "          50     0.0000    0.0000    0.0000         0\n",
      "          51     0.0000    0.0000    0.0000         0\n",
      "          52     0.0000    0.0000    0.0000         0\n",
      "          53     0.0000    0.0000    0.0000         0\n",
      "          54     0.0000    0.0000    0.0000         0\n",
      "          55     0.0000    0.0000    0.0000         0\n",
      "          56     0.0000    0.0000    0.0000         0\n",
      "          57     0.0000    0.0000    0.0000         0\n",
      "          58     0.0000    0.0000    0.0000         0\n",
      "          59     0.0000    0.0000    0.0000         0\n",
      "          61     0.0000    0.0000    0.0000         0\n",
      "          63     0.0000    0.0000    0.0000         0\n",
      "          64     0.0000    0.0000    0.0000         0\n",
      "          65     0.0000    0.0000    0.0000         0\n",
      "          67     0.0000    0.0000    0.0000         0\n",
      "          69     0.0000    0.0000    0.0000         0\n",
      "          70     0.0000    0.0000    0.0000         0\n",
      "          71     0.0000    0.0000    0.0000         0\n",
      "          72     0.0000    0.0000    0.0000         0\n",
      "          74     0.0000    0.0000    0.0000         0\n",
      "          75     0.0000    0.0000    0.0000         0\n",
      "          76     0.0000    0.0000    0.0000         0\n",
      "          77     0.0000    0.0000    0.0000         0\n",
      "          78     0.0000    0.0000    0.0000         0\n",
      "          79     0.0000    0.0000    0.0000         0\n",
      "          80     0.0000    0.0000    0.0000         0\n",
      "          81     0.0000    0.0000    0.0000         0\n",
      "          82     0.0000    0.0000    0.0000         0\n",
      "          83     0.0000    0.0000    0.0000         0\n",
      "          84     0.0000    0.0000    0.0000         0\n",
      "          85     0.0000    0.0000    0.0000         0\n",
      "          86     0.0000    0.0000    0.0000         0\n",
      "          87     0.0000    0.0000    0.0000         0\n",
      "          88     0.0000    0.0000    0.0000         0\n",
      "          89     0.0000    0.0000    0.0000         0\n",
      "          90     0.0000    0.0000    0.0000         0\n",
      "          92     0.0000    0.0000    0.0000         0\n",
      "          93     0.0000    0.0000    0.0000         0\n",
      "          94     0.0000    0.0000    0.0000         0\n",
      "          97     0.0000    0.0000    0.0000         0\n",
      "          98     0.0000    0.0000    0.0000         0\n",
      "          99     0.0000    0.0000    0.0000         0\n",
      "         104     0.0000    0.0000    0.0000         0\n",
      "         105     0.0000    0.0000    0.0000         0\n",
      "         106     0.0000    0.0000    0.0000         0\n",
      "         107     0.0000    0.0000    0.0000         0\n",
      "         109     0.0000    0.0000    0.0000         0\n",
      "         111     0.0000    0.0000    0.0000         0\n",
      "         112     0.0000    0.0000    0.0000         0\n",
      "         114     0.0000    0.0000    0.0000         0\n",
      "         116     0.0000    0.0000    0.0000         0\n",
      "         118     0.0000    0.0000    0.0000         0\n",
      "         119     0.0000    0.0000    0.0000         0\n",
      "         120     0.0000    0.0000    0.0000         0\n",
      "         122     0.0000    0.0000    0.0000         0\n",
      "         123     0.0000    0.0000    0.0000         0\n",
      "         124     0.0000    0.0000    0.0000         0\n",
      "         125     0.0000    0.0000    0.0000         0\n",
      "         127     0.0000    0.0000    0.0000         0\n",
      "         128     0.0000    0.0000    0.0000         0\n",
      "         129     0.0000    0.0000    0.0000         0\n",
      "         131     0.0000    0.0000    0.0000         0\n",
      "         132     0.0000    0.0000    0.0000         0\n",
      "         133     0.0000    0.0000    0.0000         0\n",
      "         135     0.0000    0.0000    0.0000         0\n",
      "         136     0.0000    0.0000    0.0000         0\n",
      "         137     0.0000    0.0000    0.0000         0\n",
      "         138     0.0000    0.0000    0.0000         0\n",
      "         139     0.0000    0.0000    0.0000         0\n",
      "         140     0.0000    0.0000    0.0000         0\n",
      "         141     0.0000    0.0000    0.0000         0\n",
      "         142     0.0000    0.0000    0.0000         0\n",
      "         145     0.0000    0.0000    0.0000         0\n",
      "         146     0.0000    0.0000    0.0000         0\n",
      "         148     0.0000    0.0000    0.0000         0\n",
      "         149     0.0000    0.0000    0.0000         0\n",
      "         150     1.0000    0.3340    0.5007      1000\n",
      "\n",
      "    accuracy                         0.3340      1000\n",
      "   macro avg     0.0085    0.0028    0.0042      1000\n",
      "weighted avg     1.0000    0.3340    0.5007      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tayfun.tuna/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "376.9124836921692"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "train_evaulate_model(dirs[0], models[0], batch_sizes[0])\n",
    "time()- start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8898b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/clinic/data_imbalanced/\n",
      "Inscope\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9667    0.9831        30\n",
      "           1     0.9286    0.8667    0.8966        30\n",
      "           2     1.0000    0.8667    0.9286        30\n",
      "           3     0.9062    0.9667    0.9355        30\n",
      "           4     1.0000    1.0000    1.0000        30\n",
      "           5     0.9655    0.9333    0.9492        30\n",
      "           6     1.0000    0.9000    0.9474        30\n",
      "           7     1.0000    1.0000    1.0000        30\n",
      "           8     1.0000    1.0000    1.0000        30\n",
      "           9     0.9677    1.0000    0.9836        30\n",
      "          10     0.9032    0.9333    0.9180        30\n",
      "          11     0.8485    0.9333    0.8889        30\n",
      "          12     1.0000    0.9667    0.9831        30\n",
      "          13     1.0000    1.0000    1.0000        30\n",
      "          14     0.8750    0.9333    0.9032        30\n",
      "          15     0.9375    1.0000    0.9677        30\n",
      "          16     0.9630    0.8667    0.9123        30\n",
      "          17     1.0000    0.9000    0.9474        30\n",
      "          18     0.8710    0.9000    0.8852        30\n",
      "          19     1.0000    1.0000    1.0000        30\n",
      "          20     1.0000    0.9000    0.9474        30\n",
      "          21     1.0000    1.0000    1.0000        30\n",
      "          22     0.9000    0.9000    0.9000        30\n",
      "          23     1.0000    1.0000    1.0000        30\n",
      "          24     0.9091    1.0000    0.9524        30\n",
      "          25     1.0000    0.9667    0.9831        30\n",
      "          26     0.9310    0.9000    0.9153        30\n",
      "          27     1.0000    1.0000    1.0000        30\n",
      "          28     1.0000    1.0000    1.0000        30\n",
      "          29     1.0000    1.0000    1.0000        30\n",
      "          30     0.9375    1.0000    0.9677        30\n",
      "          31     0.9677    1.0000    0.9836        30\n",
      "          32     1.0000    0.9667    0.9831        30\n",
      "          33     1.0000    0.9667    0.9831        30\n",
      "          34     1.0000    0.9667    0.9831        30\n",
      "          35     0.9000    0.9000    0.9000        30\n",
      "          36     1.0000    0.9667    0.9831        30\n",
      "          37     1.0000    1.0000    1.0000        30\n",
      "          38     0.9000    0.9000    0.9000        30\n",
      "          39     1.0000    0.9667    0.9831        30\n",
      "          40     0.9630    0.8667    0.9123        30\n",
      "          41     1.0000    1.0000    1.0000        30\n",
      "          42     0.9375    1.0000    0.9677        30\n",
      "          43     1.0000    1.0000    1.0000        30\n",
      "          44     0.9091    1.0000    0.9524        30\n",
      "          45     1.0000    1.0000    1.0000        30\n",
      "          46     1.0000    1.0000    1.0000        30\n",
      "          47     1.0000    1.0000    1.0000        30\n",
      "          48     1.0000    0.9667    0.9831        30\n",
      "          49     0.9091    1.0000    0.9524        30\n",
      "          50     0.8286    0.9667    0.8923        30\n",
      "          51     1.0000    1.0000    1.0000        30\n",
      "          52     1.0000    0.9333    0.9655        30\n",
      "          53     1.0000    0.9667    0.9831        30\n",
      "          54     1.0000    1.0000    1.0000        30\n",
      "          55     0.9355    0.9667    0.9508        30\n",
      "          56     0.9677    1.0000    0.9836        30\n",
      "          57     0.9667    0.9667    0.9667        30\n",
      "          58     0.9655    0.9333    0.9492        30\n",
      "          59     0.9630    0.8667    0.9123        30\n",
      "          60     1.0000    0.9333    0.9655        30\n",
      "          61     0.9091    1.0000    0.9524        30\n",
      "          62     0.9643    0.9000    0.9310        30\n",
      "          63     0.9091    1.0000    0.9524        30\n",
      "          64     1.0000    1.0000    1.0000        30\n",
      "          65     0.8571    0.8000    0.8276        30\n",
      "          66     1.0000    0.9667    0.9831        30\n",
      "          67     0.9630    0.8667    0.9123        30\n",
      "          68     1.0000    1.0000    1.0000        30\n",
      "          69     0.8286    0.9667    0.8923        30\n",
      "          70     0.8710    0.9000    0.8852        30\n",
      "          71     1.0000    1.0000    1.0000        30\n",
      "          72     0.9583    0.7667    0.8519        30\n",
      "          73     0.8333    1.0000    0.9091        30\n",
      "          74     1.0000    1.0000    1.0000        30\n",
      "          75     0.8788    0.9667    0.9206        30\n",
      "          76     0.9062    0.9667    0.9355        30\n",
      "          77     1.0000    1.0000    1.0000        30\n",
      "          78     0.9310    0.9000    0.9153        30\n",
      "          79     1.0000    0.9667    0.9831        30\n",
      "          80     1.0000    1.0000    1.0000        30\n",
      "          81     0.9630    0.8667    0.9123        30\n",
      "          82     1.0000    1.0000    1.0000        30\n",
      "          83     0.9355    0.9667    0.9508        30\n",
      "          84     1.0000    1.0000    1.0000        30\n",
      "          85     0.9259    0.8333    0.8772        30\n",
      "          86     0.9643    0.9000    0.9310        30\n",
      "          87     1.0000    1.0000    1.0000        30\n",
      "          88     1.0000    0.8667    0.9286        30\n",
      "          89     0.8824    1.0000    0.9375        30\n",
      "          90     1.0000    1.0000    1.0000        30\n",
      "          91     0.9655    0.9333    0.9492        30\n",
      "          92     0.9375    1.0000    0.9677        30\n",
      "          93     0.9667    0.9667    0.9667        30\n",
      "          94     1.0000    1.0000    1.0000        30\n",
      "          95     0.8710    0.9000    0.8852        30\n",
      "          96     0.9667    0.9667    0.9667        30\n",
      "          97     1.0000    0.9667    0.9831        30\n",
      "          98     0.9677    1.0000    0.9836        30\n",
      "          99     0.9655    0.9333    0.9492        30\n",
      "         100     0.9375    1.0000    0.9677        30\n",
      "         101     0.9032    0.9333    0.9180        30\n",
      "         102     0.9355    0.9667    0.9508        30\n",
      "         103     1.0000    1.0000    1.0000        30\n",
      "         104     0.8286    0.9667    0.8923        30\n",
      "         105     1.0000    0.9000    0.9474        30\n",
      "         106     0.8571    1.0000    0.9231        30\n",
      "         107     1.0000    1.0000    1.0000        30\n",
      "         108     1.0000    1.0000    1.0000        30\n",
      "         109     1.0000    0.9333    0.9655        30\n",
      "         110     0.9677    1.0000    0.9836        30\n",
      "         111     0.8571    1.0000    0.9231        30\n",
      "         112     0.9667    0.9667    0.9667        30\n",
      "         113     0.8571    1.0000    0.9231        30\n",
      "         114     1.0000    0.7667    0.8679        30\n",
      "         115     0.9677    1.0000    0.9836        30\n",
      "         116     1.0000    1.0000    1.0000        30\n",
      "         117     0.9583    0.7667    0.8519        30\n",
      "         118     0.9667    0.9667    0.9667        30\n",
      "         119     0.9667    0.9667    0.9667        30\n",
      "         120     0.9677    1.0000    0.9836        30\n",
      "         121     1.0000    1.0000    1.0000        30\n",
      "         122     0.8889    0.8000    0.8421        30\n",
      "         123     0.9677    1.0000    0.9836        30\n",
      "         124     1.0000    1.0000    1.0000        30\n",
      "         125     0.9630    0.8667    0.9123        30\n",
      "         126     1.0000    0.9333    0.9655        30\n",
      "         127     0.9655    0.9333    0.9492        30\n",
      "         128     1.0000    1.0000    1.0000        30\n",
      "         129     0.9000    0.9000    0.9000        30\n",
      "         130     0.9667    0.9667    0.9667        30\n",
      "         131     0.8824    1.0000    0.9375        30\n",
      "         132     1.0000    1.0000    1.0000        30\n",
      "         133     1.0000    0.9667    0.9831        30\n",
      "         134     1.0000    1.0000    1.0000        30\n",
      "         135     0.9375    1.0000    0.9677        30\n",
      "         136     1.0000    0.9000    0.9474        30\n",
      "         137     1.0000    0.9667    0.9831        30\n",
      "         138     0.9200    0.7667    0.8364        30\n",
      "         139     1.0000    1.0000    1.0000        30\n",
      "         140     0.7931    0.7667    0.7797        30\n",
      "         141     0.7879    0.8667    0.8254        30\n",
      "         142     0.8571    1.0000    0.9231        30\n",
      "         143     0.9667    0.9667    0.9667        30\n",
      "         144     1.0000    1.0000    1.0000        30\n",
      "         145     1.0000    1.0000    1.0000        30\n",
      "         146     0.9286    0.8667    0.8966        30\n",
      "         147     0.9677    1.0000    0.9836        30\n",
      "         148     1.0000    1.0000    1.0000        30\n",
      "         149     0.9286    0.8667    0.8966        30\n",
      "         150     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9542      4500\n",
      "   macro avg     0.9512    0.9479    0.9483      4500\n",
      "weighted avg     0.9576    0.9542    0.9547      4500\n",
      "\n",
      "Out of Scope\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         0\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "           7     0.0000    0.0000    0.0000         0\n",
      "           8     0.0000    0.0000    0.0000         0\n",
      "           9     0.0000    0.0000    0.0000         0\n",
      "          10     0.0000    0.0000    0.0000         0\n",
      "          11     0.0000    0.0000    0.0000         0\n",
      "          13     0.0000    0.0000    0.0000         0\n",
      "          16     0.0000    0.0000    0.0000         0\n",
      "          17     0.0000    0.0000    0.0000         0\n",
      "          18     0.0000    0.0000    0.0000         0\n",
      "          19     0.0000    0.0000    0.0000         0\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          22     0.0000    0.0000    0.0000         0\n",
      "          23     0.0000    0.0000    0.0000         0\n",
      "          24     0.0000    0.0000    0.0000         0\n",
      "          25     0.0000    0.0000    0.0000         0\n",
      "          26     0.0000    0.0000    0.0000         0\n",
      "          27     0.0000    0.0000    0.0000         0\n",
      "          28     0.0000    0.0000    0.0000         0\n",
      "          29     0.0000    0.0000    0.0000         0\n",
      "          30     0.0000    0.0000    0.0000         0\n",
      "          31     0.0000    0.0000    0.0000         0\n",
      "          32     0.0000    0.0000    0.0000         0\n",
      "          33     0.0000    0.0000    0.0000         0\n",
      "          34     0.0000    0.0000    0.0000         0\n",
      "          36     0.0000    0.0000    0.0000         0\n",
      "          38     0.0000    0.0000    0.0000         0\n",
      "          39     0.0000    0.0000    0.0000         0\n",
      "          41     0.0000    0.0000    0.0000         0\n",
      "          42     0.0000    0.0000    0.0000         0\n",
      "          43     0.0000    0.0000    0.0000         0\n",
      "          44     0.0000    0.0000    0.0000         0\n",
      "          45     0.0000    0.0000    0.0000         0\n",
      "          46     0.0000    0.0000    0.0000         0\n",
      "          47     0.0000    0.0000    0.0000         0\n",
      "          48     0.0000    0.0000    0.0000         0\n",
      "          49     0.0000    0.0000    0.0000         0\n",
      "          50     0.0000    0.0000    0.0000         0\n",
      "          51     0.0000    0.0000    0.0000         0\n",
      "          52     0.0000    0.0000    0.0000         0\n",
      "          53     0.0000    0.0000    0.0000         0\n",
      "          54     0.0000    0.0000    0.0000         0\n",
      "          55     0.0000    0.0000    0.0000         0\n",
      "          56     0.0000    0.0000    0.0000         0\n",
      "          57     0.0000    0.0000    0.0000         0\n",
      "          58     0.0000    0.0000    0.0000         0\n",
      "          59     0.0000    0.0000    0.0000         0\n",
      "          61     0.0000    0.0000    0.0000         0\n",
      "          63     0.0000    0.0000    0.0000         0\n",
      "          64     0.0000    0.0000    0.0000         0\n",
      "          65     0.0000    0.0000    0.0000         0\n",
      "          67     0.0000    0.0000    0.0000         0\n",
      "          69     0.0000    0.0000    0.0000         0\n",
      "          70     0.0000    0.0000    0.0000         0\n",
      "          72     0.0000    0.0000    0.0000         0\n",
      "          73     0.0000    0.0000    0.0000         0\n",
      "          74     0.0000    0.0000    0.0000         0\n",
      "          75     0.0000    0.0000    0.0000         0\n",
      "          76     0.0000    0.0000    0.0000         0\n",
      "          77     0.0000    0.0000    0.0000         0\n",
      "          78     0.0000    0.0000    0.0000         0\n",
      "          80     0.0000    0.0000    0.0000         0\n",
      "          81     0.0000    0.0000    0.0000         0\n",
      "          82     0.0000    0.0000    0.0000         0\n",
      "          84     0.0000    0.0000    0.0000         0\n",
      "          86     0.0000    0.0000    0.0000         0\n",
      "          87     0.0000    0.0000    0.0000         0\n",
      "          88     0.0000    0.0000    0.0000         0\n",
      "          89     0.0000    0.0000    0.0000         0\n",
      "          90     0.0000    0.0000    0.0000         0\n",
      "          92     0.0000    0.0000    0.0000         0\n",
      "          93     0.0000    0.0000    0.0000         0\n",
      "          96     0.0000    0.0000    0.0000         0\n",
      "          97     0.0000    0.0000    0.0000         0\n",
      "          98     0.0000    0.0000    0.0000         0\n",
      "          99     0.0000    0.0000    0.0000         0\n",
      "         104     0.0000    0.0000    0.0000         0\n",
      "         106     0.0000    0.0000    0.0000         0\n",
      "         107     0.0000    0.0000    0.0000         0\n",
      "         112     0.0000    0.0000    0.0000         0\n",
      "         113     0.0000    0.0000    0.0000         0\n",
      "         114     0.0000    0.0000    0.0000         0\n",
      "         116     0.0000    0.0000    0.0000         0\n",
      "         119     0.0000    0.0000    0.0000         0\n",
      "         120     0.0000    0.0000    0.0000         0\n",
      "         121     0.0000    0.0000    0.0000         0\n",
      "         122     0.0000    0.0000    0.0000         0\n",
      "         123     0.0000    0.0000    0.0000         0\n",
      "         124     0.0000    0.0000    0.0000         0\n",
      "         125     0.0000    0.0000    0.0000         0\n",
      "         127     0.0000    0.0000    0.0000         0\n",
      "         128     0.0000    0.0000    0.0000         0\n",
      "         130     0.0000    0.0000    0.0000         0\n",
      "         131     0.0000    0.0000    0.0000         0\n",
      "         132     0.0000    0.0000    0.0000         0\n",
      "         133     0.0000    0.0000    0.0000         0\n",
      "         134     0.0000    0.0000    0.0000         0\n",
      "         135     0.0000    0.0000    0.0000         0\n",
      "         137     0.0000    0.0000    0.0000         0\n",
      "         138     0.0000    0.0000    0.0000         0\n",
      "         139     0.0000    0.0000    0.0000         0\n",
      "         140     0.0000    0.0000    0.0000         0\n",
      "         141     0.0000    0.0000    0.0000         0\n",
      "         142     0.0000    0.0000    0.0000         0\n",
      "         145     0.0000    0.0000    0.0000         0\n",
      "         146     0.0000    0.0000    0.0000         0\n",
      "         148     0.0000    0.0000    0.0000         0\n",
      "         149     0.0000    0.0000    0.0000         0\n",
      "         150     1.0000    0.5480    0.7080      1000\n",
      "\n",
      "    accuracy                         0.5480      1000\n",
      "   macro avg     0.0089    0.0049    0.0063      1000\n",
      "weighted avg     1.0000    0.5480    0.7080      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tayfun.tuna/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.265594959259033"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "train_evaulate_model(dirs[1], models[1], batch_sizes[1])\n",
    "time()- start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a5a5a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/clinic/data_oos_plus/\n",
      "Inscope\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9667    0.9831        30\n",
      "           1     1.0000    0.9333    0.9655        30\n",
      "           2     0.9667    0.9667    0.9667        30\n",
      "           3     0.9667    0.9667    0.9667        30\n",
      "           4     1.0000    1.0000    1.0000        30\n",
      "           5     0.9655    0.9333    0.9492        30\n",
      "           6     1.0000    0.9333    0.9655        30\n",
      "           7     1.0000    1.0000    1.0000        30\n",
      "           8     1.0000    0.9667    0.9831        30\n",
      "           9     0.9677    1.0000    0.9836        30\n",
      "          10     0.8750    0.9333    0.9032        30\n",
      "          11     0.8788    0.9667    0.9206        30\n",
      "          12     1.0000    0.9667    0.9831        30\n",
      "          13     1.0000    1.0000    1.0000        30\n",
      "          14     0.8824    1.0000    0.9375        30\n",
      "          15     0.9375    1.0000    0.9677        30\n",
      "          16     0.9677    1.0000    0.9836        30\n",
      "          17     1.0000    0.9333    0.9655        30\n",
      "          18     0.8182    0.9000    0.8571        30\n",
      "          19     1.0000    1.0000    1.0000        30\n",
      "          20     1.0000    0.9000    0.9474        30\n",
      "          21     1.0000    1.0000    1.0000        30\n",
      "          22     0.9643    0.9000    0.9310        30\n",
      "          23     1.0000    1.0000    1.0000        30\n",
      "          24     1.0000    0.9333    0.9655        30\n",
      "          25     1.0000    0.9667    0.9831        30\n",
      "          26     0.9032    0.9333    0.9180        30\n",
      "          27     1.0000    1.0000    1.0000        30\n",
      "          28     0.9677    1.0000    0.9836        30\n",
      "          29     1.0000    1.0000    1.0000        30\n",
      "          30     1.0000    1.0000    1.0000        30\n",
      "          31     0.9677    1.0000    0.9836        30\n",
      "          32     1.0000    0.9667    0.9831        30\n",
      "          33     1.0000    1.0000    1.0000        30\n",
      "          34     1.0000    1.0000    1.0000        30\n",
      "          35     0.9655    0.9333    0.9492        30\n",
      "          36     1.0000    0.9667    0.9831        30\n",
      "          37     1.0000    1.0000    1.0000        30\n",
      "          38     0.9643    0.9000    0.9310        30\n",
      "          39     1.0000    1.0000    1.0000        30\n",
      "          40     0.8529    0.9667    0.9062        30\n",
      "          41     1.0000    1.0000    1.0000        30\n",
      "          42     0.9677    1.0000    0.9836        30\n",
      "          43     1.0000    1.0000    1.0000        30\n",
      "          44     0.9677    1.0000    0.9836        30\n",
      "          45     0.9677    1.0000    0.9836        30\n",
      "          46     1.0000    1.0000    1.0000        30\n",
      "          47     1.0000    0.9667    0.9831        30\n",
      "          48     1.0000    1.0000    1.0000        30\n",
      "          49     0.9375    1.0000    0.9677        30\n",
      "          50     0.9032    0.9333    0.9180        30\n",
      "          51     1.0000    1.0000    1.0000        30\n",
      "          52     1.0000    1.0000    1.0000        30\n",
      "          53     1.0000    0.9667    0.9831        30\n",
      "          54     1.0000    1.0000    1.0000        30\n",
      "          55     0.9677    1.0000    0.9836        30\n",
      "          56     1.0000    1.0000    1.0000        30\n",
      "          57     0.9667    0.9667    0.9667        30\n",
      "          58     0.9643    0.9000    0.9310        30\n",
      "          59     0.9600    0.8000    0.8727        30\n",
      "          60     0.9643    0.9000    0.9310        30\n",
      "          61     0.9667    0.9667    0.9667        30\n",
      "          62     0.9630    0.8667    0.9123        30\n",
      "          63     1.0000    1.0000    1.0000        30\n",
      "          64     1.0000    1.0000    1.0000        30\n",
      "          65     0.9231    0.8000    0.8571        30\n",
      "          66     0.9355    0.9667    0.9508        30\n",
      "          67     0.9643    0.9000    0.9310        30\n",
      "          68     0.9677    1.0000    0.9836        30\n",
      "          69     0.8056    0.9667    0.8788        30\n",
      "          70     0.9259    0.8333    0.8772        30\n",
      "          71     1.0000    1.0000    1.0000        30\n",
      "          72     0.9630    0.8667    0.9123        30\n",
      "          73     0.9375    1.0000    0.9677        30\n",
      "          74     0.9677    1.0000    0.9836        30\n",
      "          75     0.9062    0.9667    0.9355        30\n",
      "          76     0.8529    0.9667    0.9062        30\n",
      "          77     1.0000    0.9667    0.9831        30\n",
      "          78     0.9000    0.9000    0.9000        30\n",
      "          79     1.0000    0.9667    0.9831        30\n",
      "          80     0.9677    1.0000    0.9836        30\n",
      "          81     0.9310    0.9000    0.9153        30\n",
      "          82     1.0000    1.0000    1.0000        30\n",
      "          83     0.9333    0.9333    0.9333        30\n",
      "          84     1.0000    0.9667    0.9831        30\n",
      "          85     0.9310    0.9000    0.9153        30\n",
      "          86     0.9655    0.9333    0.9492        30\n",
      "          87     1.0000    1.0000    1.0000        30\n",
      "          88     1.0000    0.9000    0.9474        30\n",
      "          89     1.0000    1.0000    1.0000        30\n",
      "          90     1.0000    0.9667    0.9831        30\n",
      "          91     0.9643    0.9000    0.9310        30\n",
      "          92     0.9677    1.0000    0.9836        30\n",
      "          93     0.9355    0.9667    0.9508        30\n",
      "          94     1.0000    1.0000    1.0000        30\n",
      "          95     0.8788    0.9667    0.9206        30\n",
      "          96     0.9667    0.9667    0.9667        30\n",
      "          97     0.9667    0.9667    0.9667        30\n",
      "          98     0.9677    1.0000    0.9836        30\n",
      "          99     0.9677    1.0000    0.9836        30\n",
      "         100     0.9375    1.0000    0.9677        30\n",
      "         101     0.9032    0.9333    0.9180        30\n",
      "         102     0.9062    0.9667    0.9355        30\n",
      "         103     1.0000    1.0000    1.0000        30\n",
      "         104     0.8788    0.9667    0.9206        30\n",
      "         105     0.9375    1.0000    0.9677        30\n",
      "         106     0.9091    1.0000    0.9524        30\n",
      "         107     1.0000    1.0000    1.0000        30\n",
      "         108     1.0000    1.0000    1.0000        30\n",
      "         109     1.0000    0.9333    0.9655        30\n",
      "         110     1.0000    0.9333    0.9655        30\n",
      "         111     0.8529    0.9667    0.9062        30\n",
      "         112     0.9355    0.9667    0.9508        30\n",
      "         113     1.0000    1.0000    1.0000        30\n",
      "         114     0.9643    0.9000    0.9310        30\n",
      "         115     0.9677    1.0000    0.9836        30\n",
      "         116     1.0000    0.9667    0.9831        30\n",
      "         117     0.9667    0.9667    0.9667        30\n",
      "         118     1.0000    0.9333    0.9655        30\n",
      "         119     1.0000    0.9333    0.9655        30\n",
      "         120     0.9375    1.0000    0.9677        30\n",
      "         121     1.0000    1.0000    1.0000        30\n",
      "         122     1.0000    0.8667    0.9286        30\n",
      "         123     1.0000    0.9333    0.9655        30\n",
      "         124     1.0000    1.0000    1.0000        30\n",
      "         125     1.0000    0.8667    0.9286        30\n",
      "         126     0.9375    1.0000    0.9677        30\n",
      "         127     0.9667    0.9667    0.9667        30\n",
      "         128     1.0000    1.0000    1.0000        30\n",
      "         129     0.9333    0.9333    0.9333        30\n",
      "         130     0.9667    0.9667    0.9667        30\n",
      "         131     0.8824    1.0000    0.9375        30\n",
      "         132     1.0000    1.0000    1.0000        30\n",
      "         133     0.9667    0.9667    0.9667        30\n",
      "         134     0.9677    1.0000    0.9836        30\n",
      "         135     0.9375    1.0000    0.9677        30\n",
      "         136     0.9643    0.9000    0.9310        30\n",
      "         137     1.0000    0.9667    0.9831        30\n",
      "         138     0.8889    0.8000    0.8421        30\n",
      "         139     1.0000    1.0000    1.0000        30\n",
      "         140     0.9200    0.7667    0.8364        30\n",
      "         141     0.8000    0.9333    0.8615        30\n",
      "         142     0.9667    0.9667    0.9667        30\n",
      "         143     1.0000    1.0000    1.0000        30\n",
      "         144     1.0000    1.0000    1.0000        30\n",
      "         145     1.0000    1.0000    1.0000        30\n",
      "         146     1.0000    0.8667    0.9286        30\n",
      "         147     1.0000    1.0000    1.0000        30\n",
      "         148     1.0000    1.0000    1.0000        30\n",
      "         149     0.9259    0.8333    0.8772        30\n",
      "         150     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9618      4500\n",
      "   macro avg     0.9591    0.9554    0.9564      4500\n",
      "weighted avg     0.9655    0.9618    0.9627      4500\n",
      "\n",
      "Out of Scope\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "           2     0.0000    0.0000    0.0000         0\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         0\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "           7     0.0000    0.0000    0.0000         0\n",
      "           9     0.0000    0.0000    0.0000         0\n",
      "          10     0.0000    0.0000    0.0000         0\n",
      "          11     0.0000    0.0000    0.0000         0\n",
      "          16     0.0000    0.0000    0.0000         0\n",
      "          17     0.0000    0.0000    0.0000         0\n",
      "          18     0.0000    0.0000    0.0000         0\n",
      "          19     0.0000    0.0000    0.0000         0\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          22     0.0000    0.0000    0.0000         0\n",
      "          23     0.0000    0.0000    0.0000         0\n",
      "          24     0.0000    0.0000    0.0000         0\n",
      "          25     0.0000    0.0000    0.0000         0\n",
      "          26     0.0000    0.0000    0.0000         0\n",
      "          27     0.0000    0.0000    0.0000         0\n",
      "          28     0.0000    0.0000    0.0000         0\n",
      "          30     0.0000    0.0000    0.0000         0\n",
      "          32     0.0000    0.0000    0.0000         0\n",
      "          33     0.0000    0.0000    0.0000         0\n",
      "          34     0.0000    0.0000    0.0000         0\n",
      "          35     0.0000    0.0000    0.0000         0\n",
      "          36     0.0000    0.0000    0.0000         0\n",
      "          37     0.0000    0.0000    0.0000         0\n",
      "          38     0.0000    0.0000    0.0000         0\n",
      "          41     0.0000    0.0000    0.0000         0\n",
      "          42     0.0000    0.0000    0.0000         0\n",
      "          43     0.0000    0.0000    0.0000         0\n",
      "          44     0.0000    0.0000    0.0000         0\n",
      "          47     0.0000    0.0000    0.0000         0\n",
      "          48     0.0000    0.0000    0.0000         0\n",
      "          49     0.0000    0.0000    0.0000         0\n",
      "          50     0.0000    0.0000    0.0000         0\n",
      "          52     0.0000    0.0000    0.0000         0\n",
      "          53     0.0000    0.0000    0.0000         0\n",
      "          55     0.0000    0.0000    0.0000         0\n",
      "          58     0.0000    0.0000    0.0000         0\n",
      "          59     0.0000    0.0000    0.0000         0\n",
      "          60     0.0000    0.0000    0.0000         0\n",
      "          61     0.0000    0.0000    0.0000         0\n",
      "          63     0.0000    0.0000    0.0000         0\n",
      "          64     0.0000    0.0000    0.0000         0\n",
      "          65     0.0000    0.0000    0.0000         0\n",
      "          67     0.0000    0.0000    0.0000         0\n",
      "          68     0.0000    0.0000    0.0000         0\n",
      "          69     0.0000    0.0000    0.0000         0\n",
      "          71     0.0000    0.0000    0.0000         0\n",
      "          72     0.0000    0.0000    0.0000         0\n",
      "          73     0.0000    0.0000    0.0000         0\n",
      "          75     0.0000    0.0000    0.0000         0\n",
      "          76     0.0000    0.0000    0.0000         0\n",
      "          77     0.0000    0.0000    0.0000         0\n",
      "          78     0.0000    0.0000    0.0000         0\n",
      "          80     0.0000    0.0000    0.0000         0\n",
      "          81     0.0000    0.0000    0.0000         0\n",
      "          82     0.0000    0.0000    0.0000         0\n",
      "          83     0.0000    0.0000    0.0000         0\n",
      "          84     0.0000    0.0000    0.0000         0\n",
      "          87     0.0000    0.0000    0.0000         0\n",
      "          88     0.0000    0.0000    0.0000         0\n",
      "          89     0.0000    0.0000    0.0000         0\n",
      "          92     0.0000    0.0000    0.0000         0\n",
      "          93     0.0000    0.0000    0.0000         0\n",
      "          94     0.0000    0.0000    0.0000         0\n",
      "          96     0.0000    0.0000    0.0000         0\n",
      "          97     0.0000    0.0000    0.0000         0\n",
      "          98     0.0000    0.0000    0.0000         0\n",
      "          99     0.0000    0.0000    0.0000         0\n",
      "         101     0.0000    0.0000    0.0000         0\n",
      "         102     0.0000    0.0000    0.0000         0\n",
      "         104     0.0000    0.0000    0.0000         0\n",
      "         105     0.0000    0.0000    0.0000         0\n",
      "         106     0.0000    0.0000    0.0000         0\n",
      "         107     0.0000    0.0000    0.0000         0\n",
      "         112     0.0000    0.0000    0.0000         0\n",
      "         114     0.0000    0.0000    0.0000         0\n",
      "         117     0.0000    0.0000    0.0000         0\n",
      "         119     0.0000    0.0000    0.0000         0\n",
      "         120     0.0000    0.0000    0.0000         0\n",
      "         123     0.0000    0.0000    0.0000         0\n",
      "         124     0.0000    0.0000    0.0000         0\n",
      "         132     0.0000    0.0000    0.0000         0\n",
      "         133     0.0000    0.0000    0.0000         0\n",
      "         135     0.0000    0.0000    0.0000         0\n",
      "         136     0.0000    0.0000    0.0000         0\n",
      "         137     0.0000    0.0000    0.0000         0\n",
      "         138     0.0000    0.0000    0.0000         0\n",
      "         140     0.0000    0.0000    0.0000         0\n",
      "         141     0.0000    0.0000    0.0000         0\n",
      "         142     0.0000    0.0000    0.0000         0\n",
      "         145     0.0000    0.0000    0.0000         0\n",
      "         148     0.0000    0.0000    0.0000         0\n",
      "         149     0.0000    0.0000    0.0000         0\n",
      "         150     1.0000    0.6930    0.8187      1000\n",
      "\n",
      "    accuracy                         0.6930      1000\n",
      "   macro avg     0.0102    0.0071    0.0084      1000\n",
      "weighted avg     1.0000    0.6930    0.8187      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tayfun.tuna/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40.016282081604004"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "train_evaulate_model(dirs[2], models[2], batch_sizes[2])\n",
    "time()- start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a2e39ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/clinic/data_small/\n",
      "Inscope\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9667    0.9831        30\n",
      "           1     1.0000    0.9000    0.9474        30\n",
      "           2     1.0000    0.9000    0.9474        30\n",
      "           3     0.9667    0.9667    0.9667        30\n",
      "           4     1.0000    1.0000    1.0000        30\n",
      "           5     0.9643    0.9000    0.9310        30\n",
      "           6     0.9667    0.9667    0.9667        30\n",
      "           7     1.0000    0.9667    0.9831        30\n",
      "           8     1.0000    0.9667    0.9831        30\n",
      "           9     1.0000    1.0000    1.0000        30\n",
      "          10     0.8788    0.9667    0.9206        30\n",
      "          11     0.9375    1.0000    0.9677        30\n",
      "          12     1.0000    0.9333    0.9655        30\n",
      "          13     1.0000    1.0000    1.0000        30\n",
      "          14     0.8108    1.0000    0.8955        30\n",
      "          15     0.9375    1.0000    0.9677        30\n",
      "          16     0.9091    1.0000    0.9524        30\n",
      "          17     1.0000    0.9000    0.9474        30\n",
      "          18     0.9000    0.9000    0.9000        30\n",
      "          19     1.0000    1.0000    1.0000        30\n",
      "          20     1.0000    0.9667    0.9831        30\n",
      "          21     0.9677    1.0000    0.9836        30\n",
      "          22     1.0000    0.9000    0.9474        30\n",
      "          23     1.0000    0.9667    0.9831        30\n",
      "          24     1.0000    0.8667    0.9286        30\n",
      "          25     1.0000    0.9667    0.9831        30\n",
      "          26     0.8966    0.8667    0.8814        30\n",
      "          27     0.9375    1.0000    0.9677        30\n",
      "          28     0.9677    1.0000    0.9836        30\n",
      "          29     1.0000    1.0000    1.0000        30\n",
      "          30     0.9677    1.0000    0.9836        30\n",
      "          31     0.9375    1.0000    0.9677        30\n",
      "          32     1.0000    0.9667    0.9831        30\n",
      "          33     1.0000    0.9667    0.9831        30\n",
      "          34     1.0000    1.0000    1.0000        30\n",
      "          35     0.8286    0.9667    0.8923        30\n",
      "          36     1.0000    0.9333    0.9655        30\n",
      "          37     0.9677    1.0000    0.9836        30\n",
      "          38     0.8750    0.9333    0.9032        30\n",
      "          39     1.0000    1.0000    1.0000        30\n",
      "          40     0.9355    0.9667    0.9508        30\n",
      "          41     1.0000    1.0000    1.0000        30\n",
      "          42     0.9677    1.0000    0.9836        30\n",
      "          43     1.0000    1.0000    1.0000        30\n",
      "          44     0.9375    1.0000    0.9677        30\n",
      "          45     0.9667    0.9667    0.9667        30\n",
      "          46     0.9677    1.0000    0.9836        30\n",
      "          47     1.0000    0.9667    0.9831        30\n",
      "          48     1.0000    0.9667    0.9831        30\n",
      "          49     0.7838    0.9667    0.8657        30\n",
      "          50     0.8710    0.9000    0.8852        30\n",
      "          51     1.0000    1.0000    1.0000        30\n",
      "          52     1.0000    1.0000    1.0000        30\n",
      "          53     1.0000    1.0000    1.0000        30\n",
      "          54     1.0000    1.0000    1.0000        30\n",
      "          55     0.9355    0.9667    0.9508        30\n",
      "          56     0.9375    1.0000    0.9677        30\n",
      "          57     0.9667    0.9667    0.9667        30\n",
      "          58     0.9655    0.9333    0.9492        30\n",
      "          59     0.9259    0.8333    0.8772        30\n",
      "          60     0.9655    0.9333    0.9492        30\n",
      "          61     0.9677    1.0000    0.9836        30\n",
      "          62     0.9630    0.8667    0.9123        30\n",
      "          63     0.9375    1.0000    0.9677        30\n",
      "          64     1.0000    1.0000    1.0000        30\n",
      "          65     0.9200    0.7667    0.8364        30\n",
      "          66     1.0000    0.9667    0.9831        30\n",
      "          67     0.9615    0.8333    0.8929        30\n",
      "          68     1.0000    0.9667    0.9831        30\n",
      "          69     0.8824    1.0000    0.9375        30\n",
      "          70     0.8710    0.9000    0.8852        30\n",
      "          71     1.0000    1.0000    1.0000        30\n",
      "          72     0.9615    0.8333    0.8929        30\n",
      "          73     0.9062    0.9667    0.9355        30\n",
      "          74     0.9677    1.0000    0.9836        30\n",
      "          75     0.9375    1.0000    0.9677        30\n",
      "          76     0.8788    0.9667    0.9206        30\n",
      "          77     1.0000    0.9667    0.9831        30\n",
      "          78     0.8750    0.9333    0.9032        30\n",
      "          79     1.0000    1.0000    1.0000        30\n",
      "          80     0.9655    0.9333    0.9492        30\n",
      "          81     1.0000    0.9000    0.9474        30\n",
      "          82     1.0000    1.0000    1.0000        30\n",
      "          83     0.8710    0.9000    0.8852        30\n",
      "          84     1.0000    1.0000    1.0000        30\n",
      "          85     0.8966    0.8667    0.8814        30\n",
      "          86     1.0000    0.8333    0.9091        30\n",
      "          87     1.0000    1.0000    1.0000        30\n",
      "          88     0.9355    0.9667    0.9508        30\n",
      "          89     0.9677    1.0000    0.9836        30\n",
      "          90     1.0000    0.9667    0.9831        30\n",
      "          91     0.9310    0.9000    0.9153        30\n",
      "          92     1.0000    1.0000    1.0000        30\n",
      "          93     0.9630    0.8667    0.9123        30\n",
      "          94     1.0000    1.0000    1.0000        30\n",
      "          95     0.8750    0.9333    0.9032        30\n",
      "          96     0.9375    1.0000    0.9677        30\n",
      "          97     0.9333    0.9333    0.9333        30\n",
      "          98     0.9677    1.0000    0.9836        30\n",
      "          99     0.9655    0.9333    0.9492        30\n",
      "         100     0.8529    0.9667    0.9062        30\n",
      "         101     0.9655    0.9333    0.9492        30\n",
      "         102     0.9355    0.9667    0.9508        30\n",
      "         103     1.0000    1.0000    1.0000        30\n",
      "         104     1.0000    0.9667    0.9831        30\n",
      "         105     1.0000    0.9333    0.9655        30\n",
      "         106     0.9655    0.9333    0.9492        30\n",
      "         107     1.0000    1.0000    1.0000        30\n",
      "         108     0.9677    1.0000    0.9836        30\n",
      "         109     1.0000    0.9667    0.9831        30\n",
      "         110     1.0000    0.8667    0.9286        30\n",
      "         111     0.8750    0.9333    0.9032        30\n",
      "         112     1.0000    0.9000    0.9474        30\n",
      "         113     1.0000    1.0000    1.0000        30\n",
      "         114     0.9310    0.9000    0.9153        30\n",
      "         115     1.0000    1.0000    1.0000        30\n",
      "         116     0.9375    1.0000    0.9677        30\n",
      "         117     1.0000    0.8667    0.9286        30\n",
      "         118     0.9643    0.9000    0.9310        30\n",
      "         119     0.9655    0.9333    0.9492        30\n",
      "         120     1.0000    0.9667    0.9831        30\n",
      "         121     1.0000    1.0000    1.0000        30\n",
      "         122     0.8333    0.8333    0.8333        30\n",
      "         123     1.0000    0.9000    0.9474        30\n",
      "         124     1.0000    0.9667    0.9831        30\n",
      "         125     0.9600    0.8000    0.8727        30\n",
      "         126     0.8824    1.0000    0.9375        30\n",
      "         127     0.9062    0.9667    0.9355        30\n",
      "         128     1.0000    1.0000    1.0000        30\n",
      "         129     0.9355    0.9667    0.9508        30\n",
      "         130     1.0000    1.0000    1.0000        30\n",
      "         131     0.9375    1.0000    0.9677        30\n",
      "         132     1.0000    1.0000    1.0000        30\n",
      "         133     1.0000    0.9333    0.9655        30\n",
      "         134     0.9677    1.0000    0.9836        30\n",
      "         135     0.9375    1.0000    0.9677        30\n",
      "         136     1.0000    0.9667    0.9831        30\n",
      "         137     1.0000    0.9667    0.9831        30\n",
      "         138     1.0000    0.8000    0.8889        30\n",
      "         139     1.0000    1.0000    1.0000        30\n",
      "         140     0.7143    0.6667    0.6897        30\n",
      "         141     0.7714    0.9000    0.8308        30\n",
      "         142     0.9677    1.0000    0.9836        30\n",
      "         143     1.0000    0.9667    0.9831        30\n",
      "         144     1.0000    0.9667    0.9831        30\n",
      "         145     0.9677    1.0000    0.9836        30\n",
      "         146     0.9630    0.8667    0.9123        30\n",
      "         147     1.0000    1.0000    1.0000        30\n",
      "         148     1.0000    1.0000    1.0000        30\n",
      "         149     0.9630    0.8667    0.9123        30\n",
      "         150     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.9538      4500\n",
      "   macro avg     0.9540    0.9475    0.9496      4500\n",
      "weighted avg     0.9603    0.9538    0.9559      4500\n",
      "\n",
      "Out of Scope\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000         0\n",
      "           3     0.0000    0.0000    0.0000         0\n",
      "           5     0.0000    0.0000    0.0000         0\n",
      "           6     0.0000    0.0000    0.0000         0\n",
      "           7     0.0000    0.0000    0.0000         0\n",
      "          10     0.0000    0.0000    0.0000         0\n",
      "          11     0.0000    0.0000    0.0000         0\n",
      "          14     0.0000    0.0000    0.0000         0\n",
      "          15     0.0000    0.0000    0.0000         0\n",
      "          16     0.0000    0.0000    0.0000         0\n",
      "          17     0.0000    0.0000    0.0000         0\n",
      "          18     0.0000    0.0000    0.0000         0\n",
      "          19     0.0000    0.0000    0.0000         0\n",
      "          20     0.0000    0.0000    0.0000         0\n",
      "          22     0.0000    0.0000    0.0000         0\n",
      "          23     0.0000    0.0000    0.0000         0\n",
      "          25     0.0000    0.0000    0.0000         0\n",
      "          26     0.0000    0.0000    0.0000         0\n",
      "          27     0.0000    0.0000    0.0000         0\n",
      "          28     0.0000    0.0000    0.0000         0\n",
      "          32     0.0000    0.0000    0.0000         0\n",
      "          33     0.0000    0.0000    0.0000         0\n",
      "          34     0.0000    0.0000    0.0000         0\n",
      "          35     0.0000    0.0000    0.0000         0\n",
      "          36     0.0000    0.0000    0.0000         0\n",
      "          37     0.0000    0.0000    0.0000         0\n",
      "          38     0.0000    0.0000    0.0000         0\n",
      "          40     0.0000    0.0000    0.0000         0\n",
      "          41     0.0000    0.0000    0.0000         0\n",
      "          42     0.0000    0.0000    0.0000         0\n",
      "          43     0.0000    0.0000    0.0000         0\n",
      "          44     0.0000    0.0000    0.0000         0\n",
      "          46     0.0000    0.0000    0.0000         0\n",
      "          47     0.0000    0.0000    0.0000         0\n",
      "          49     0.0000    0.0000    0.0000         0\n",
      "          50     0.0000    0.0000    0.0000         0\n",
      "          51     0.0000    0.0000    0.0000         0\n",
      "          52     0.0000    0.0000    0.0000         0\n",
      "          53     0.0000    0.0000    0.0000         0\n",
      "          55     0.0000    0.0000    0.0000         0\n",
      "          56     0.0000    0.0000    0.0000         0\n",
      "          57     0.0000    0.0000    0.0000         0\n",
      "          58     0.0000    0.0000    0.0000         0\n",
      "          59     0.0000    0.0000    0.0000         0\n",
      "          60     0.0000    0.0000    0.0000         0\n",
      "          61     0.0000    0.0000    0.0000         0\n",
      "          63     0.0000    0.0000    0.0000         0\n",
      "          64     0.0000    0.0000    0.0000         0\n",
      "          65     0.0000    0.0000    0.0000         0\n",
      "          67     0.0000    0.0000    0.0000         0\n",
      "          69     0.0000    0.0000    0.0000         0\n",
      "          70     0.0000    0.0000    0.0000         0\n",
      "          72     0.0000    0.0000    0.0000         0\n",
      "          73     0.0000    0.0000    0.0000         0\n",
      "          75     0.0000    0.0000    0.0000         0\n",
      "          76     0.0000    0.0000    0.0000         0\n",
      "          77     0.0000    0.0000    0.0000         0\n",
      "          78     0.0000    0.0000    0.0000         0\n",
      "          79     0.0000    0.0000    0.0000         0\n",
      "          80     0.0000    0.0000    0.0000         0\n",
      "          81     0.0000    0.0000    0.0000         0\n",
      "          82     0.0000    0.0000    0.0000         0\n",
      "          83     0.0000    0.0000    0.0000         0\n",
      "          84     0.0000    0.0000    0.0000         0\n",
      "          87     0.0000    0.0000    0.0000         0\n",
      "          88     0.0000    0.0000    0.0000         0\n",
      "          89     0.0000    0.0000    0.0000         0\n",
      "          90     0.0000    0.0000    0.0000         0\n",
      "          91     0.0000    0.0000    0.0000         0\n",
      "          92     0.0000    0.0000    0.0000         0\n",
      "          93     0.0000    0.0000    0.0000         0\n",
      "          94     0.0000    0.0000    0.0000         0\n",
      "          96     0.0000    0.0000    0.0000         0\n",
      "          97     0.0000    0.0000    0.0000         0\n",
      "          98     0.0000    0.0000    0.0000         0\n",
      "          99     0.0000    0.0000    0.0000         0\n",
      "         100     0.0000    0.0000    0.0000         0\n",
      "         103     0.0000    0.0000    0.0000         0\n",
      "         104     0.0000    0.0000    0.0000         0\n",
      "         106     0.0000    0.0000    0.0000         0\n",
      "         107     0.0000    0.0000    0.0000         0\n",
      "         111     0.0000    0.0000    0.0000         0\n",
      "         114     0.0000    0.0000    0.0000         0\n",
      "         116     0.0000    0.0000    0.0000         0\n",
      "         119     0.0000    0.0000    0.0000         0\n",
      "         120     0.0000    0.0000    0.0000         0\n",
      "         121     0.0000    0.0000    0.0000         0\n",
      "         122     0.0000    0.0000    0.0000         0\n",
      "         123     0.0000    0.0000    0.0000         0\n",
      "         124     0.0000    0.0000    0.0000         0\n",
      "         127     0.0000    0.0000    0.0000         0\n",
      "         128     0.0000    0.0000    0.0000         0\n",
      "         129     0.0000    0.0000    0.0000         0\n",
      "         130     0.0000    0.0000    0.0000         0\n",
      "         132     0.0000    0.0000    0.0000         0\n",
      "         133     0.0000    0.0000    0.0000         0\n",
      "         136     0.0000    0.0000    0.0000         0\n",
      "         137     0.0000    0.0000    0.0000         0\n",
      "         138     0.0000    0.0000    0.0000         0\n",
      "         140     0.0000    0.0000    0.0000         0\n",
      "         141     0.0000    0.0000    0.0000         0\n",
      "         142     0.0000    0.0000    0.0000         0\n",
      "         143     0.0000    0.0000    0.0000         0\n",
      "         145     0.0000    0.0000    0.0000         0\n",
      "         146     0.0000    0.0000    0.0000         0\n",
      "         148     0.0000    0.0000    0.0000         0\n",
      "         149     0.0000    0.0000    0.0000         0\n",
      "         150     1.0000    0.5830    0.7366      1000\n",
      "\n",
      "    accuracy                         0.5830      1000\n",
      "   macro avg     0.0093    0.0054    0.0068      1000\n",
      "weighted avg     1.0000    0.5830    0.7366      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "192.43939208984375"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "train_evaulate_model(dirs[3], models[3], batch_sizes[3])\n",
    "time()- start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24be1e9",
   "metadata": {},
   "source": [
    "# Summary of Results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d373159d",
   "metadata": {},
   "source": [
    "../data/clinic/data_full/\n",
    "\n",
    "Inscope:        precision    recall  f1-score   support           \n",
    "    accuracy                         0.9531      4500\n",
    "   macro avg     0.9495    0.9468    0.9470      4500\n",
    "weighted avg     0.9559    0.9531    0.9533      4500\n",
    "\n",
    "\n",
    "Outof Scope:   precision    recall  f1-score   support\n",
    "    accuracy                         0.3340      1000\n",
    "   macro avg     0.0085    0.0028    0.0042      1000\n",
    "weighted avg     1.0000    0.3340    0.5007      1000"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ea39fd8",
   "metadata": {},
   "source": [
    "../data/clinic/data_imbalanced/\n",
    "\n",
    "Inscope:        precision    recall  f1-score   support           \n",
    "    accuracy                         0.9542      4500\n",
    "   macro avg     0.9512    0.9479    0.9483      4500\n",
    "weighted avg     0.9576    0.9542    0.9547      4500\n",
    "\n",
    "\n",
    "    accuracy                         0.5480      1000\n",
    "   macro avg     0.0089    0.0049    0.0063      1000\n",
    "weighted avg     1.0000    0.5480    0.7080      1000"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2fd4263",
   "metadata": {},
   "source": [
    "../data/clinic/data_oos_plus/\n",
    "\n",
    "Inscope:        precision    recall  f1-score   support           \n",
    "    accuracy                         0.9618      4500\n",
    "   macro avg     0.9591    0.9554    0.9564      4500\n",
    "weighted avg     0.9655    0.9618    0.9627      4500\n",
    "\n",
    "\n",
    "Outof Scope:   precision    recall  f1-score   support\n",
    "    accuracy                         0.6930      1000\n",
    "   macro avg     0.0102    0.0071    0.0084      1000\n",
    "weighted avg     1.0000    0.6930    0.8187      1000"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ad589d4",
   "metadata": {},
   "source": [
    "../data/clinic/data_small/\n",
    "\n",
    "Inscope:        precision    recall  f1-score   support           \n",
    "    accuracy                         0.9538      4500\n",
    "   macro avg     0.9540    0.9475    0.9496      4500\n",
    "weighted avg     0.9603    0.9538    0.9559      4500\n",
    "\n",
    "\n",
    "Outof Scope:   precision    recall  f1-score   support\n",
    "    accuracy                         0.5830      1000\n",
    "   macro avg     0.0093    0.0054    0.0068      1000\n",
    "weighted avg     1.0000    0.5830    0.7366      1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
