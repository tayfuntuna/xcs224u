{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "137b3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/abs/1909.02027\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import tensorflow_hub as hub\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bb2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/clinic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0420b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/clinic/data_imbalanced/val.csv',\n",
       " '../data/clinic/data_imbalanced/oos_test.csv',\n",
       " '../data/clinic/data_imbalanced/test.csv',\n",
       " '../data/clinic/data_imbalanced/oos_train.csv',\n",
       " '../data/clinic/data_imbalanced/oos_val.csv',\n",
       " '../data/clinic/data_imbalanced/train.csv',\n",
       " '../data/clinic/data_small/val.csv',\n",
       " '../data/clinic/data_small/oos_test.csv',\n",
       " '../data/clinic/data_small/test.csv',\n",
       " '../data/clinic/data_small/oos_train.csv',\n",
       " '../data/clinic/data_small/oos_val.csv',\n",
       " '../data/clinic/data_small/train.csv',\n",
       " '../data/clinic/data_full/val.csv',\n",
       " '../data/clinic/data_full/oos_test.csv',\n",
       " '../data/clinic/data_full/test.csv',\n",
       " '../data/clinic/data_full/oos_train.csv',\n",
       " '../data/clinic/data_full/oos_val.csv',\n",
       " '../data/clinic/data_full/train.csv',\n",
       " '../data/clinic/data_oos_plus/val.csv',\n",
       " '../data/clinic/data_oos_plus/oos_test.csv',\n",
       " '../data/clinic/data_oos_plus/test.csv',\n",
       " '../data/clinic/data_oos_plus/oos_train.csv',\n",
       " '../data/clinic/data_oos_plus/oos_val.csv',\n",
       " '../data/clinic/data_oos_plus/train.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(DATA_FOLDER+ '*/*.csv*')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cd96848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['change_accent', 'who_do_you_work_for', 'bill_balance',\n",
       "       'next_song', 'calories', 'change_user_name', 'confirm_reservation',\n",
       "       'jump_start', 'card_declined', 'cook_time', 'nutrition_info',\n",
       "       'greeting', 'calendar', 'schedule_maintenance', 'balance',\n",
       "       'tire_pressure', 'shopping_list', 'ingredients_list',\n",
       "       'whisper_mode', 'meal_suggestion', 'travel_alert', 'lost_luggage',\n",
       "       'weather', 'pin_change', 'pto_request', 'change_speed', 'no',\n",
       "       'user_name', 'taxes', 'book_flight', 'yes', 'timezone', 'fun_fact',\n",
       "       'order', 'traffic', 'pay_bill', 'report_fraud', 'vaccines',\n",
       "       'recipe', 'report_lost_card', 'transfer', 'redeem_rewards',\n",
       "       'exchange_rate', 'expiration_date', 'order_status',\n",
       "       'reset_settings', 'cancel_reservation', 'goodbye',\n",
       "       'restaurant_reviews', 'tell_joke', 'current_location', 'pto_used',\n",
       "       'international_visa', 'restaurant_suggestion', 'pto_balance',\n",
       "       'payday', 'flight_status', 'distance', 'routing', 'translate',\n",
       "       'text', 'carry_on', 'interest_rate', 'min_payment', 'roll_dice',\n",
       "       'measurement_conversion', 'book_hotel', 'travel_suggestion',\n",
       "       'cancel', 'credit_limit_change', 'apr', 'time', 'direct_deposit',\n",
       "       'repeat', 'how_busy', 'rollover_401k', 'travel_notification',\n",
       "       'calendar_update', 'international_fees', 'account_blocked',\n",
       "       'improve_credit_score', 'uber', 'tire_change', 'gas_type',\n",
       "       'do_you_have_pets', 'application_status',\n",
       "       'replacement_card_duration', 'play_music', 'where_are_you_from',\n",
       "       'credit_limit', 'date', 'share_location', 'who_made_you',\n",
       "       'spelling', 'maybe', 'accept_reservations', 'spending_history',\n",
       "       'meaning_of_life', 'gas', 'todo_list_update', 'plug_type',\n",
       "       'update_playlist', 'ingredient_substitution', 'reminder_update',\n",
       "       'what_is_your_name', 'todo_list', 'income', 'transactions',\n",
       "       'shopping_list_update', 'what_are_your_hobbies', 'make_call',\n",
       "       'definition', 'change_ai_name', 'change_language',\n",
       "       'oil_change_how', 'what_song', 'freeze_account', 'thank_you',\n",
       "       'mpg', 'rewards_balance', 'find_phone', 'flip_coin', 'car_rental',\n",
       "       'food_last', 'insurance_change', 'credit_score',\n",
       "       'pto_request_status', 'reminder', 'what_can_i_ask_you',\n",
       "       'next_holiday', 'order_checks', 'how_old_are_you', 'calculator',\n",
       "       'directions', 'damaged_card', 'new_card', 'are_you_a_bot',\n",
       "       'insurance', 'bill_due', 'smart_home', 'timer', 'sync_device',\n",
       "       'w2', 'schedule_meeting', 'oil_change_when', 'alarm',\n",
       "       'change_volume', 'restaurant_reservation', 'meeting_schedule',\n",
       "       'last_maintenance'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/clinic/data_full/train.csv')\n",
    "df_train['intent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4047d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {k:i for i,k in enumerate(set(df_train['intent'].tolist()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f6cae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meaning_of_life': 0,\n",
       " 'who_do_you_work_for': 1,\n",
       " 'pto_request': 2,\n",
       " 'restaurant_reservation': 3,\n",
       " 'gas_type': 4,\n",
       " 'update_playlist': 5,\n",
       " 'restaurant_suggestion': 6,\n",
       " 'book_flight': 7,\n",
       " 'date': 8,\n",
       " 'mpg': 9,\n",
       " 'play_music': 10,\n",
       " 'new_card': 11,\n",
       " 'timezone': 12,\n",
       " 'jump_start': 13,\n",
       " 'schedule_meeting': 14,\n",
       " 'flight_status': 15,\n",
       " 'weather': 16,\n",
       " 'transfer': 17,\n",
       " 'recipe': 18,\n",
       " 'reset_settings': 19,\n",
       " 'schedule_maintenance': 20,\n",
       " 'international_fees': 21,\n",
       " 'income': 22,\n",
       " 'cook_time': 23,\n",
       " 'redeem_rewards': 24,\n",
       " 'calories': 25,\n",
       " 'shopping_list': 26,\n",
       " 'change_language': 27,\n",
       " 'alarm': 28,\n",
       " 'flip_coin': 29,\n",
       " 'no': 30,\n",
       " 'whisper_mode': 31,\n",
       " 'insurance_change': 32,\n",
       " 'payday': 33,\n",
       " 'what_are_your_hobbies': 34,\n",
       " 'damaged_card': 35,\n",
       " 'definition': 36,\n",
       " 'insurance': 37,\n",
       " 'share_location': 38,\n",
       " 'next_song': 39,\n",
       " 'report_fraud': 40,\n",
       " 'vaccines': 41,\n",
       " 'next_holiday': 42,\n",
       " 'carry_on': 43,\n",
       " 'cancel_reservation': 44,\n",
       " 'what_can_i_ask_you': 45,\n",
       " 'how_old_are_you': 46,\n",
       " 'what_song': 47,\n",
       " 'where_are_you_from': 48,\n",
       " 'directions': 49,\n",
       " 'user_name': 50,\n",
       " 'do_you_have_pets': 51,\n",
       " 'find_phone': 52,\n",
       " 'car_rental': 53,\n",
       " 'roll_dice': 54,\n",
       " 'order_status': 55,\n",
       " 'who_made_you': 56,\n",
       " 'greeting': 57,\n",
       " 'calculator': 58,\n",
       " 'distance': 59,\n",
       " 'pay_bill': 60,\n",
       " 'make_call': 61,\n",
       " 'report_lost_card': 62,\n",
       " 'improve_credit_score': 63,\n",
       " 'sync_device': 64,\n",
       " 'calendar': 65,\n",
       " 'expiration_date': 66,\n",
       " 'change_volume': 67,\n",
       " 'order_checks': 68,\n",
       " 'spending_history': 69,\n",
       " 'change_ai_name': 70,\n",
       " 'lost_luggage': 71,\n",
       " 'replacement_card_duration': 72,\n",
       " 'credit_limit': 73,\n",
       " 'min_payment': 74,\n",
       " 'cancel': 75,\n",
       " 'calendar_update': 76,\n",
       " 'tire_change': 77,\n",
       " 'goodbye': 78,\n",
       " 'application_status': 79,\n",
       " 'repeat': 80,\n",
       " 'text': 81,\n",
       " 'direct_deposit': 82,\n",
       " 'meal_suggestion': 83,\n",
       " 'measurement_conversion': 84,\n",
       " 'what_is_your_name': 85,\n",
       " 'restaurant_reviews': 86,\n",
       " 'taxes': 87,\n",
       " 'interest_rate': 88,\n",
       " 'travel_suggestion': 89,\n",
       " 'plug_type': 90,\n",
       " 'yes': 91,\n",
       " 'book_hotel': 92,\n",
       " 'smart_home': 93,\n",
       " 'ingredient_substitution': 94,\n",
       " 'pto_balance': 95,\n",
       " 'gas': 96,\n",
       " 'todo_list_update': 97,\n",
       " 'last_maintenance': 98,\n",
       " 'apr': 99,\n",
       " 'shopping_list_update': 100,\n",
       " 'oil_change_when': 101,\n",
       " 'thank_you': 102,\n",
       " 'w2': 103,\n",
       " 'balance': 104,\n",
       " 'credit_limit_change': 105,\n",
       " 'current_location': 106,\n",
       " 'uber': 107,\n",
       " 'travel_notification': 108,\n",
       " 'confirm_reservation': 109,\n",
       " 'card_declined': 110,\n",
       " 'bill_due': 111,\n",
       " 'traffic': 112,\n",
       " 'maybe': 113,\n",
       " 'bill_balance': 114,\n",
       " 'change_accent': 115,\n",
       " 'food_last': 116,\n",
       " 'account_blocked': 117,\n",
       " 'timer': 118,\n",
       " 'reminder_update': 119,\n",
       " 'reminder': 120,\n",
       " 'rollover_401k': 121,\n",
       " 'pin_change': 122,\n",
       " 'todo_list': 123,\n",
       " 'fun_fact': 124,\n",
       " 'meeting_schedule': 125,\n",
       " 'rewards_balance': 126,\n",
       " 'time': 127,\n",
       " 'travel_alert': 128,\n",
       " 'pto_request_status': 129,\n",
       " 'change_speed': 130,\n",
       " 'accept_reservations': 131,\n",
       " 'tell_joke': 132,\n",
       " 'translate': 133,\n",
       " 'tire_pressure': 134,\n",
       " 'oil_change_how': 135,\n",
       " 'how_busy': 136,\n",
       " 'spelling': 137,\n",
       " 'transactions': 138,\n",
       " 'routing': 139,\n",
       " 'order': 140,\n",
       " 'change_user_name': 141,\n",
       " 'freeze_account': 142,\n",
       " 'credit_score': 143,\n",
       " 'are_you_a_bot': 144,\n",
       " 'exchange_rate': 145,\n",
       " 'pto_used': 146,\n",
       " 'international_visa': 147,\n",
       " 'nutrition_info': 148,\n",
       " 'ingredients_list': 149}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "131054b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['oos']=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58992f53",
   "metadata": {},
   "source": [
    "## ADD USE EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58940a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2521835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_guse_embedings_with_batch(sentences,batch_size=64):\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0,len(sentences),batch_size)):\n",
    "      embeddings_batch = embed(sentences[i:i+batch_size])\n",
    "      embeddings.extend(embeddings_batch)\n",
    "    return embeddings\n",
    "\n",
    "def add_embeddings(dt, column= 'text'):\n",
    "    embeddings = get_guse_embedings_with_batch(dt[column])\n",
    "    embs = np.array(embeddings).tolist()\n",
    "    df = pd.DataFrame([pd.Series(x) for x in embs])\n",
    "    df.columns = ['emb_{}'.format(x+1) for x in df.columns]\n",
    "    dt = pd.concat([dt,df], axis=1).reindex(dt.index)\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be1d5bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:10<00:00,  6.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>label</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_503</th>\n",
       "      <th>emb_504</th>\n",
       "      <th>emb_505</th>\n",
       "      <th>emb_506</th>\n",
       "      <th>emb_507</th>\n",
       "      <th>emb_508</th>\n",
       "      <th>emb_509</th>\n",
       "      <th>emb_510</th>\n",
       "      <th>emb_511</th>\n",
       "      <th>emb_512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set the alarm now</td>\n",
       "      <td>alarm</td>\n",
       "      <td>28</td>\n",
       "      <td>0.004335</td>\n",
       "      <td>0.044460</td>\n",
       "      <td>-0.049194</td>\n",
       "      <td>-0.041635</td>\n",
       "      <td>-0.031951</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>0.089107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107635</td>\n",
       "      <td>0.081210</td>\n",
       "      <td>0.005851</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>-0.046487</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>-0.031242</td>\n",
       "      <td>-0.072224</td>\n",
       "      <td>-0.108159</td>\n",
       "      <td>-0.009890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please tell me what subjects you like</td>\n",
       "      <td>what_can_i_ask_you</td>\n",
       "      <td>45</td>\n",
       "      <td>0.059729</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.046124</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.007193</td>\n",
       "      <td>0.068866</td>\n",
       "      <td>-0.017350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023217</td>\n",
       "      <td>-0.049913</td>\n",
       "      <td>0.011365</td>\n",
       "      <td>0.036991</td>\n",
       "      <td>-0.017940</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.031345</td>\n",
       "      <td>-0.029549</td>\n",
       "      <td>0.023903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is there an uber that drives to the bank on 5t...</td>\n",
       "      <td>uber</td>\n",
       "      <td>107</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>-0.014766</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>0.059949</td>\n",
       "      <td>0.043445</td>\n",
       "      <td>0.056851</td>\n",
       "      <td>0.052119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041092</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.085444</td>\n",
       "      <td>-0.068558</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.055524</td>\n",
       "      <td>0.028536</td>\n",
       "      <td>0.049110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>change to something that's not whisper mode</td>\n",
       "      <td>whisper_mode</td>\n",
       "      <td>31</td>\n",
       "      <td>0.042140</td>\n",
       "      <td>0.019140</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.033907</td>\n",
       "      <td>0.013733</td>\n",
       "      <td>-0.035960</td>\n",
       "      <td>-0.013485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072704</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>-0.028814</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>-0.088805</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.030570</td>\n",
       "      <td>0.069152</td>\n",
       "      <td>0.026542</td>\n",
       "      <td>-0.011627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer, call alexa</td>\n",
       "      <td>make_call</td>\n",
       "      <td>61</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>-0.002721</td>\n",
       "      <td>0.032199</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>-0.087309</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064405</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>-0.066277</td>\n",
       "      <td>-0.019167</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>-0.003916</td>\n",
       "      <td>0.017222</td>\n",
       "      <td>-0.047592</td>\n",
       "      <td>0.011032</td>\n",
       "      <td>-0.027060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              intent  \\\n",
       "0                                  set the alarm now               alarm   \n",
       "1              please tell me what subjects you like  what_can_i_ask_you   \n",
       "2  is there an uber that drives to the bank on 5t...                uber   \n",
       "3        change to something that's not whisper mode        whisper_mode   \n",
       "4                               computer, call alexa           make_call   \n",
       "\n",
       "   label     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0     28  0.004335  0.044460 -0.049194 -0.041635 -0.031951 -0.015406   \n",
       "1     45  0.059729  0.032617  0.046124 -0.002091  0.007193  0.068866   \n",
       "2    107  0.064134 -0.014766 -0.007532  0.059949  0.043445  0.056851   \n",
       "3     31  0.042140  0.019140  0.011681  0.033907  0.013733 -0.035960   \n",
       "4     61  0.016042  0.037868 -0.002721  0.032199  0.036126 -0.087309   \n",
       "\n",
       "      emb_7  ...   emb_503   emb_504   emb_505   emb_506   emb_507   emb_508  \\\n",
       "0  0.089107  ...  0.107635  0.081210  0.005851  0.016944 -0.046487  0.004882   \n",
       "1 -0.017350  ... -0.023217 -0.049913  0.011365  0.036991 -0.017940 -0.011743   \n",
       "2  0.052119  ... -0.041092  0.015019  0.085444 -0.068558  0.004263  0.014379   \n",
       "3 -0.013485  ... -0.072704  0.053845 -0.028814  0.015518 -0.088805  0.007782   \n",
       "4  0.003662  ... -0.064405  0.019637 -0.066277 -0.019167  0.029189 -0.003916   \n",
       "\n",
       "    emb_509   emb_510   emb_511   emb_512  \n",
       "0 -0.031242 -0.072224 -0.108159 -0.009890  \n",
       "1  0.018322  0.031345 -0.029549  0.023903  \n",
       "2 -0.000778 -0.055524  0.028536  0.049110  \n",
       "3  0.030570  0.069152  0.026542 -0.011627  \n",
       "4  0.017222 -0.047592  0.011032 -0.027060  \n",
       "\n",
       "[5 rows x 515 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['label'] = dt['intent'].apply(lambda x: labels.get(x,150))\n",
    "dt = add_embeddings(dt)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdaabdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:07<00:00,  6.41it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.06it/s]\n",
      "100%|██████████| 71/71 [00:12<00:00,  5.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.81it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.63it/s]\n",
      "100%|██████████| 165/165 [00:24<00:00,  6.79it/s]\n",
      "100%|██████████| 47/47 [00:07<00:00,  6.57it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.07it/s]\n",
      "100%|██████████| 71/71 [00:11<00:00,  6.07it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.64it/s]\n",
      "100%|██████████| 118/118 [00:18<00:00,  6.54it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.01it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.69it/s]\n",
      "100%|██████████| 71/71 [00:10<00:00,  6.69it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.17it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.28it/s]\n",
      "100%|██████████| 235/235 [00:32<00:00,  7.24it/s]\n",
      "100%|██████████| 47/47 [00:06<00:00,  7.00it/s]\n",
      "100%|██████████| 16/16 [00:02<00:00,  6.86it/s]\n",
      "100%|██████████| 71/71 [00:10<00:00,  6.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  7.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  8.85it/s]\n",
      "100%|██████████| 235/235 [00:34<00:00,  6.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2703.8341739177704"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time()\n",
    "for file_name in files:\n",
    "    dt = pd.read_csv(file_name)\n",
    "    dt['label'] = dt['intent'].apply(lambda x: labels.get(x,150))\n",
    "    add_embeddings(dt).to_csv(file_name.replace('.csv','_with_use_emb.csv'))\n",
    "time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6939e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb5cd9b9",
   "metadata": {},
   "source": [
    "# Parameters:\n",
    "#https://github.com/clinc/oos-eval/blob/master/hyperparameters.csv\n",
    "\n",
    "Full\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       400\t       use\t        1\t      0\t\n",
    "           \n",
    "Small\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        1\t      0.1\n",
    "           \n",
    "Imbalanced\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        64      \t0\n",
    "           \n",
    "OOS+\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       200\t       use\t        16      \t0.1\t\n",
    "           \n",
    "UnderSample Binary\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\n",
    "           mlp\t       tanh\t                  softmax\t       100\t       use\t        64      \t0\t\n",
    "           \n",
    "Wiki Aug Binary\tclassifier\tf_hidden_activation\ts_hidden_activation\thidden_dim\tvectorizer\tbatch_size\tdropout\t\t\n",
    "           mlp\t       tanh\t                  softmax\t       300\t       use\t        16      \t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abe753",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_full = MLPClassifier(hidden_layer_sizes=(400), \n",
    "                         max_iter=300,\n",
    "                         activation = 'relu',\n",
    "                         solver='adam',\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e506cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MLPClassifier(hidden_dim_size, drop_out):\n",
    "    keras_model = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(512,), name ='input'),\n",
    "        keras.layers.Dense(512, activation='relu', name ='hidden1'),\n",
    "        keras.layers.Dense(2,  name ='output')\n",
    "    ])\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    keras_model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    return keras_model\n",
    "\n",
    "keras_model = generate_keras_model_without_drop_out()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf6bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220abbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35a81347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7033c1c08e0e48a1b140f813275e17e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304805c02d414c4cadf28749333b98cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32dedc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75467ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds = tokenizer(train.text.tolist(), truncation=True, padding=True, max_length=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9a7b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_embeds = tokenizer(valid.text.tolist(), truncation=True, padding=True, max_length=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88a2de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = tokenizer(test.text.tolist(), truncation=True, padding=True, max_length=max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed295ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model=BertForSequenceClassification.from_pretrained(model_name, num_labels=len(set(train.intent.tolist())))\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    output_dir = 'output_file'\n",
    ")\n",
    "training_args = TrainingArguments(\"test-trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f3d3908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::ptyprocess==0.7.0=pyhd3eb1b0_2\n",
      "  - defaults/osx-64::entrypoints==0.3=py36_0\n",
      "  - defaults/noarch::jupyter_client==7.1.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::webencodings==0.5.1=py36_1\n",
      "  - defaults/osx-64::jsonschema==3.0.2=py36_0\n",
      "  - defaults/osx-64::pandocfilters==1.4.3=py36hecd8cb5_1\n",
      "  - defaults/osx-64::python==3.6.13=h88f2d9e_0\n",
      "  - defaults/osx-64::pyzmq==22.2.1=py36h23ab428_1\n",
      "  - defaults/osx-64::numpy==1.17.0=py36h926163e_0\n",
      "  - defaults/noarch::defusedxml==0.7.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::decorator==5.1.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::nbclient==0.5.3=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::cffi==1.14.6=py36h2125817_0\n",
      "  - defaults/noarch::pycparser==2.21=pyhd3eb1b0_0\n",
      "  - defaults/noarch::parso==0.8.3=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::notebook==6.4.3=py36hecd8cb5_0\n",
      "  - defaults/noarch::pytz==2021.3=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::appnope==0.1.2=py36hecd8cb5_1001\n",
      "  - defaults/osx-64::argon2-cffi==20.1.0=py36h9ed2024_1\n",
      "  - defaults/noarch::pexpect==4.8.0=pyhd3eb1b0_3\n",
      "  - defaults/noarch::six==1.16.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::mistune==0.8.4=py36h1de35cc_0\n",
      "  - defaults/osx-64::numpy-base==1.17.0=py36ha711998_0\n",
      "  - defaults/noarch::python-dateutil==2.8.2=pyhd3eb1b0_0\n",
      "  - defaults/noarch::wcwidth==0.2.5=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::async_generator==1.10=py36h28b3542_0\n",
      "  - defaults/noarch::send2trash==1.8.0=pyhd3eb1b0_1\n",
      "  - defaults/noarch::attrs==21.2.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::jedi==0.17.0=py36_0\n",
      "  - defaults/noarch::nest-asyncio==1.5.1=pyhd3eb1b0_0\n",
      "  - defaults/noarch::jupyterlab_pygments==0.1.2=py_0\n",
      "  - defaults/noarch::testpath==0.5.0=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::ipykernel==5.3.4=py36h5ca1d4c_0\n",
      "  - defaults/noarch::ipython_genutils==0.2.0=pyhd3eb1b0_1\n",
      "  - defaults/osx-64::pip==21.2.2=py36hecd8cb5_0\n",
      "  - defaults/osx-64::markupsafe==2.0.1=py36h9ed2024_0\n",
      "  - defaults/osx-64::jupyter_core==4.8.1=py36hecd8cb5_0\n",
      "  - defaults/noarch::backcall==0.2.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::bleach==4.1.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::pygments==2.10.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::nbformat==5.1.3=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::traitlets==4.3.3=py36hecd8cb5_0\n",
      "  - defaults/noarch::prompt-toolkit==3.0.20=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::ipython==7.16.1=py36h5ca1d4c_0\n",
      "  - defaults/osx-64::pyrsistent==0.17.3=py36haf1e3a3_0\n",
      "  - defaults/osx-64::tornado==6.1=py36h9ed2024_0\n",
      "  - defaults/osx-64::terminado==0.9.4=py36hecd8cb5_0\n",
      "  - defaults/noarch::jinja2==3.0.2=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::h5py==2.10.0=py36h0601b69_1\n",
      "  - defaults/osx-64::certifi==2021.5.30=py36hecd8cb5_0\n",
      "  - defaults/noarch::pyparsing==3.0.4=pyhd3eb1b0_0\n",
      "  - defaults/osx-64::nbconvert==6.0.7=py36_0\n",
      "  - defaults/osx-64::pandas==0.25.3=py36h0a44026_0\n",
      "  - defaults/noarch::pickleshare==0.7.5=pyhd3eb1b0_1003\n",
      "  - defaults/noarch::packaging==21.3=pyhd3eb1b0_0\n",
      "  - defaults/noarch::prometheus_client==0.12.0=pyhd3eb1b0_0\n",
      "  - defaults/noarch::wheel==0.37.1=pyhd3eb1b0_0\n",
      "| ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U sentence-transformers\n",
    "!conda install -c conda-forge sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9cd21dd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HF_MODULES_CACHE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d6fd298036bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all-MiniLM-L6-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Our sentences we like to encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sentences = ['This framework generates embeddings for each input sentence',\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2.2.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m__MODEL_HUB_ORGANIZATION__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sentence-transformers'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sentence_transformers/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDenoisingAutoEncoderDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDenoisingAutoEncoderDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mNoDuplicatesDataLoader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoDuplicatesDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mParallelSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentencesDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSentenceLabelDataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceLabelDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sentence_transformers/datasets/ParallelSentencesDataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_from_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPooling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_card_templates\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCardTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sentence_transformers/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mTransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mAsym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAsym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mBoW\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCNN\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT5Config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2485\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbig_bird\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBigBirdConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigbird_pegasus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBigBirdPegasusConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2487\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblenderbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlenderbotConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlenderbotTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2488\u001b[0m     from .models.blenderbot_small import (\n\u001b[1;32m   2489\u001b[0m         \u001b[0mBLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0mcode_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_docstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TokenClassification\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"MultipleChoice\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \u001b[0mcode_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_docstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MultipleChoice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"MaskedLM\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"FlaubertWithLMHeadModel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"XLMWithLMHeadModel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0mcode_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_docstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MaskedLM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"TokenClassification\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0mcode_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_docstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TokenClassification\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"MultipleChoice\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m             \u001b[0mcode_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_docstrings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MultipleChoice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"MaskedLM\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"FlaubertWithLMHeadModel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"XLMWithLMHeadModel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/models/auto/__init__.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mAutoModelForVision2Seq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         )\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/models/auto/modeling_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mauto_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_BaseAutoModelClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_LazyAutoMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_class_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCONFIG_MAPPING_NAMES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mdynamic_module_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHF_MODULES_CACHE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRANSFORMERS_DYNAMIC_MODULE_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_bucket_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_offline_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HF_MODULES_CACHE'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d4a12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc12bdd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f7948a9efac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"label\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/astra/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             raise ValueError(\n\u001b[0;32m-> 2565\u001b[0;31m                 \u001b[0;34m\"You should supply an encoding or a list of encodings to this method\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2566\u001b[0m                 \u001b[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m             )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  args=training_args, \n",
    "                  train_dataset=train_embeds,\n",
    "                  eval_dataset=valid_embeds,\n",
    "                   data_collator=data_collator,\n",
    "                tokenizer=tokenizer,\n",
    "                )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60cde68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oos_val\n",
      "val\n",
      "train\n",
      "oos_test\n",
      "test\n",
      "oos_train\n"
     ]
    }
   ],
   "source": [
    "for k in data.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e3cd94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    100 non-null    object\n",
      " 1   intent  100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dt = pd.DataFrame(data['oos_train'], columns = ['text', 'intent'])\n",
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ba68e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how much is an overdraft fee for bank</td>\n",
       "      <td>oos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why are exponents preformed before multiplicat...</td>\n",
       "      <td>oos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what size wipers does this car take</td>\n",
       "      <td>oos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where is the dipstick</td>\n",
       "      <td>oos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how much is 1 share of aapl</td>\n",
       "      <td>oos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text intent\n",
       "0              how much is an overdraft fee for bank    oos\n",
       "1  why are exponents preformed before multiplicat...    oos\n",
       "2                what size wipers does this car take    oos\n",
       "3                              where is the dipstick    oos\n",
       "4                        how much is 1 share of aapl    oos"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5389def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_full.json oos_val 100\n",
      "data_full.json val 3000\n",
      "data_full.json train 15000\n",
      "data_full.json oos_test 1000\n",
      "data_full.json test 4500\n",
      "data_full.json oos_train 100\n",
      "data_imbalanced.json oos_val 100\n",
      "data_imbalanced.json val 3000\n",
      "data_imbalanced.json train 10525\n",
      "data_imbalanced.json oos_test 1000\n",
      "data_imbalanced.json test 4500\n",
      "data_imbalanced.json oos_train 100\n",
      "data_oos_plus.json oos_val 100\n",
      "data_oos_plus.json val 3000\n",
      "data_oos_plus.json train 15000\n",
      "data_oos_plus.json oos_test 1000\n",
      "data_oos_plus.json test 4500\n",
      "data_oos_plus.json oos_train 250\n",
      "data_small.json oos_val 100\n",
      "data_small.json val 3000\n",
      "data_small.json train 7500\n",
      "data_small.json oos_test 1000\n",
      "data_small.json test 4500\n",
      "data_small.json oos_train 100\n"
     ]
    }
   ],
   "source": [
    "for file_name in files:\n",
    "    data = json.load(open(DATA_FOLDER + file_name))\n",
    "    new_path = DATA_FOLDER + file_name.replace('.json','')\n",
    "    os.makedirs(new_path, exist_ok=True)\n",
    "    for key in data.keys():\n",
    "        dt = pd.DataFrame(data[key], columns = ['text', 'intent'])\n",
    "        print(file_name,key, len(dt))\n",
    "        dt.sample(frac=1).to_csv(os.path.join(new_path, key +\".csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740f747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
