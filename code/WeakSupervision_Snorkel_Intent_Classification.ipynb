{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "md-exclude"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter, RandomVoter, LabelModel\n",
    "\n",
    "\n",
    "\n",
    "from snorkel.labeling import labeling_function\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0 1.17.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__, np. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val.csv',\n",
       " 'oos_test.csv',\n",
       " 'test.csv',\n",
       " 'oos_train.csv',\n",
       " 'oos_val.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = \"../data/clinic/data_small/\"\n",
    "os.listdir(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500 entries, 0 to 7499\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    7500 non-null   object\n",
      " 1   intent  7500 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_FOLDER + 'train.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3000 non-null   object\n",
      " 1   intent  3000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_valid = pd.read_csv(DATA_FOLDER + 'val.csv')\n",
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4500 entries, 0 to 4499\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    4500 non-null   object\n",
      " 1   intent  4500 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(DATA_FOLDER + 'test.csv')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current_location': 0,\n",
       " 'date': 1,\n",
       " 'international_fees': 2,\n",
       " 'lost_luggage': 3,\n",
       " 'whisper_mode': 4,\n",
       " 'plug_type': 5,\n",
       " 'credit_limit': 6,\n",
       " 'pto_used': 7,\n",
       " 'make_call': 8,\n",
       " 'directions': 9,\n",
       " 'report_fraud': 10,\n",
       " 'spending_history': 11,\n",
       " 'share_location': 12,\n",
       " 'new_card': 13,\n",
       " 'who_made_you': 14,\n",
       " 'expiration_date': 15,\n",
       " 'payday': 16,\n",
       " 'gas': 17,\n",
       " 'flight_status': 18,\n",
       " 'travel_alert': 19,\n",
       " 'what_are_your_hobbies': 20,\n",
       " 'what_can_i_ask_you': 21,\n",
       " 'travel_notification': 22,\n",
       " 'calendar_update': 23,\n",
       " 'meal_suggestion': 24,\n",
       " 'nutrition_info': 25,\n",
       " 'calories': 26,\n",
       " 'pay_bill': 27,\n",
       " 'replacement_card_duration': 28,\n",
       " 'credit_limit_change': 29,\n",
       " 'next_holiday': 30,\n",
       " 'timezone': 31,\n",
       " 'pto_balance': 32,\n",
       " 'are_you_a_bot': 33,\n",
       " 'transactions': 34,\n",
       " 'gas_type': 35,\n",
       " 'measurement_conversion': 36,\n",
       " 'todo_list_update': 37,\n",
       " 'alarm': 38,\n",
       " 'damaged_card': 39,\n",
       " 'exchange_rate': 40,\n",
       " 'balance': 41,\n",
       " 'repeat': 42,\n",
       " 'taxes': 43,\n",
       " 'application_status': 44,\n",
       " 'pto_request': 45,\n",
       " 'fun_fact': 46,\n",
       " 'freeze_account': 47,\n",
       " 'what_song': 48,\n",
       " 'order_checks': 49,\n",
       " 'redeem_rewards': 50,\n",
       " 'report_lost_card': 51,\n",
       " 'who_do_you_work_for': 52,\n",
       " 'what_is_your_name': 53,\n",
       " 'next_song': 54,\n",
       " 'change_speed': 55,\n",
       " 'mpg': 56,\n",
       " 'apr': 57,\n",
       " 'income': 58,\n",
       " 'restaurant_suggestion': 59,\n",
       " 'accept_reservations': 60,\n",
       " 'restaurant_reservation': 61,\n",
       " 'change_accent': 62,\n",
       " 'weather': 63,\n",
       " 'distance': 64,\n",
       " 'schedule_meeting': 65,\n",
       " 'meaning_of_life': 66,\n",
       " 'direct_deposit': 67,\n",
       " 'order': 68,\n",
       " 'change_volume': 69,\n",
       " 'cancel': 70,\n",
       " 'w2': 71,\n",
       " 'last_maintenance': 72,\n",
       " 'international_visa': 73,\n",
       " 'do_you_have_pets': 74,\n",
       " 'oil_change_when': 75,\n",
       " 'interest_rate': 76,\n",
       " 'tire_pressure': 77,\n",
       " 'where_are_you_from': 78,\n",
       " 'order_status': 79,\n",
       " 'book_flight': 80,\n",
       " 'how_old_are_you': 81,\n",
       " 'text': 82,\n",
       " 'play_music': 83,\n",
       " 'uber': 84,\n",
       " 'book_hotel': 85,\n",
       " 'confirm_reservation': 86,\n",
       " 'find_phone': 87,\n",
       " 'insurance_change': 88,\n",
       " 'flip_coin': 89,\n",
       " 'carry_on': 90,\n",
       " 'schedule_maintenance': 91,\n",
       " 'reminder': 92,\n",
       " 'no': 93,\n",
       " 'timer': 94,\n",
       " 'food_last': 95,\n",
       " 'oil_change_how': 96,\n",
       " 'change_user_name': 97,\n",
       " 'cook_time': 98,\n",
       " 'time': 99,\n",
       " 'tell_joke': 100,\n",
       " 'sync_device': 101,\n",
       " 'shopping_list': 102,\n",
       " 'ingredients_list': 103,\n",
       " 'reset_settings': 104,\n",
       " 'credit_score': 105,\n",
       " 'definition': 106,\n",
       " 'pto_request_status': 107,\n",
       " 'goodbye': 108,\n",
       " 'todo_list': 109,\n",
       " 'improve_credit_score': 110,\n",
       " 'min_payment': 111,\n",
       " 'user_name': 112,\n",
       " 'rollover_401k': 113,\n",
       " 'tire_change': 114,\n",
       " 'transfer': 115,\n",
       " 'calculator': 116,\n",
       " 'yes': 117,\n",
       " 'roll_dice': 118,\n",
       " 'recipe': 119,\n",
       " 'bill_balance': 120,\n",
       " 'change_language': 121,\n",
       " 'meeting_schedule': 122,\n",
       " 'vaccines': 123,\n",
       " 'routing': 124,\n",
       " 'jump_start': 125,\n",
       " 'smart_home': 126,\n",
       " 'car_rental': 127,\n",
       " 'cancel_reservation': 128,\n",
       " 'how_busy': 129,\n",
       " 'maybe': 130,\n",
       " 'spelling': 131,\n",
       " 'bill_due': 132,\n",
       " 'reminder_update': 133,\n",
       " 'restaurant_reviews': 134,\n",
       " 'thank_you': 135,\n",
       " 'update_playlist': 136,\n",
       " 'traffic': 137,\n",
       " 'travel_suggestion': 138,\n",
       " 'card_declined': 139,\n",
       " 'ingredient_substitution': 140,\n",
       " 'rewards_balance': 141,\n",
       " 'change_ai_name': 142,\n",
       " 'pin_change': 143,\n",
       " 'calendar': 144,\n",
       " 'greeting': 145,\n",
       " 'insurance': 146,\n",
       " 'account_blocked': 147,\n",
       " 'translate': 148,\n",
       " 'shopping_list_update': 149}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {k:i for i,k in enumerate(set(df_train['intent'].tolist()))}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [k.replace('_',' ') for k in labels.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_access_request = 'Access Request'\n",
    "l_action_request ='Action request'\n",
    "l_asking_for_information ='Asking for Information'\n",
    "l_clarify_issue='Clarify Issue'\n",
    "l_general_statement='General Statement'\n",
    "l_issue_error_problem='Issue Error problem'\n",
    "l_need_support_person_help='Need support person help'\n",
    "l_benefits_question = 'benefits Question'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label_number'] = df_train['intent'].apply(lambda x: labels.get(x,-1))\n",
    "df_valid['label_number'] = df_valid['intent'].apply(lambda x: labels.get(x,-1))\n",
    "df_test['label_number'] = df_test['intent'].apply(lambda x: labels.get(x,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 4500, 3000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train),  len(df_test), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad045a1ce9540c69feca85b9b37f8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=26.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff5811f8c840a890d9613f201a6d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898822.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903d5b22507241d5a4f82186056095ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d079c7a990144f8aa9b6152371ba0e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",\n",
    "                      model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me the expiration date for my current credit card'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(df_train['text'][0], label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expiration date 0.11\n",
      "pto request status 0.09\n",
      "what can i ask you 0.07\n",
      "change language 0.07\n",
      "date 0.07\n",
      "pto request 0.06\n",
      "reminder 0.05\n",
      "make call 0.04\n",
      "reminder update 0.03\n",
      "translate 0.02\n",
      "directions 0.02\n",
      "text 0.01\n",
      "share location 0.01\n",
      "maybe 0.01\n",
      "pto balance 0.01\n",
      "change accent 0.01\n",
      "repeat 0.01\n",
      "plug type 0.01\n",
      "pto used 0.01\n",
      "order 0.01\n",
      "replacement card duration 0.01\n",
      "order status 0.01\n",
      "sync device 0.01\n",
      "min payment 0.01\n",
      "goodbye 0.01\n",
      "definition 0.01\n",
      "spending history 0.01\n",
      "reset settings 0.01\n",
      "routing 0.01\n",
      "balance 0.01\n",
      "credit limit 0.0\n",
      "no 0.0\n",
      "timer 0.0\n",
      "time 0.0\n",
      "fun fact 0.0\n",
      "change volume 0.0\n",
      "change speed 0.0\n",
      "freeze account 0.0\n",
      "travel alert 0.0\n",
      "bill balance 0.0\n",
      "transactions 0.0\n",
      "mpg 0.0\n",
      "credit limit change 0.0\n",
      "jump start 0.0\n",
      "w2 0.0\n",
      "rewards balance 0.0\n",
      "pay bill 0.0\n",
      "whisper mode 0.0\n",
      "find phone 0.0\n",
      "carry on 0.0\n",
      "bill due 0.0\n",
      "accept reservations 0.0\n",
      "transfer 0.0\n",
      "last maintenance 0.0\n",
      "redeem rewards 0.0\n",
      "uber 0.0\n",
      "application status 0.0\n",
      "travel suggestion 0.0\n",
      "update playlist 0.0\n",
      "smart home 0.0\n",
      "todo list 0.0\n",
      "user name 0.0\n",
      "timezone 0.0\n",
      "measurement conversion 0.0\n",
      "gas type 0.0\n",
      "exchange rate 0.0\n",
      "distance 0.0\n",
      "pin change 0.0\n",
      "todo list update 0.0\n",
      "calculator 0.0\n",
      "change user name 0.0\n",
      "income 0.0\n",
      "confirm reservation 0.0\n",
      "change ai name 0.0\n",
      "travel notification 0.0\n",
      "yes 0.0\n",
      "greeting 0.0\n",
      "spelling 0.0\n",
      "interest rate 0.0\n",
      "cancel 0.0\n",
      "calendar update 0.0\n",
      "alarm 0.0\n",
      "credit score 0.0\n",
      "improve credit score 0.0\n",
      "current location 0.0\n",
      "report lost card 0.0\n",
      "order checks 0.0\n",
      "cook time 0.0\n",
      "ingredient substitution 0.0\n",
      "thank you 0.0\n",
      "schedule meeting 0.0\n",
      "schedule maintenance 0.0\n",
      "damaged card 0.0\n",
      "meal suggestion 0.0\n",
      "shopping list update 0.0\n",
      "what song 0.0\n",
      "meaning of life 0.0\n",
      "tell joke 0.0\n",
      "report fraud 0.0\n",
      "calendar 0.0\n",
      "cancel reservation 0.0\n",
      "restaurant suggestion 0.0\n",
      "flight status 0.0\n",
      "meeting schedule 0.0\n",
      "flip coin 0.0\n",
      "insurance change 0.0\n",
      "new card 0.0\n",
      "shopping list 0.0\n",
      "card declined 0.0\n",
      "ingredients list 0.0\n",
      "next song 0.0\n",
      "traffic 0.0\n",
      "direct deposit 0.0\n",
      "play music 0.0\n",
      "insurance 0.0\n",
      "book hotel 0.0\n",
      "payday 0.0\n",
      "recipe 0.0\n",
      "book flight 0.0\n",
      "gas 0.0\n",
      "oil change how 0.0\n",
      "calories 0.0\n",
      "who do you work for 0.0\n",
      "how busy 0.0\n",
      "what is your name 0.0\n",
      "car rental 0.0\n",
      "how old are you 0.0\n",
      "apr 0.0\n",
      "oil change when 0.0\n",
      "nutrition info 0.0\n",
      "do you have pets 0.0\n",
      "international fees 0.0\n",
      "tire pressure 0.0\n",
      "tire change 0.0\n",
      "roll dice 0.0\n",
      "are you a bot 0.0\n",
      "food last 0.0\n",
      "where are you from 0.0\n",
      "taxes 0.0\n",
      "lost luggage 0.0\n",
      "account blocked 0.0\n",
      "restaurant reviews 0.0\n",
      "weather 0.0\n",
      "restaurant reservation 0.0\n",
      "what are your hobbies 0.0\n",
      "international visa 0.0\n",
      "vaccines 0.0\n",
      "rollover 401k 0.0\n",
      "who made you 0.0\n",
      "next holiday 0.0\n"
     ]
    }
   ],
   "source": [
    "for l, s in zip(res['labels'], res['scores']):\n",
    "    print(l,round(s,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'would you disconnect from my phone'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = classifier(df_train['text'][1], label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance 0.08\n",
      "change language 0.07\n",
      "pto request 0.06\n",
      "cancel 0.05\n",
      "pto request status 0.05\n",
      "card declined 0.05\n",
      "goodbye 0.04\n",
      "what can i ask you 0.04\n",
      "account blocked 0.03\n",
      "maybe 0.03\n",
      "transfer 0.03\n",
      "find phone 0.02\n",
      "no 0.02\n",
      "confirm reservation 0.02\n",
      "accept reservations 0.02\n",
      "pto balance 0.02\n",
      "pto used 0.02\n",
      "change accent 0.02\n",
      "reset settings 0.01\n",
      "sync device 0.01\n",
      "change user name 0.01\n",
      "translate 0.01\n",
      "plug type 0.01\n",
      "balance 0.01\n",
      "reminder 0.01\n",
      "mpg 0.01\n",
      "w2 0.01\n",
      "text 0.01\n",
      "order status 0.01\n",
      "freeze account 0.01\n",
      "change speed 0.01\n",
      "share location 0.01\n",
      "change ai name 0.01\n",
      "user name 0.01\n",
      "order 0.01\n",
      "cancel reservation 0.01\n",
      "routing 0.01\n",
      "replacement card duration 0.01\n",
      "current location 0.01\n",
      "change volume 0.0\n",
      "definition 0.0\n",
      "repeat 0.0\n",
      "application status 0.0\n",
      "damaged card 0.0\n",
      "min payment 0.0\n",
      "alarm 0.0\n",
      "apr 0.0\n",
      "yes 0.0\n",
      "uber 0.0\n",
      "make call 0.0\n",
      "jump start 0.0\n",
      "timer 0.0\n",
      "time 0.0\n",
      "whisper mode 0.0\n",
      "pin change 0.0\n",
      "gas type 0.0\n",
      "rewards balance 0.0\n",
      "timezone 0.0\n",
      "new card 0.0\n",
      "tell joke 0.0\n",
      "date 0.0\n",
      "transactions 0.0\n",
      "thank you 0.0\n",
      "last maintenance 0.0\n",
      "what song 0.0\n",
      "travel alert 0.0\n",
      "spelling 0.0\n",
      "meaning of life 0.0\n",
      "spending history 0.0\n",
      "ingredient substitution 0.0\n",
      "travel suggestion 0.0\n",
      "expiration date 0.0\n",
      "flip coin 0.0\n",
      "smart home 0.0\n",
      "direct deposit 0.0\n",
      "greeting 0.0\n",
      "gas 0.0\n",
      "how busy 0.0\n",
      "income 0.0\n",
      "credit limit 0.0\n",
      "meal suggestion 0.0\n",
      "calendar 0.0\n",
      "credit limit change 0.0\n",
      "reminder update 0.0\n",
      "what are your hobbies 0.0\n",
      "international fees 0.0\n",
      "bill due 0.0\n",
      "fun fact 0.0\n",
      "cook time 0.0\n",
      "directions 0.0\n",
      "calculator 0.0\n",
      "travel notification 0.0\n",
      "exchange rate 0.0\n",
      "do you have pets 0.0\n",
      "order checks 0.0\n",
      "carry on 0.0\n",
      "measurement conversion 0.0\n",
      "calendar update 0.0\n",
      "update playlist 0.0\n",
      "where are you from 0.0\n",
      "ingredients list 0.0\n",
      "book hotel 0.0\n",
      "schedule meeting 0.0\n",
      "calories 0.0\n",
      "schedule maintenance 0.0\n",
      "book flight 0.0\n",
      "redeem rewards 0.0\n",
      "next song 0.0\n",
      "todo list 0.0\n",
      "bill balance 0.0\n",
      "who do you work for 0.0\n",
      "are you a bot 0.0\n",
      "roll dice 0.0\n",
      "payday 0.0\n",
      "pay bill 0.0\n",
      "report fraud 0.0\n",
      "restaurant suggestion 0.0\n",
      "tire change 0.0\n",
      "tire pressure 0.0\n",
      "recipe 0.0\n",
      "interest rate 0.0\n",
      "todo list update 0.0\n",
      "flight status 0.0\n",
      "weather 0.0\n",
      "rollover 401k 0.0\n",
      "report lost card 0.0\n",
      "insurance change 0.0\n",
      "traffic 0.0\n",
      "international visa 0.0\n",
      "credit score 0.0\n",
      "improve credit score 0.0\n",
      "oil change when 0.0\n",
      "what is your name 0.0\n",
      "oil change how 0.0\n",
      "meeting schedule 0.0\n",
      "lost luggage 0.0\n",
      "next holiday 0.0\n",
      "car rental 0.0\n",
      "food last 0.0\n",
      "insurance 0.0\n",
      "play music 0.0\n",
      "restaurant reviews 0.0\n",
      "restaurant reservation 0.0\n",
      "who made you 0.0\n",
      "how old are you 0.0\n",
      "shopping list 0.0\n",
      "vaccines 0.0\n",
      "shopping list update 0.0\n",
      "nutrition info 0.0\n",
      "taxes 0.0\n"
     ]
    }
   ],
   "source": [
    "for l, s in zip(res['labels'], res['scores']):\n",
    "    print(l,round(s,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "ABSTAIN = -1\n",
    "\n",
    "@labeling_function()\n",
    "def r1(x):\n",
    "    pass\n",
    "\n",
    "@labeling_function()\n",
    "def r2(x):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:00<00:00, 4043.30it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [r1, r2, r3, r4, r5, r6, r7, r8,r9,r10, r11, r12, r13, r14, r15, r16, r17, r18]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverages:\n",
      "  r1: 0.50%\n",
      "  r2: 2.25%\n",
      "  r3: 99.25%\n",
      "  r4: 21.62%\n",
      "  r5: 0.19%\n",
      "  r6: 0.88%\n",
      "  r7: 0.81%\n",
      "  r8: 0.19%\n",
      "  r9: 0.00%\n",
      "  r10: 0.00%\n",
      "  r11: 0.00%\n",
      "  r12: 0.00%\n",
      "  r13: 0.00%\n",
      "  r14: 0.12%\n",
      "  r15: 0.00%\n",
      "  r16: 0.00%\n",
      "  r17: 0.00%\n",
      "  r18: 0.12%\n"
     ]
    }
   ],
   "source": [
    "coverages = (L_train != ABSTAIN).mean(axis=0)\n",
    "print(\"Coverages:\")\n",
    "for  cov, lf in zip(coverages, lfs):\n",
    "    print(\"  {}: {:.2f}%\".format(lf.name, 100*cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.021250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r3</th>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.021250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r4</th>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.216250</td>\n",
       "      <td>0.215625</td>\n",
       "      <td>0.003750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r5</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r6</th>\n",
       "      <td>5</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r7</th>\n",
       "      <td>6</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r8</th>\n",
       "      <td>7</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r9</th>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r10</th>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r11</th>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r12</th>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r13</th>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r14</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r15</th>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r16</th>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r17</th>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r18</th>\n",
       "      <td>17</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      j Polarity  Coverage  Overlaps  Conflicts\n",
       "r1    0      [1]  0.005000  0.001875   0.000625\n",
       "r2    1      [1]  0.022500  0.022500   0.021250\n",
       "r3    2      [2]  0.992500  0.253125   0.021250\n",
       "r4    3      [2]  0.216250  0.215625   0.003750\n",
       "r5    4      [2]  0.001875  0.001875   0.000000\n",
       "r6    5      [2]  0.008750  0.008750   0.000000\n",
       "r7    6      [2]  0.008125  0.008125   0.000625\n",
       "r8    7      [2]  0.001875  0.001875   0.000000\n",
       "r9    8       []  0.000000  0.000000   0.000000\n",
       "r10   9       []  0.000000  0.000000   0.000000\n",
       "r11  10       []  0.000000  0.000000   0.000000\n",
       "r12  11       []  0.000000  0.000000   0.000000\n",
       "r13  12       []  0.000000  0.000000   0.000000\n",
       "r14  13      [0]  0.001250  0.001250   0.000000\n",
       "r15  14       []  0.000000  0.000000   0.000000\n",
       "r16  15       []  0.000000  0.000000   0.000000\n",
       "r17  16       []  0.000000  0.000000   0.000000\n",
       "r18  17      [0]  0.001250  0.001250   0.000000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_voter = RandomVoter(cardinality=3)\n",
    "preds_train = random_voter.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_model = MajorityLabelVoter(cardinality=3)\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.632]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.001]\n",
      " 31%|███       | 155/500 [00:00<00:00, 1547.64epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 63%|██████▎   | 317/500 [00:00<00:00, 1566.89epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1534.59epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "label_model = LabelModel(cardinality=3, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 3856.67it/s]\n"
     ]
    }
   ],
   "source": [
    "L_test = applier.apply(df=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Model Accuracy:    32.1%\n",
      "Majority Vote Accuracy:   34.0%\n",
      "Label Model Accuracy:     33.8%\n"
     ]
    }
   ],
   "source": [
    "random_model_acc = random_voter.score(L=L_test, Y=df_test['label_number'], tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Random Model Accuracy:':<25} {random_model_acc * 100:.1f}%\")\n",
    "\n",
    "majority_acc = majority_model.score(L=L_test, Y=df_test['label_number'], tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=df_test['label_number'], tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_label_frequency(L):\n",
    "    plt.hist((L != ABSTAIN).sum(axis=1), density=True, bins=range(L.shape[1]))\n",
    "    plt.xlabel(\"Number of labels\")\n",
    "    plt.ylabel(\"Fraction of dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_label_frequency(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATION:\n",
    " - Most of labels doesnot triggered\n",
    " - Label 1 has the highest coverage and effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAa6ElEQVR4nO3df7xVVZ3/8ddbiPyRiQo5ChRUWA81Tbo6lDOK2g/REUwz5WsJDMXUUNlYk2hNVj4aNUZNv5p+SU34Zpq/JkkpB0nUfqBe/I0/EgkVRvGOP4hSIfQzf+x143i99+x9L3efsy/3/Xw8zuPuvfY6e384Xu/nrLX2XksRgZmZWT1bNDsAMzOrPicLMzPL5WRhZma5nCzMzCyXk4WZmeUa2OwAyjBkyJAYOXJks8MwM+tTlixZ8j8RMbSzY5tlshg5ciStra3NDsPMrE+R9ERXx9wNZWZmuZwszMwsl5OFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuUp7glvSpcA/AM9GxB6pbBZwOLAeeByYGhEvpmMnA9OAV4EvRcRNqfwQ4FxgAHBxRJxRVszWeCNn3tiU664447CmXNesryqzZXEZcEiHsgXAHhGxJ/B74GQASbsBxwK7p/f8QNIASQOAC4DxwG7ApFTXzMwaqLRkERG3Ac93KPuviNiQdhcDw9P2RODKiFgXEX8AlgH7pteyiFgeEeuBK1NdMzNroGaOWfwj8Iu0PQx4qubYylTWVbmZmTVQU5KFpK8DG4DLe/Gc0yW1Smpta2vrrdOamRlNSBaSppANfB8XEZGKVwEjaqoNT2Vdlb9BRMyOiJaIaBk6tNPp2M3MrIcamizSnU1fAyZExEs1h+YBx0p6s6RRwGjgTuAuYLSkUZIGkQ2Cz2tkzGZmVu6ts1cA44AhklYCp5Ld/fRmYIEkgMUR8bmIWCrpKuAhsu6pGRHxajrPF4CbyG6dvTQilpYVs5mZda60ZBERkzopvqRO/e8C3+2kfD4wvxdDMzOzbvIT3GZmlsvJwszMcjlZmJlZLicLMzPL5WRhZma5nCzMzCyXk4WZmeVysjAzs1xOFmZmlsvJwszMcjlZmJlZLicLMzPL5WRhZma5nCzMzCyXk4WZmeVysjAzs1xOFmZmlsvJwszMcjlZmJlZLicLMzPL5WRhZma5nCzMzCyXk4WZmeVysjAzs1xOFmZmlqu0ZCHpUknPSnqwpmwHSQskPZZ+bp/KJek8Scsk3S9pTM17Jqf6j0maXFa8ZmbWtTJbFpcBh3QomwksjIjRwMK0DzAeGJ1e04ELIUsuwKnA3wL7Aqe2JxgzM2uc0pJFRNwGPN+heCIwJ23PAY6oKZ8bmcXAYEk7Ax8DFkTE8xHxArCANyYgMzMrWaPHLHaKiKfT9jPATml7GPBUTb2VqayrcjMza6CmDXBHRADRW+eTNF1Sq6TWtra23jqtmZnR+GSxOnUvkX4+m8pXASNq6g1PZV2Vv0FEzI6IlohoGTp0aK8HbmbWnzU6WcwD2u9omgxcX1N+fLoraiywJnVX3QR8VNL2aWD7o6nMzMwaaGBZJ5Z0BTAOGCJpJdldTWcAV0maBjwBfDJVnw8cCiwDXgKmAkTE85JOA+5K9b4TER0Hzc3MrGSlJYuImNTFoYM7qRvAjC7OcylwaS+GZmZm3eQnuM3MLFduspC0n6Rt0vanJJ0t6R3lh2ZmZlVRpGVxIfCSpL2ArwCPA3NLjcrMzCqlSLLYkMYUJgLnR8QFwLblhmVmZlVSZIB7raSTgU8B+0vaAnhTuWGZmVmVFGlZHAOsA6ZFxDNkD8bNKjUqMzOrlCIti3+JiJPadyLiSUm7lxiTmZlVTJGWxUc6KRvf24GYmVl1ddmykPR54J+Bd0q6v+bQtsBvyw7MzMyqo1431E+AXwCns3GRIoC1nnLDzKx/6TJZRMQaYA0wSdIAsrUnBgJvkfSWiHiyQTGamVmT5Q5wS/oC8C1gNfBaKg5gz/LCMjOzKilyN9SXgfdExHMlx2JmZhVV5G6op8i6o8zMrJ8q0rJYDiySdCPZw3kARMTZpUVlZmaVUiRZPJleg9LLzMz6mdxkERHfbkQgZmZWXfUeyvt+RHxZ0s/J7n56nYiYUGpkZmZWGfVaFv8//fyPRgRiZmbVVe+hvCXp562SBgG7pkOPRsRfGhGcmZlVQ5GH8sYBc4AVgIARkiZHxG2lRmZmZpVR5G6os4CPRsSjAJJ2Ba4APlBmYGZmVh1FHsp7U3uiAIiI3+OV8szM+pUiLYtWSRcDP077xwGt5YVkZmZVUyRZfB6YAXwp7d8O/KC0iMzMrHKKPJS3TtL5wEKyWWcfjYj1m3JRSf8CfIbs+Y0HgKnAzsCVwI7AEuDTEbFe0puBuWRjJM8Bx0TEik25vpmZdU/umIWkw4DHgXOB84Flknq8rKqkYWStlJaI2AMYABwLnAmcExHvBl4ApqW3TANeSOXnpHpmZtZARQa4zwIOjIhxEXEAcCDZH+1NMRDYStJAYGvgaeAg4Jp0fA5wRNqemPZJxw+WpE28vpmZdUORZLE2IpbV7C8H1vb0ghGxiuyp8CfJksQasm6nFyNiQ6q2EhiWtoeRTZNOOr6GrKvqdSRNl9QqqbWtra2n4ZmZWSeKJItWSfMlTZE0Gfg5cJekIyUd2d0LStqerLUwCtgF2AY4pLvn6SgiZkdES0S0DB06dFNPZ2ZmNYrcDbUl2ZKqB6T9NmAr4HCyAerrunnNDwN/iIg2AEnXAfsBgyUNTK2H4cCqVH8VMAJYmbqttiMb6DYzswYpcjfU1F6+5pPAWElbAy8DB5M9t3EL8AmyO6ImA9en+vPS/u/S8V9FxBtmwTUzs/IU6YbqVRFxB9lA9d1kt81uAcwGTgJOlLSMbEzikvSWS4AdU/mJwMxGx2xm1t8V6YbqdRFxKnBqh+LlwL6d1H0FOLoRcZmZWeca3rIwM7O+p1DLIj2YtzvZYDcAEfGdsoIyM7NqKfIE90XAMcAXydazOBp4R8lxmZlZhRTphvpQRBxPNuXGt4EPsnHVPDMz6weKJIuX08+XJO0C/IVs0j8zM+snioxZ3CBpMDCL7HbXAC4uMygzM6uWIsniexGxDrhW0g1kg9yvlBuWmZlVSZFuqN+1b0TEuohYU1tmZmabvy5bFpL+hmzG160k7U12JxTAW8mmFTczs36iXjfUx4ApZJP6nV1TvhY4pcSYzMysYrpMFhExB5gj6aiIuLaBMZmZWcUUmXX2Wj/BbWbWv/kJbjMzy+UnuM3MLJef4DYzs1x+gtvMzHIVGeA+LW3+9Qnu9GCemZn1E/UeyjuyzjEi4rpyQjIzs6qp17I4PP18G/Ah4Fdp/0Dgt4CThZlZP1HvobypAJL+C9gtIp5O+zsDlzUkOjMzq4Qid0ONaE8UyWrg7SXFY2ZmFVTkbqiFkm4Crkj7xwA3lxeSmZlVTZG7ob4g6ePA/qlodkT8Z7lhmZlZlRRpWZCSgxOEmVk/VWTMwszM+rmmJAtJgyVdI+kRSQ9L+qCkHSQtkPRY+rl9qitJ50laJul+SWOaEbOZWX/WZbKQtDD9PLOE654L/DIi3gvsBTwMzAQWRsRoYGHaBxgPjE6v6cCFJcRjZmZ11Buz2FnSh4AJkq5k47KqAETE3T25oKTtyAbLp6TzrAfWS5oIjEvV5gCLgJOAicDciAhgcWqV7Nzhdl4zMytRvWTxTeDfeOOyqpBNJnhQD685CmgDfiRpL2AJcAKwU00CeAbYKW0PA56qef/KVPa6ZCFpOlnLg7e/3Y+BmJn1pi67oSLimogYD3wvIg7s8OppooAsQY0BLoyIvYE/s7HLqf3aQZaQCouI2RHREhEtQ4cO3YTwzMyso0KzzkqawMbnLBZFxA2bcM2VwMqIuCPtX0OWLFa3dy+lKUWeTcdXASNq3j88lZmZWYMUWVb1dLJuoofS6wRJ/97TC0bEM8BTkt6Tig5O550HTE5lk4Hr0/Y84Ph0V9RYYI3HK8zMGqvIQ3mHAe+PiNcAJM0B7gFO2YTrfhG4XNIgYDkwlSxxXSVpGvAE8MlUdz5wKLAMeCnVNTOzBir0BDcwGHg+bW+3qReNiHuBlk4OHdxJ3QBmbOo1zcys54oki9OBeyTdQnb77P50GJA2M7PNW5EB7iskLQL2SUUnpXEHMzPrJ4pOJPg02UCzmZn1Q55I0MzMcjlZmJlZrrrJQtIASY80KhgzM6umuskiIl4FHpXkyZbMzPqxIgPc2wNLJd1JNo8TABExobSozMysUooki38rPQozM6u0Is9Z3CrpHcDoiLhZ0tbAgPJDMzOzqigykeBnyWaG/X+paBjwsxJjMjOziily6+wMYD/gjwAR8RjwtjKDMjOzaimSLNalpU8BkDSQbi5MZGZmfVuRZHGrpFOArSR9BLga+Hm5YZmZWZUUSRYzydbMfgD4J7L1Jb5RZlBmZlYtRe6Gei0teHQHWffTo2mNCTMz6ydyk4Wkw4CLgMfJ1rMYJemfIuIXZQdnZmbVUOShvLOAAyNiGYCkdwE3Ak4WZmb9RJExi7XtiSJZDqwtKR4zM6ugLlsWko5Mm62S5gNXkY1ZHA3c1YDYzMysIup1Qx1es70aOCBttwFblRaRmZlVTpfJIiKmNjIQMzOrriJ3Q40CvgiMrK3vKcrNzPqPIndD/Qy4hOyp7ddKjcbMzCqpSLJ4JSLOKz0SMzOrrCK3zp4r6VRJH5Q0pv21qRdO63vfI+mGtD9K0h2Slkn6qaRBqfzNaX9ZOj5yU69tZmbdU6Rl8T7g08BBbOyGirS/KU4AHgbemvbPBM6JiCslXQRMAy5MP1+IiHdLOjbVO2YTr21mZt1QpGVxNPDOiDggIg5Mr01KFJKGA4cBF6d9kSWfa1KVOcARaXti2icdPzjVNzOzBimSLB4EBvfydb8PfI2NLZUdgRcjYkPaX0m2Ih/p51MA6fiaVP91JE2X1Cqpta2trZfDNTPr34p0Qw0GHpF0F7CuvbCnt85K+gfg2YhYImlcT87RmYiYDcwGaGlp8ay4Zma9qEiyOLWXr7kfMEHSocCWZGMW5wKDJQ1MrYfhwKpUfxUwAliZVunbDniul2MyM7M6iqxncWtvXjAiTgZOBkgti69GxHGSrgY+AVwJTAauT2+Zl/Z/l47/yutpmJk1Vu6YhaS1kv6YXq9IelXSH0uI5STgREnLyMYkLknllwA7pvITyVbuMzOzBirSsti2fTvdhTQRGNsbF4+IRcCitL0c2LeTOq+Q3ZFlZmZNUuRuqL+KzM+Aj5UTjpmZVVGRiQSPrNndAmgBXiktIjMzq5wid0PVrmuxAVhB1hVlZmb9RJExC69rYWbWz9VbVvWbdd4XEXFaCfFYk4yceWOzQzCzCqvXsvhzJ2XbkE3styPgZGFm1k/UW1b1rPZtSduSzRI7leyhubO6ep+ZmW1+6o5ZSNqB7EG448hmfh0TES80IjAzM6uOemMWs4AjySbne19E/KlhUZmZWaXUeyjvK8AuwDeA/66Z8mNtSdN9mJlZRdUbs+jW091mZrb5ckIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuZwszMwsl5OFmZnlcrIwM7NcThZmZpbLycLMzHI5WZiZWS4nCzMzy+VkYWZmuRqeLCSNkHSLpIckLZV0QirfQdICSY+ln9unckk6T9IySfdLGtPomM3M+rtmtCw2AF+JiN2AscAMSbsBM4GFETEaWJj2AcYDo9NrOnBh40M2M+vfGp4sIuLpiLg7ba8FHgaGARPJ1vkm/TwibU8E5kZmMTBY0s6NjdrMrH9r6piFpJHA3sAdwE4R8XQ69AywU9oeBjxV87aVqazjuaZLapXU2tbWVl7QZmb9UNOShaS3ANcCX46I163pHREBRHfOFxGzI6IlIlqGDh3ai5GamVlTkoWkN5Elissj4rpUvLq9eyn9fDaVrwJG1Lx9eCozM7MGacbdUAIuAR6OiLNrDs0DJqftycD1NeXHp7uixgJrarqrzMysAQY24Zr7AZ8GHpB0byo7BTgDuErSNOAJ4JPp2HzgUGAZ8BIwtaHRmplZ45NFRPwaUBeHD+6kfgAzSg3KzMzq8hPcZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwszM8vlZGFmZrmcLMzMLNfAZgdQRSNn3tiU664447CmXNfMLI9bFmZmlsvJwszMcvWZZCHpEEmPSlomaWaz4zEz60/6RLKQNAC4ABgP7AZMkrRbc6MyM+s/+kSyAPYFlkXE8ohYD1wJTGxyTGZm/UZfuRtqGPBUzf5K4G9rK0iaDkxPu3+S9GgvXn8I8D+9eL5O6cxeP2VD4i5B6XGX8FmDP+9Gc9y97x1dHegrySJXRMwGZpdxbkmtEdFSxrnL5Lgby3E3luNurL7SDbUKGFGzPzyVmZlZA/SVZHEXMFrSKEmDgGOBeU2Oycys3+gT3VARsUHSF4CbgAHApRGxtIEhlNK91QCOu7Ecd2M57gZSRDQ7BjMzq7i+0g1lZmZN5GRhZma5nCxq5E0pIml/SXdL2iDpE82IsTMF4j5R0kOS7pe0UFKX91I3UoG4PyfpAUn3Svp1VZ7aLzr1jKSjJIWkStwmWeDzniKpLX3e90r6TDPi7KjI5y3pk+l3fKmknzQ6xs4U+LzPqfmsfy/pxSaEWVxE+JWN2wwAHgfeCQwC7gN261BnJLAnMBf4RLNj7kbcBwJbp+3PAz/tI3G/tWZ7AvDLvhB3qrctcBuwGGjpC3EDU4Dzmx1rD+IeDdwDbJ/239YX4u5Q/4tkN+40/TPv6uWWxUa5U4pExIqIuB94rRkBdqFI3LdExEtpdzHZcyrNViTuP9bsbgNU4W6MolPPnAacCbzSyODq6KtT5hSJ+7PABRHxAkBEPNvgGDvT3c97EnBFQyLrISeLjTqbUmRYk2Lpju7GPQ34RakRFVMobkkzJD0OfA/4UoNiqyc3bkljgBER0ZxVtDpX9PfkqNRdeY2kEZ0cb7Qice8K7CrpN5IWSzqkYdF1rfD/l6lbeBTwqwbE1WNOFv2IpE8BLcCsZsdSVERcEBHvAk4CvtHsePJI2gI4G/hKs2PpgZ8DIyNiT2ABMKfJ8RQ1kKwrahzZN/QfShrczIC66Vjgmoh4tdmB1ONksVFfnVKkUNySPgx8HZgQEesaFFs93f28rwSOKDOggvLi3hbYA1gkaQUwFphXgUHu3M87Ip6r+d24GPhAg2Krp8jvyUpgXkT8JSL+APyeLHk0U3d+v4+l4l1QgAe4219k306WkzUH2wekdu+i7mVUZ4A7N25gb7LBttHNjrebcY+u2T4caO0LcXeov4hqDHAX+bx3rtn+OLC4j8R9CDAnbQ8h6/7Zsepxp3rvBVaQHpCu8qvpAVTpBRxK9q3kceDrqew7ZN/GAfYh+xbzZ+A5YGmzYy4Y983AauDe9JrX7JgLxn0usDTFfEu9P8pVirtD3Uoki4Kf9+np874vfd7vbXbMBeMWWdffQ8ADwLHNjrno7wnwLeCMZsda5OXpPszMLJfHLMzMLJeThZmZ5XKyMDOzXE4WZmaWy8nCzMxyOVmYmVkuJwtrCkmvpqmZH5R0taStu/HeKZLO7+b1/tRF+XfS0+1IWtT+pLWk+ZIGp9c/d+daOXHMStNoz+pQPkXSa5L2rCl7UNLI3rp2Oufx6bwPSLpH0le7qPc5ScfXxLZLzbGLezJdvKRxkm7oefTWTE4W1iwvR8T7I2IPYD3wudqDkhqyPnxEfDMibu6k/NCIeBEYDPRasgCmA3tGxL92cmwl2ZQspZA0Hvgy8NGIeB/ZVCRrOqk3MCIuioi5qWgK8NdkERGfiYiHyorTqsnJwqrgduDd6Zvn7ZLmAQ9J2lLSj2q+BR9Y854RqSXwmKRT2wsl/UzSkvTtfXrtRdJiM0vTAlBDU9llnS1kJWmFpCHAGcC7UitolqS5ko6oqXe5pIkd3qtUt/0b/DGpfB7wFmBJe1kHNwC7S3pPJ/FMSud6UNKZNeV/kvRdSfelGVd36vpj5mTgqxHx3wARsS4ifpjOs0jS9yW1AidI+pakr6bPpgW4PH0GW3VogR2ibEGw+yQtTGX7Svpd+m/2287+Pdb3OFlYU6UWxHiyaRoAxgAnRMSuwAwg0rfgScAcSVumevsCR5EtRnV0zUR9/xgRHyD7A/clSTum8m3I5pbaHbgV+GuCyTETeDy1gv4VuITsmzaStgM+BHScivxI4P3AXsCHgVmSdo6ICWxsUf20k2u9RjYV+ykdPqNdyNbGOCidd5+ahLUN2RxOe5EttvTZOv+WPYAldY4PioiWiDirvSAirgFageNS3C/XxDUU+CFwVLr+0enQI8DfR8TewDeBf69zTesjnCysWbaSdC/ZH6Inyf4IA9wZ2cyhAH8H/BggIh4BniBbuwBgQWSzpL4MXJfqQpYg7iNb5GkEG2cffQ1o/wP945r63RIRtwKj0x/KScC1EbGhQ7W/A66IiFcjYjVZctqn4CV+AoyVNKqmbB9gUUS0pWtdDuyfjq0na5FAlghGdvffVKOzBFbPWOC29v9eEfF8Kt8OuFrSg8A5wO6bEJNVREP6hc068XJEvL+2QBJkkzQW0XFSs5A0juyb/Acj4iVJi4At6dymTIo2F/gU2dTSUzfhPG8QERsknUW2fkcRf4mNE7y9Sv3/p5eSTTve1SI7RT/7PKcBt0TEx9MA/aJeOq81kVsWVmW3A8cBSNoVeDvwaDr2EUk7SNqKbJ2L35B9o30hJYr3kn3zbbcF0D428X+AXxeMYS3ZGhW1LiMbKKaLgd7bgWMkDUgtkP2BOwter/38HwaGpv07gQMkDZE0gKxFc2s3ztfudLIusb8BkDRI0mcKvK+zzwCy1tv+7a0gSTuk8u3YuHbDlB7EaRXkZGFV9gNgC0kPkHWRTImNi/PcCVwL3E/WFdQK/BIYKOlhsoHpxTXn+jOwb+oaOYhsquhcEfEc8Js0sDwrla0GHgZ+1MXb/jPFdR/Zt/ivRcQzBf/NRLZm83nA29L+02RjJ7ekcy6JiOuLnq/mvPOB84GbJS0F7gbeWuCtlwEXtQ9w15yvjezurutS1197N9b3gNMl3YN7LzYbnqLcrJuUPRPyADAmIt5w66nZ5sgtC7NuUPYA38PA/3WisP7ELQuzzYykr7PxNtZ2V0fEd5sRj20enCzMzCyXu6HMzCyXk4WZmeVysjAzs1xOFmZmlut/AeP0uyTAumu6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plot_probabilities_histogram(Y, col):\n",
    "    plt.hist(Y, bins=10)\n",
    "    plt.xlabel(\"Probability of \" + col)\n",
    "    plt.ylabel(\"Number of data points\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "plot_probabilities_histogram(probs_train[:, Critical], 'Critical')\n",
    "plot_probabilities_histogram(probs_train[:, Non_Critical], 'Non_Critical')\n",
    "plot_probabilities_histogram(probs_train[:, Inconclusive], 'Inconclusive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")\n",
    "df_train_filtered[['text','label', 'label1','label2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tayfun.tuna/opt/anaconda3/envs/astra/lib/python3.6/site-packages/pandas/core/series.py:4535: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_filtered['label1'].fillna('no-label',inplace=True)\n",
    "df_train_filtered['label2'].fillna('no-label',inplace=True)\n",
    "\n",
    "df_train_filtered[['text','label', 'label1','label2']][df_train_filtered['label1']=='no-label']['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs_train = label_model.predict_proba(L=L_test)\n",
    "plot_probabilities_histogram(probs_train[:, Critical], 'Critical')\n",
    "plot_probabilities_histogram(probs_train[:, Non_Critical], 'Non_Critical')\n",
    "plot_probabilities_histogram(probs_train[:, Inconclusive], 'Inconclusive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tayfun.tuna/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 152925), (1599,))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, preds_train_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=df_test['label_number'].values) * 100:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "def clf_metric_AImp(y_test,y_pred, y_pred_prob, T_num):\n",
    "    res = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    roc_list = []\n",
    "    occ_list = []\n",
    "    prc_list = []\n",
    "    tgt_list = []\n",
    "    igr = 0\n",
    "    for tgt in range(T_num):\n",
    "        y_test2 = [1 if i == tgt else 0 for i in y_test]\n",
    "        y_pred2 = [1 if i == tgt else 0 for i in y_pred]\n",
    "        y_pred_prob2 = [i[tgt] for i in y_pred_prob]\n",
    "        try:\n",
    "            roc_list.append(roc_auc_score(y_test2, y_pred_prob2))\n",
    "            occ_list.append((y_test == tgt).sum())\n",
    "            precision, recall, thresholds = precision_recall_curve(y_test2, y_pred_prob2)\n",
    "            prc_list.append(auc(recall, precision))\n",
    "            tgt_list.append(str(tgt))\n",
    "        except ValueError:\n",
    "            print(\"Only one class present in y_test2. Ignoring this class\")\n",
    "            igr = igr + 1\n",
    "    \n",
    "    roc_macro = np.average(roc_list)\n",
    "    roc_weighted = np.average(roc_list, weights=occ_list)\n",
    "    prc_macro = np.average(prc_list)\n",
    "    prc_weighted = np.average(prc_list, weights=occ_list)\n",
    "    \n",
    "    df_roc_prc = pd.DataFrame(list(zip(roc_list, prc_list)),index = tgt_list,\n",
    "               columns =['AUROC', 'AUPRC'])\n",
    "    df_roc_prc.loc['accuracy'] = [None, None]\n",
    "    df_roc_prc.loc['macro avg'] = [roc_macro, prc_macro]\n",
    "    df_roc_prc.loc['weighted avg'] = [roc_weighted, prc_weighted]\n",
    "\n",
    "    res = pd.concat([res, df_roc_prc], axis=1)\n",
    "    res.at[\"accuracy\",\"precision\"] = None\n",
    "    res.at[\"accuracy\",\"recall\"] = None\n",
    "    res.at[\"accuracy\",\"support\"] = max(res.support)\n",
    "    res = res[res.support != 0]\n",
    "    return res, igr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.12862002e-05, 5.38137717e-05, 9.99914900e-01],\n",
       "       [1.78566820e-05, 4.62629446e-04, 9.99519514e-01],\n",
       "       [8.48665677e-04, 1.63651089e-03, 9.97514823e-01],\n",
       "       ...,\n",
       "       [1.80444938e-04, 2.85580016e-02, 9.71261553e-01],\n",
       "       [1.99933176e-07, 1.49158935e-03, 9.98508211e-01],\n",
       "       [5.51724263e-06, 4.60784422e-05, 9.99948404e-01]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tayfun.tuna/opt/anaconda3/envs/astra/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.552851</td>\n",
       "      <td>0.553673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.483143</td>\n",
       "      <td>0.153164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341709</td>\n",
       "      <td>0.992701</td>\n",
       "      <td>0.508411</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>0.397587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341250</td>\n",
       "      <td>800.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.197236</td>\n",
       "      <td>0.333588</td>\n",
       "      <td>0.174679</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.535446</td>\n",
       "      <td>0.368141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.155785</td>\n",
       "      <td>0.341250</td>\n",
       "      <td>0.176553</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.548037</td>\n",
       "      <td>0.438135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support     AUROC     AUPRC\n",
       "0              0.000000  0.000000  0.000000    402.0  0.552851  0.553673\n",
       "1              0.250000  0.008065  0.015625    124.0  0.483143  0.153164\n",
       "2              0.341709  0.992701  0.508411    274.0  0.570342  0.397587\n",
       "accuracy            NaN       NaN  0.341250    800.0       NaN       NaN\n",
       "macro avg      0.197236  0.333588  0.174679    800.0  0.535446  0.368141\n",
       "weighted avg   0.155785  0.341250  0.176553    800.0  0.548037  0.438135"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_num = 3 #Number of classes\n",
    "y_pred_prob = sklearn_model.predict_proba(X_test)\n",
    "y_test = df_test['label_number'].values\n",
    "y_pred = sklearn_model.predict(X_test)\n",
    "res, igr = clf_metric_AImp(y_test,y_pred, y_pred_prob, T_num)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from snorkel.augmentation import transformation_function\n",
    "\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \"\"\"Get the synonyms of word from Wordnet.\"\"\"\n",
    "    lemmas = set().union(*[s.lemmas() for s in wn.synsets(word)])\n",
    "    return list(set(l.name().lower().replace(\"_\", \" \") for l in lemmas) - {word})\n",
    "\n",
    "\n",
    "@transformation_function()\n",
    "def tf_replace_word_with_synonym(x):\n",
    "    \"\"\"Try to replace a random word with a synonym.\"\"\"\n",
    "    words = x.text.lower().split()\n",
    "    idx = random.choice(range(len(words)))\n",
    "    synonyms = get_synonyms(words[idx])\n",
    "    if len(synonyms) > 0:\n",
    "        x.text = \" \".join(words[:idx] + [synonyms[0]] + words[idx + 1 :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/4554 [00:00<?, ?it/s]\u001b[A\n",
      " 21%|██▏       | 978/4554 [00:00<00:00, 9772.88it/s]\u001b[A\n",
      " 45%|████▌     | 2067/4554 [00:00<00:00, 10082.43it/s]\u001b[A\n",
      " 70%|███████   | 3195/4554 [00:00<00:00, 10413.97it/s]\u001b[A\n",
      "100%|██████████| 4554/4554 [00:00<00:00, 10683.32it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier\n",
    "\n",
    "tf_policy = ApplyOnePolicy(n_per_original=0, keep_original=True)\n",
    "tf_applier = PandasTFApplier([tf_replace_word_with_synonym], tf_policy)\n",
    "df_train_augmented = tf_applier.apply(df_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4554, 3)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_augmented.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUSE embedding for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 1min 7s, total: 3min 27s\n",
      "Wall time: 54.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vec0</th>\n",
       "      <th>vec1</th>\n",
       "      <th>vec2</th>\n",
       "      <th>vec3</th>\n",
       "      <th>vec4</th>\n",
       "      <th>vec5</th>\n",
       "      <th>vec6</th>\n",
       "      <th>vec7</th>\n",
       "      <th>vec8</th>\n",
       "      <th>vec9</th>\n",
       "      <th>...</th>\n",
       "      <th>vec504</th>\n",
       "      <th>vec505</th>\n",
       "      <th>vec506</th>\n",
       "      <th>vec507</th>\n",
       "      <th>vec508</th>\n",
       "      <th>vec509</th>\n",
       "      <th>vec510</th>\n",
       "      <th>vec511</th>\n",
       "      <th>sys_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.059866</td>\n",
       "      <td>-0.001436</td>\n",
       "      <td>-0.109919</td>\n",
       "      <td>-0.095510</td>\n",
       "      <td>0.074394</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>0.085519</td>\n",
       "      <td>-0.034903</td>\n",
       "      <td>0.045007</td>\n",
       "      <td>0.064680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>-0.006976</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>0.021821</td>\n",
       "      <td>-0.081722</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>2148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.027004</td>\n",
       "      <td>0.013067</td>\n",
       "      <td>-0.085010</td>\n",
       "      <td>-0.033053</td>\n",
       "      <td>0.027256</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>0.071584</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.067493</td>\n",
       "      <td>0.012164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096953</td>\n",
       "      <td>0.048307</td>\n",
       "      <td>-0.024828</td>\n",
       "      <td>-0.034587</td>\n",
       "      <td>-0.039312</td>\n",
       "      <td>0.090378</td>\n",
       "      <td>-0.013480</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.033173</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>0.078843</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.041389</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.036849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>-0.075504</td>\n",
       "      <td>0.019888</td>\n",
       "      <td>-0.041388</td>\n",
       "      <td>-0.002503</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>8783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.015789</td>\n",
       "      <td>0.028990</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>-0.052206</td>\n",
       "      <td>0.054239</td>\n",
       "      <td>-0.048980</td>\n",
       "      <td>-0.022582</td>\n",
       "      <td>0.104886</td>\n",
       "      <td>-0.003501</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054130</td>\n",
       "      <td>-0.028953</td>\n",
       "      <td>0.085035</td>\n",
       "      <td>0.059622</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>0.022781</td>\n",
       "      <td>0.070689</td>\n",
       "      <td>-0.022480</td>\n",
       "      <td>9409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001484</td>\n",
       "      <td>0.017850</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.077527</td>\n",
       "      <td>0.041264</td>\n",
       "      <td>-0.065037</td>\n",
       "      <td>0.064227</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>-0.072233</td>\n",
       "      <td>0.107032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065416</td>\n",
       "      <td>-0.024670</td>\n",
       "      <td>-0.045834</td>\n",
       "      <td>0.094015</td>\n",
       "      <td>0.011115</td>\n",
       "      <td>0.012767</td>\n",
       "      <td>-0.072835</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>9352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vec0      vec1      vec2      vec3      vec4      vec5      vec6  \\\n",
       "0 -0.059866 -0.001436 -0.109919 -0.095510  0.074394 -0.025056  0.085519   \n",
       "1 -0.027004  0.013067 -0.085010 -0.033053  0.027256  0.016147  0.071584   \n",
       "2  0.021272  0.033173  0.011312  0.024171  0.078843  0.010647  0.041389   \n",
       "3 -0.015789  0.028990 -0.001349 -0.052206  0.054239 -0.048980 -0.022582   \n",
       "4 -0.001484  0.017850  0.007739  0.077527  0.041264 -0.065037  0.064227   \n",
       "\n",
       "       vec7      vec8      vec9  ...    vec504    vec505    vec506    vec507  \\\n",
       "0 -0.034903  0.045007  0.064680  ...  0.103880 -0.006976  0.028728  0.021821   \n",
       "1 -0.003178  0.067493  0.012164  ...  0.096953  0.048307 -0.024828 -0.034587   \n",
       "2  0.009457 -0.014883  0.036849  ...  0.075960 -0.075504  0.019888 -0.041388   \n",
       "3  0.104886 -0.003501  0.056325  ...  0.054130 -0.028953  0.085035  0.059622   \n",
       "4  0.000619 -0.072233  0.107032  ...  0.065416 -0.024670 -0.045834  0.094015   \n",
       "\n",
       "     vec508    vec509    vec510    vec511  sys_id  label  \n",
       "0 -0.081722  0.038529  0.065333  0.031073    2148      0  \n",
       "1 -0.039312  0.090378 -0.013480  0.001796    1911      0  \n",
       "2 -0.002503  0.004291  0.012759  0.037707    8783      1  \n",
       "3 -0.003623  0.022781  0.070689 -0.022480    9409      0  \n",
       "4  0.011115  0.012767 -0.072835  0.016259    9352      0  \n",
       "\n",
       "[5 rows x 514 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tr_embed = []\n",
    "\n",
    "i = 0\n",
    "while(i < df_train_augmented.shape[0]-10):\n",
    "    tr_embed.append(embed(df_train_augmented.text[i:i+10]).tolist())\n",
    "    i+= 10\n",
    "    #print(i)\n",
    "else:\n",
    "    tr_embed.append(embed(df_train_augmented.text[i:]).tolist())\n",
    "\n",
    "tr_embed2 = []\n",
    "for x in tr_embed:\n",
    "    for y in x:\n",
    "        tr_embed2.append(y)\n",
    "\n",
    "        \n",
    "df_emb = pd.DataFrame(tr_embed2, columns = [\"vec\" + str(i) for i in range(512)])\n",
    "\n",
    "temp =  df_train_augmented[[\"sys_id\",\"label\"]].copy()\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "df_emb = pd.concat([df_emb, temp], axis=1)\n",
    "df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_emb[[\"vec\" + str(i) for i in range(512)]  ], \n",
    "                                                    df_emb.label, \n",
    "                                                    test_size=0.2,  \n",
    "                                                    random_state=1,\n",
    "                                                    stratify = df_emb.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "37/37 [==============================] - 1s 6ms/step - loss: 0.6750 - accuracy: 0.6865 - val_loss: 0.6502 - val_accuracy: 0.8035\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.8007 - val_loss: 0.6128 - val_accuracy: 0.8244\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.8240 - val_loss: 0.5807 - val_accuracy: 0.8397\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.8435 - val_loss: 0.5526 - val_accuracy: 0.8474\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.8501 - val_loss: 0.5280 - val_accuracy: 0.8573\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8526 - val_loss: 0.5061 - val_accuracy: 0.8650\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.8553 - val_loss: 0.4869 - val_accuracy: 0.8672\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8606 - val_loss: 0.4700 - val_accuracy: 0.8705\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.8619 - val_loss: 0.4547 - val_accuracy: 0.8716\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.8628 - val_loss: 0.4412 - val_accuracy: 0.8705\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.8641 - val_loss: 0.4289 - val_accuracy: 0.8716\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8652 - val_loss: 0.4179 - val_accuracy: 0.8716\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8663 - val_loss: 0.4081 - val_accuracy: 0.8716\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8680 - val_loss: 0.3992 - val_accuracy: 0.8727\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8680 - val_loss: 0.3910 - val_accuracy: 0.8727\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3925 - accuracy: 0.8691 - val_loss: 0.3834 - val_accuracy: 0.8760\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3853 - accuracy: 0.8713 - val_loss: 0.3766 - val_accuracy: 0.8760\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8718 - val_loss: 0.3703 - val_accuracy: 0.8760\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8732 - val_loss: 0.3645 - val_accuracy: 0.8771\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8743 - val_loss: 0.3591 - val_accuracy: 0.8771\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8748 - val_loss: 0.3541 - val_accuracy: 0.8782\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8759 - val_loss: 0.3496 - val_accuracy: 0.8782\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8762 - val_loss: 0.3452 - val_accuracy: 0.8782\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8767 - val_loss: 0.3412 - val_accuracy: 0.8782\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8776 - val_loss: 0.3374 - val_accuracy: 0.8814\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3407 - accuracy: 0.8781 - val_loss: 0.3339 - val_accuracy: 0.8825\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8784 - val_loss: 0.3306 - val_accuracy: 0.8825\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8795 - val_loss: 0.3274 - val_accuracy: 0.8825\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8795 - val_loss: 0.3245 - val_accuracy: 0.8858\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8806 - val_loss: 0.3217 - val_accuracy: 0.8869\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8828 - val_loss: 0.3191 - val_accuracy: 0.8869\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8833 - val_loss: 0.3165 - val_accuracy: 0.8869\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8833 - val_loss: 0.3140 - val_accuracy: 0.8858\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8847 - val_loss: 0.3118 - val_accuracy: 0.8869\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3155 - accuracy: 0.8855 - val_loss: 0.3097 - val_accuracy: 0.8858\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8844 - val_loss: 0.3076 - val_accuracy: 0.8858\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8847 - val_loss: 0.3057 - val_accuracy: 0.8891\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8850 - val_loss: 0.3037 - val_accuracy: 0.8902\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3073 - accuracy: 0.8855 - val_loss: 0.3019 - val_accuracy: 0.8891\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8858 - val_loss: 0.3001 - val_accuracy: 0.8902\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8864 - val_loss: 0.2985 - val_accuracy: 0.8902\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8869 - val_loss: 0.2968 - val_accuracy: 0.8902\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8877 - val_loss: 0.2953 - val_accuracy: 0.8902\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8880 - val_loss: 0.2938 - val_accuracy: 0.8902\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8875 - val_loss: 0.2924 - val_accuracy: 0.8902\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8886 - val_loss: 0.2909 - val_accuracy: 0.8902\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8888 - val_loss: 0.2896 - val_accuracy: 0.8902\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8897 - val_loss: 0.2883 - val_accuracy: 0.8913\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8905 - val_loss: 0.2871 - val_accuracy: 0.8935\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8910 - val_loss: 0.2858 - val_accuracy: 0.8957\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8910 - val_loss: 0.2846 - val_accuracy: 0.8957\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8924 - val_loss: 0.2836 - val_accuracy: 0.8957\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8924 - val_loss: 0.2824 - val_accuracy: 0.8957\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.8927 - val_loss: 0.2814 - val_accuracy: 0.8946\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2840 - accuracy: 0.8929 - val_loss: 0.2802 - val_accuracy: 0.8957\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8932 - val_loss: 0.2792 - val_accuracy: 0.8968\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8935 - val_loss: 0.2781 - val_accuracy: 0.8957\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8935 - val_loss: 0.2771 - val_accuracy: 0.8979\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2795 - accuracy: 0.8938 - val_loss: 0.2763 - val_accuracy: 0.8968\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8935 - val_loss: 0.2753 - val_accuracy: 0.8990\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2775 - accuracy: 0.8943 - val_loss: 0.2745 - val_accuracy: 0.9001\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2765 - accuracy: 0.8951 - val_loss: 0.2735 - val_accuracy: 0.9001\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8960 - val_loss: 0.2727 - val_accuracy: 0.9023\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8965 - val_loss: 0.2719 - val_accuracy: 0.9023\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8962 - val_loss: 0.2710 - val_accuracy: 0.9023\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.8965 - val_loss: 0.2704 - val_accuracy: 0.9034\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 0.8976 - val_loss: 0.2696 - val_accuracy: 0.9034\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8979 - val_loss: 0.2688 - val_accuracy: 0.9045\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.8979 - val_loss: 0.2679 - val_accuracy: 0.9045\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2692 - accuracy: 0.8990 - val_loss: 0.2673 - val_accuracy: 0.9045\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2684 - accuracy: 0.8990 - val_loss: 0.2665 - val_accuracy: 0.9045\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.8993 - val_loss: 0.2659 - val_accuracy: 0.9056\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2668 - accuracy: 0.8993 - val_loss: 0.2652 - val_accuracy: 0.9067\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8995 - val_loss: 0.2646 - val_accuracy: 0.9089\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.9004 - val_loss: 0.2639 - val_accuracy: 0.9056\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.9012 - val_loss: 0.2633 - val_accuracy: 0.9089\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9012 - val_loss: 0.2627 - val_accuracy: 0.9089\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.9023 - val_loss: 0.2620 - val_accuracy: 0.9078\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9031 - val_loss: 0.2614 - val_accuracy: 0.9089\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.9034 - val_loss: 0.2608 - val_accuracy: 0.9089\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.9034 - val_loss: 0.2602 - val_accuracy: 0.9100\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9039 - val_loss: 0.2596 - val_accuracy: 0.9100\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.9039 - val_loss: 0.2591 - val_accuracy: 0.9100\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.9047 - val_loss: 0.2585 - val_accuracy: 0.9100\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2580 - accuracy: 0.9056 - val_loss: 0.2581 - val_accuracy: 0.9100\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9050 - val_loss: 0.2575 - val_accuracy: 0.9100\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9058 - val_loss: 0.2570 - val_accuracy: 0.9111\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2560 - accuracy: 0.9061 - val_loss: 0.2566 - val_accuracy: 0.9111\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9058 - val_loss: 0.2560 - val_accuracy: 0.9122\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.9067 - val_loss: 0.2555 - val_accuracy: 0.9133\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9069 - val_loss: 0.2550 - val_accuracy: 0.9133\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9067 - val_loss: 0.2546 - val_accuracy: 0.9122\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9069 - val_loss: 0.2541 - val_accuracy: 0.9122\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9080 - val_loss: 0.2536 - val_accuracy: 0.9122\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.9078 - val_loss: 0.2532 - val_accuracy: 0.9122\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.9078 - val_loss: 0.2527 - val_accuracy: 0.9133\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9080 - val_loss: 0.2523 - val_accuracy: 0.9122\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2500 - accuracy: 0.9083 - val_loss: 0.2519 - val_accuracy: 0.9122\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2495 - accuracy: 0.9086 - val_loss: 0.2515 - val_accuracy: 0.9122\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9091 - val_loss: 0.2510 - val_accuracy: 0.9122\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9094 - val_loss: 0.2506 - val_accuracy: 0.9133\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9094 - val_loss: 0.2502 - val_accuracy: 0.9133\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9089 - val_loss: 0.2499 - val_accuracy: 0.9133\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.9091 - val_loss: 0.2494 - val_accuracy: 0.9133\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9097 - val_loss: 0.2490 - val_accuracy: 0.9133\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9105 - val_loss: 0.2487 - val_accuracy: 0.9133\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9108 - val_loss: 0.2483 - val_accuracy: 0.9133\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9100 - val_loss: 0.2479 - val_accuracy: 0.9133\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.9108 - val_loss: 0.2476 - val_accuracy: 0.9133\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.9111 - val_loss: 0.2472 - val_accuracy: 0.9133\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.9108 - val_loss: 0.2468 - val_accuracy: 0.9133\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 0.9113 - val_loss: 0.2465 - val_accuracy: 0.9144\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9122 - val_loss: 0.2463 - val_accuracy: 0.9144\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9130 - val_loss: 0.2459 - val_accuracy: 0.9144\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9122 - val_loss: 0.2455 - val_accuracy: 0.9144\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9124 - val_loss: 0.2453 - val_accuracy: 0.9144\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.9130 - val_loss: 0.2449 - val_accuracy: 0.9144\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9127 - val_loss: 0.2445 - val_accuracy: 0.9144\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9130 - val_loss: 0.2442 - val_accuracy: 0.9144\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9133 - val_loss: 0.2439 - val_accuracy: 0.9144\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9135 - val_loss: 0.2436 - val_accuracy: 0.9144\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9138 - val_loss: 0.2433 - val_accuracy: 0.9144\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2377 - accuracy: 0.9138 - val_loss: 0.2431 - val_accuracy: 0.9155\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9135 - val_loss: 0.2428 - val_accuracy: 0.9155\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9138 - val_loss: 0.2425 - val_accuracy: 0.9155\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9144 - val_loss: 0.2422 - val_accuracy: 0.9166\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9146 - val_loss: 0.2419 - val_accuracy: 0.9177\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9152 - val_loss: 0.2417 - val_accuracy: 0.9166\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9155 - val_loss: 0.2413 - val_accuracy: 0.9177\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9160 - val_loss: 0.2411 - val_accuracy: 0.9177\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9163 - val_loss: 0.2409 - val_accuracy: 0.9177\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9166 - val_loss: 0.2406 - val_accuracy: 0.9177\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.9171 - val_loss: 0.2404 - val_accuracy: 0.9177\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9171 - val_loss: 0.2401 - val_accuracy: 0.9177\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.9177 - val_loss: 0.2398 - val_accuracy: 0.9177\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9177 - val_loss: 0.2395 - val_accuracy: 0.9177\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.9177 - val_loss: 0.2393 - val_accuracy: 0.9188\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2316 - accuracy: 0.9174 - val_loss: 0.2391 - val_accuracy: 0.9188\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9179 - val_loss: 0.2388 - val_accuracy: 0.9188\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2308 - accuracy: 0.9179 - val_loss: 0.2386 - val_accuracy: 0.9188\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 0.9179 - val_loss: 0.2384 - val_accuracy: 0.9188\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9185 - val_loss: 0.2381 - val_accuracy: 0.9188\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9185 - val_loss: 0.2380 - val_accuracy: 0.9188\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9187 - val_loss: 0.2377 - val_accuracy: 0.9188\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9185 - val_loss: 0.2375 - val_accuracy: 0.9188\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9182 - val_loss: 0.2373 - val_accuracy: 0.9177\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9185 - val_loss: 0.2371 - val_accuracy: 0.9177\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9187 - val_loss: 0.2368 - val_accuracy: 0.9177\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9185 - val_loss: 0.2367 - val_accuracy: 0.9155\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9187 - val_loss: 0.2364 - val_accuracy: 0.9155\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.9187 - val_loss: 0.2363 - val_accuracy: 0.9166\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.9185 - val_loss: 0.2360 - val_accuracy: 0.9155\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2263 - accuracy: 0.9185 - val_loss: 0.2359 - val_accuracy: 0.9155\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9182 - val_loss: 0.2357 - val_accuracy: 0.9155\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9185 - val_loss: 0.2354 - val_accuracy: 0.9155\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9182 - val_loss: 0.2352 - val_accuracy: 0.9155\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9185 - val_loss: 0.2351 - val_accuracy: 0.9155\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9185 - val_loss: 0.2348 - val_accuracy: 0.9155\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9187 - val_loss: 0.2347 - val_accuracy: 0.9155\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9187 - val_loss: 0.2345 - val_accuracy: 0.9155\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9190 - val_loss: 0.2344 - val_accuracy: 0.9155\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2233 - accuracy: 0.9190 - val_loss: 0.2342 - val_accuracy: 0.9155\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9190 - val_loss: 0.2341 - val_accuracy: 0.9144\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9193 - val_loss: 0.2337 - val_accuracy: 0.9166\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9198 - val_loss: 0.2336 - val_accuracy: 0.9166\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9198 - val_loss: 0.2335 - val_accuracy: 0.9166\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2219 - accuracy: 0.9201 - val_loss: 0.2333 - val_accuracy: 0.9166\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9198 - val_loss: 0.2332 - val_accuracy: 0.9155\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9196 - val_loss: 0.2329 - val_accuracy: 0.9166\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9207 - val_loss: 0.2327 - val_accuracy: 0.9177\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9204 - val_loss: 0.2326 - val_accuracy: 0.9155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9209 - val_loss: 0.2325 - val_accuracy: 0.9177\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9207 - val_loss: 0.2323 - val_accuracy: 0.9166\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9201 - val_loss: 0.2322 - val_accuracy: 0.9144\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9207 - val_loss: 0.2320 - val_accuracy: 0.9177\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9207 - val_loss: 0.2318 - val_accuracy: 0.9166\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9207 - val_loss: 0.2317 - val_accuracy: 0.9144\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9207 - val_loss: 0.2315 - val_accuracy: 0.9155\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9207 - val_loss: 0.2314 - val_accuracy: 0.9155\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9207 - val_loss: 0.2313 - val_accuracy: 0.9133\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9209 - val_loss: 0.2311 - val_accuracy: 0.9133\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2175 - accuracy: 0.9207 - val_loss: 0.2309 - val_accuracy: 0.9144\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9207 - val_loss: 0.2308 - val_accuracy: 0.9155\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.9207 - val_loss: 0.2307 - val_accuracy: 0.9166\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9207 - val_loss: 0.2305 - val_accuracy: 0.9177\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9207 - val_loss: 0.2304 - val_accuracy: 0.9155\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.9209 - val_loss: 0.2302 - val_accuracy: 0.9166\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9209 - val_loss: 0.2301 - val_accuracy: 0.9166\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9209 - val_loss: 0.2299 - val_accuracy: 0.9166\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.9209 - val_loss: 0.2298 - val_accuracy: 0.9166\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9209 - val_loss: 0.2296 - val_accuracy: 0.9166\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9209 - val_loss: 0.2294 - val_accuracy: 0.9166\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9209 - val_loss: 0.2294 - val_accuracy: 0.9166\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9215 - val_loss: 0.2293 - val_accuracy: 0.9166\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9209 - val_loss: 0.2291 - val_accuracy: 0.9155\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9212 - val_loss: 0.2290 - val_accuracy: 0.9166\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9218 - val_loss: 0.2289 - val_accuracy: 0.9166\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.9215 - val_loss: 0.2287 - val_accuracy: 0.9155\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9215 - val_loss: 0.2286 - val_accuracy: 0.9155\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9218 - val_loss: 0.2285 - val_accuracy: 0.9155\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9223 - val_loss: 0.2284 - val_accuracy: 0.9155\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9212 - val_loss: 0.2283 - val_accuracy: 0.9155\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2121 - accuracy: 0.9218 - val_loss: 0.2282 - val_accuracy: 0.9166\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9218 - val_loss: 0.2281 - val_accuracy: 0.9166\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9220 - val_loss: 0.2280 - val_accuracy: 0.9166\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9212 - val_loss: 0.2278 - val_accuracy: 0.9166\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9220 - val_loss: 0.2277 - val_accuracy: 0.9166\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9218 - val_loss: 0.2276 - val_accuracy: 0.9188\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9223 - val_loss: 0.2275 - val_accuracy: 0.9144\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9223 - val_loss: 0.2274 - val_accuracy: 0.9155\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9223 - val_loss: 0.2273 - val_accuracy: 0.9155\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9223 - val_loss: 0.2272 - val_accuracy: 0.9155\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9220 - val_loss: 0.2271 - val_accuracy: 0.9155\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9223 - val_loss: 0.2270 - val_accuracy: 0.9155\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2094 - accuracy: 0.9223 - val_loss: 0.2268 - val_accuracy: 0.9166\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9226 - val_loss: 0.2268 - val_accuracy: 0.9166\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2090 - accuracy: 0.9223 - val_loss: 0.2267 - val_accuracy: 0.9166\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9223 - val_loss: 0.2266 - val_accuracy: 0.9177\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.9220 - val_loss: 0.2265 - val_accuracy: 0.9166\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9223 - val_loss: 0.2264 - val_accuracy: 0.9177\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9226 - val_loss: 0.2262 - val_accuracy: 0.9177\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9223 - val_loss: 0.2262 - val_accuracy: 0.9177\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2077 - accuracy: 0.9223 - val_loss: 0.2261 - val_accuracy: 0.9188\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9223 - val_loss: 0.2260 - val_accuracy: 0.9177\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2072 - accuracy: 0.9223 - val_loss: 0.2260 - val_accuracy: 0.9188\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9223 - val_loss: 0.2259 - val_accuracy: 0.9188\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2069 - accuracy: 0.9223 - val_loss: 0.2258 - val_accuracy: 0.9188\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9226 - val_loss: 0.2257 - val_accuracy: 0.9188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2064 - accuracy: 0.9229 - val_loss: 0.2257 - val_accuracy: 0.9188\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9226 - val_loss: 0.2256 - val_accuracy: 0.9188\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9229 - val_loss: 0.2254 - val_accuracy: 0.9188\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9229 - val_loss: 0.2254 - val_accuracy: 0.9188\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2057 - accuracy: 0.9231 - val_loss: 0.2252 - val_accuracy: 0.9199\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9226 - val_loss: 0.2251 - val_accuracy: 0.9188\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2052 - accuracy: 0.9229 - val_loss: 0.2251 - val_accuracy: 0.9188\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9223 - val_loss: 0.2249 - val_accuracy: 0.9188\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9229 - val_loss: 0.2248 - val_accuracy: 0.9199\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.9231 - val_loss: 0.2247 - val_accuracy: 0.9199\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9229 - val_loss: 0.2247 - val_accuracy: 0.9199\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9231 - val_loss: 0.2246 - val_accuracy: 0.9199\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9223 - val_loss: 0.2245 - val_accuracy: 0.9199\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9229 - val_loss: 0.2245 - val_accuracy: 0.9188\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9226 - val_loss: 0.2244 - val_accuracy: 0.9188\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9229 - val_loss: 0.2243 - val_accuracy: 0.9199\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9231 - val_loss: 0.2242 - val_accuracy: 0.9199\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2031 - accuracy: 0.9234 - val_loss: 0.2241 - val_accuracy: 0.9199\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9231 - val_loss: 0.2241 - val_accuracy: 0.9199\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9237 - val_loss: 0.2240 - val_accuracy: 0.9199\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2025 - accuracy: 0.9234 - val_loss: 0.2239 - val_accuracy: 0.9210\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9231 - val_loss: 0.2239 - val_accuracy: 0.9210\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.9234 - val_loss: 0.2237 - val_accuracy: 0.9210\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9231 - val_loss: 0.2237 - val_accuracy: 0.9210\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9237 - val_loss: 0.2237 - val_accuracy: 0.9199\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9240 - val_loss: 0.2236 - val_accuracy: 0.9188\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9253 - val_loss: 0.2236 - val_accuracy: 0.9210\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9248 - val_loss: 0.2235 - val_accuracy: 0.9199\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9253 - val_loss: 0.2235 - val_accuracy: 0.9188\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9248 - val_loss: 0.2235 - val_accuracy: 0.9199\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9248 - val_loss: 0.2233 - val_accuracy: 0.9199\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9256 - val_loss: 0.2233 - val_accuracy: 0.9199\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9256 - val_loss: 0.2232 - val_accuracy: 0.9199\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9264 - val_loss: 0.2232 - val_accuracy: 0.9199\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2000 - accuracy: 0.9253 - val_loss: 0.2231 - val_accuracy: 0.9199\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9262 - val_loss: 0.2230 - val_accuracy: 0.9199\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9259 - val_loss: 0.2230 - val_accuracy: 0.9188\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1995 - accuracy: 0.9259 - val_loss: 0.2230 - val_accuracy: 0.9188\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9262 - val_loss: 0.2229 - val_accuracy: 0.9188\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9264 - val_loss: 0.2229 - val_accuracy: 0.9188\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9262 - val_loss: 0.2228 - val_accuracy: 0.9177\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9264 - val_loss: 0.2227 - val_accuracy: 0.9177\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9264 - val_loss: 0.2227 - val_accuracy: 0.9177\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9267 - val_loss: 0.2226 - val_accuracy: 0.9177\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9264 - val_loss: 0.2225 - val_accuracy: 0.9188\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9264 - val_loss: 0.2225 - val_accuracy: 0.9188\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9267 - val_loss: 0.2224 - val_accuracy: 0.9188\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9267 - val_loss: 0.2224 - val_accuracy: 0.9188\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9264 - val_loss: 0.2223 - val_accuracy: 0.9199\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1975 - accuracy: 0.9267 - val_loss: 0.2222 - val_accuracy: 0.9188\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9267 - val_loss: 0.2222 - val_accuracy: 0.9199\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9264 - val_loss: 0.2222 - val_accuracy: 0.9199\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9264 - val_loss: 0.2221 - val_accuracy: 0.9199\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1970 - accuracy: 0.9267 - val_loss: 0.2220 - val_accuracy: 0.9199\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9264 - val_loss: 0.2220 - val_accuracy: 0.9199\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9267 - val_loss: 0.2219 - val_accuracy: 0.9199\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1964 - accuracy: 0.9267 - val_loss: 0.2219 - val_accuracy: 0.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9267 - val_loss: 0.2218 - val_accuracy: 0.9199\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1962 - accuracy: 0.9264 - val_loss: 0.2219 - val_accuracy: 0.9199\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9264 - val_loss: 0.2217 - val_accuracy: 0.9199\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9264 - val_loss: 0.2217 - val_accuracy: 0.9199\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9275 - val_loss: 0.2217 - val_accuracy: 0.9199\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.9270 - val_loss: 0.2216 - val_accuracy: 0.9199\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9267 - val_loss: 0.2216 - val_accuracy: 0.9199\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9270 - val_loss: 0.2215 - val_accuracy: 0.9199\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1951 - accuracy: 0.9273 - val_loss: 0.2215 - val_accuracy: 0.9199\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.9267 - val_loss: 0.2215 - val_accuracy: 0.9199\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1948 - accuracy: 0.9270 - val_loss: 0.2214 - val_accuracy: 0.9199\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9273 - val_loss: 0.2214 - val_accuracy: 0.9199\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.9275 - val_loss: 0.2214 - val_accuracy: 0.9199\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1943 - accuracy: 0.9275 - val_loss: 0.2213 - val_accuracy: 0.9199\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.9281 - val_loss: 0.2213 - val_accuracy: 0.9188\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9278 - val_loss: 0.2213 - val_accuracy: 0.9177\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9275 - val_loss: 0.2212 - val_accuracy: 0.9177\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9278 - val_loss: 0.2211 - val_accuracy: 0.9177\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9275 - val_loss: 0.2211 - val_accuracy: 0.9177\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.9273 - val_loss: 0.2211 - val_accuracy: 0.9177\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9278 - val_loss: 0.2211 - val_accuracy: 0.9188\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9275 - val_loss: 0.2210 - val_accuracy: 0.9188\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9278 - val_loss: 0.2211 - val_accuracy: 0.9188\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1928 - accuracy: 0.9275 - val_loss: 0.2210 - val_accuracy: 0.9188\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1927 - accuracy: 0.9281 - val_loss: 0.2210 - val_accuracy: 0.9188\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.9275 - val_loss: 0.2209 - val_accuracy: 0.9188\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9278 - val_loss: 0.2209 - val_accuracy: 0.9188\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9281 - val_loss: 0.2208 - val_accuracy: 0.9188\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9284 - val_loss: 0.2208 - val_accuracy: 0.9188\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9284 - val_loss: 0.2208 - val_accuracy: 0.9188\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.9284 - val_loss: 0.2207 - val_accuracy: 0.9188\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9286 - val_loss: 0.2207 - val_accuracy: 0.9188\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9281 - val_loss: 0.2207 - val_accuracy: 0.9188\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1915 - accuracy: 0.9284 - val_loss: 0.2206 - val_accuracy: 0.9188\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9281 - val_loss: 0.2205 - val_accuracy: 0.9188\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9286 - val_loss: 0.2205 - val_accuracy: 0.9188\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1911 - accuracy: 0.9286 - val_loss: 0.2205 - val_accuracy: 0.9188\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9286 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9289 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9286 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9286 - val_loss: 0.2204 - val_accuracy: 0.9188\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9286 - val_loss: 0.2203 - val_accuracy: 0.9188\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9286 - val_loss: 0.2203 - val_accuracy: 0.9188\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9292 - val_loss: 0.2203 - val_accuracy: 0.9188\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9286 - val_loss: 0.2202 - val_accuracy: 0.9177\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9292 - val_loss: 0.2203 - val_accuracy: 0.9177\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9289 - val_loss: 0.2202 - val_accuracy: 0.9177\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9289 - val_loss: 0.2202 - val_accuracy: 0.9166\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9289 - val_loss: 0.2201 - val_accuracy: 0.9166\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9292 - val_loss: 0.2201 - val_accuracy: 0.9166\n",
      "Epoch 336/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9292 - val_loss: 0.2201 - val_accuracy: 0.9166\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9295 - val_loss: 0.2201 - val_accuracy: 0.9166\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9289 - val_loss: 0.2201 - val_accuracy: 0.9177\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9295 - val_loss: 0.2200 - val_accuracy: 0.9166\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9297 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.9295 - val_loss: 0.2200 - val_accuracy: 0.9166\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.9295 - val_loss: 0.2199 - val_accuracy: 0.9166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.9300 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.9297 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9300 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
      "Epoch 346/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9295 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 347/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9289 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 348/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.9295 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 349/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9297 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 350/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9300 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 351/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9300 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9297 - val_loss: 0.2199 - val_accuracy: 0.9166\n",
      "Epoch 353/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9303 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.9303 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
      "Epoch 355/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.9308 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
      "Epoch 356/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9308 - val_loss: 0.2197 - val_accuracy: 0.9166\n",
      "Epoch 357/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9308 - val_loss: 0.2197 - val_accuracy: 0.9177\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9306 - val_loss: 0.2198 - val_accuracy: 0.9177\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.9308 - val_loss: 0.2198 - val_accuracy: 0.9166\n",
      "Epoch 360/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9308 - val_loss: 0.2198 - val_accuracy: 0.9177\n",
      "Epoch 361/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9311 - val_loss: 0.2197 - val_accuracy: 0.9177\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9308 - val_loss: 0.2197 - val_accuracy: 0.9177\n",
      "Epoch 363/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.9308 - val_loss: 0.2196 - val_accuracy: 0.9177\n",
      "Epoch 364/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9306 - val_loss: 0.2197 - val_accuracy: 0.9177\n",
      "Epoch 365/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.9308 - val_loss: 0.2196 - val_accuracy: 0.9166\n",
      "Epoch 366/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9308 - val_loss: 0.2196 - val_accuracy: 0.9177\n",
      "Epoch 367/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9308 - val_loss: 0.2196 - val_accuracy: 0.9177\n",
      "Epoch 368/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9306 - val_loss: 0.2196 - val_accuracy: 0.9177\n",
      "Epoch 369/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.9308 - val_loss: 0.2195 - val_accuracy: 0.9166\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9311 - val_loss: 0.2195 - val_accuracy: 0.9177\n",
      "Epoch 371/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9308 - val_loss: 0.2195 - val_accuracy: 0.9177\n",
      "Epoch 372/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9314 - val_loss: 0.2195 - val_accuracy: 0.9177\n",
      "Epoch 373/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9308 - val_loss: 0.2195 - val_accuracy: 0.9166\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.9306 - val_loss: 0.2195 - val_accuracy: 0.9177\n",
      "Epoch 375/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9308 - val_loss: 0.2195 - val_accuracy: 0.9166\n",
      "Epoch 376/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9308 - val_loss: 0.2194 - val_accuracy: 0.9166\n",
      "Epoch 377/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.9316 - val_loss: 0.2194 - val_accuracy: 0.9166\n",
      "Epoch 378/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.9308 - val_loss: 0.2194 - val_accuracy: 0.9177\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9314 - val_loss: 0.2194 - val_accuracy: 0.9166\n",
      "Epoch 380/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.9314 - val_loss: 0.2194 - val_accuracy: 0.9166\n",
      "Epoch 381/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.9314 - val_loss: 0.2194 - val_accuracy: 0.9177\n",
      "Epoch 382/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9311 - val_loss: 0.2194 - val_accuracy: 0.9166\n",
      "Epoch 383/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9311 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 384/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.9319 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 385/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9314 - val_loss: 0.2194 - val_accuracy: 0.9166\n",
      "Epoch 386/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9314 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 387/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9314 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9319 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 389/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9316 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 390/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9314 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 391/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.9316 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 392/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.9316 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 393/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.9316 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 394/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.9314 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 395/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.9319 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 396/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.9316 - val_loss: 0.2193 - val_accuracy: 0.9166\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9319 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 398/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9322 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 399/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9325 - val_loss: 0.2192 - val_accuracy: 0.9166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9316 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 401/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9319 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 402/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9325 - val_loss: 0.2192 - val_accuracy: 0.9166\n",
      "Epoch 403/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.9322 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 404/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9319 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 405/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9327 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 406/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9330 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 407/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.9327 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 408/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9327 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 409/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9330 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9333 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 411/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.9330 - val_loss: 0.2191 - val_accuracy: 0.9166\n",
      "Epoch 412/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9327 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 413/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9327 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 414/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1805 - accuracy: 0.9333 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 415/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9336 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.9336 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 417/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9336 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 418/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 419/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9336 - val_loss: 0.2189 - val_accuracy: 0.9166\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1800 - accuracy: 0.9336 - val_loss: 0.2189 - val_accuracy: 0.9166\n",
      "Epoch 421/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.9336 - val_loss: 0.2189 - val_accuracy: 0.9166\n",
      "Epoch 422/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9336 - val_loss: 0.2189 - val_accuracy: 0.9166\n",
      "Epoch 423/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.9336 - val_loss: 0.2189 - val_accuracy: 0.9155\n",
      "Epoch 424/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.2189 - val_accuracy: 0.9166\n",
      "Epoch 425/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9338 - val_loss: 0.2189 - val_accuracy: 0.9155\n",
      "Epoch 426/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9336 - val_loss: 0.2190 - val_accuracy: 0.9155\n",
      "Epoch 427/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9155\n",
      "Epoch 428/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9166\n",
      "Epoch 429/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9155\n",
      "Epoch 430/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.9338 - val_loss: 0.2189 - val_accuracy: 0.9155\n",
      "Epoch 431/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9336 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9338 - val_loss: 0.2191 - val_accuracy: 0.9155\n",
      "Epoch 433/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 434/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 435/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9341 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 436/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 437/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1784 - accuracy: 0.9336 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 438/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 439/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.9344 - val_loss: 0.2191 - val_accuracy: 0.9144\n",
      "Epoch 440/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.9338 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 441/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.9341 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 442/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9349 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 443/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9344 - val_loss: 0.2190 - val_accuracy: 0.9144\n",
      "Epoch 444/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9338 - val_loss: 0.2189 - val_accuracy: 0.9144\n",
      "Epoch 445/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1776 - accuracy: 0.9341 - val_loss: 0.2190 - val_accuracy: 0.9144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bbe72cb70>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_model = tf.keras.models.Sequential()\n",
    "# cl_model.add(tf.keras.layers.Dense(512, input_dim = 512,activation='sigmoid'))\n",
    "# cl_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "initializer = tf.keras.initializers.Identity()\n",
    "#base_model.add(tf.keras.layers.Dense())\n",
    "cl_model.add(tf.keras.layers.Dense(512,input_dim = 512,activation=None,trainable=False,kernel_initializer=initializer))#activation=\"relu\"))\n",
    "# cl_model.add(tf.keras.layers.Dense(512, activation='sigmoid'))\n",
    "# cl_model.add(tf.keras.layers.Dense(512, activation='sigmoid'))\n",
    "cl_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "cl_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 20, \n",
    "                                        restore_best_weights = True)\n",
    "    \n",
    "cl_model.fit(x_train.values,y_train.values, batch_size = 100,epochs=1000,validation_data=(x_test.values,y_test.values),callbacks =[earlystopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 28.5 s, total: 1min 20s\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "holdout = pd.read_csv(\"/Users/dinesh.surapaneni/OneDrive - ServiceNow/Snorkel/data/holdout.csv\",encoding='latin-1')\n",
    "holdout[\"label\"] = holdout[\"label\"].replace(\"undecided\", \"non-critical\")\n",
    "holdout[\"label_bn\"] = [1 if i == \"critical\" else 0 for i in holdout.label ]\n",
    "\n",
    "tt_embed = []\n",
    "i = 0\n",
    "while(i < holdout.shape[0]-10):\n",
    "    tt_embed.append(embed(holdout.text[i:i+10]).tolist())\n",
    "    i+= 10\n",
    "    #print(i)\n",
    "else:\n",
    "    tt_embed.append(embed(holdout.text[i:]).tolist())\n",
    "\n",
    "tt_embed2 = []\n",
    "for x in tt_embed:\n",
    "    for y in x:\n",
    "        tt_embed2.append(y)\n",
    "\n",
    "        \n",
    "df_emb_hold = pd.DataFrame(tt_embed2, columns = [\"vec\" + str(i) for i in range(512)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.59\n"
     ]
    }
   ],
   "source": [
    "_, accu = cl_model.evaluate(df_emb_hold.values, holdout.label_bn,verbose=0)\n",
    "print('Accuracy: %.2f' % (accu*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout[\"pred\"] = [1 if i > 0.50 else 0 for i in cl_model.predict(df_emb_hold.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred         0    1\n",
      "label_bn           \n",
      "0         1058  792\n",
      "1          117   80\n"
     ]
    }
   ],
   "source": [
    "data_crosstab = pd.crosstab(holdout[\"label_bn\"],\n",
    "                            holdout[\"pred\"], \n",
    "                               margins = False)\n",
    "print(data_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.900426</td>\n",
       "      <td>0.571892</td>\n",
       "      <td>0.699504</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>0.496812</td>\n",
       "      <td>0.910732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091743</td>\n",
       "      <td>0.406091</td>\n",
       "      <td>0.149673</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.496812</td>\n",
       "      <td>0.090249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555936</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.496084</td>\n",
       "      <td>0.488992</td>\n",
       "      <td>0.424588</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>0.496812</td>\n",
       "      <td>0.500491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.822599</td>\n",
       "      <td>0.555936</td>\n",
       "      <td>0.646589</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>0.496812</td>\n",
       "      <td>0.831770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support     AUROC     AUPRC\n",
       "0              0.900426  0.571892  0.699504   1850.0  0.496812  0.910732\n",
       "1              0.091743  0.406091  0.149673    197.0  0.496812  0.090249\n",
       "accuracy            NaN       NaN  0.555936   2047.0       NaN       NaN\n",
       "macro avg      0.496084  0.488992  0.424588   2047.0  0.496812  0.500491\n",
       "weighted avg   0.822599  0.555936  0.646589   2047.0  0.496812  0.831770"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For binary classifier\n",
    "T_num = 2 #Number of classes\n",
    "y_pred_prob = np.array([np.concatenate([1-prb,prb]) for prb in cl_model.predict(df_emb_hold.values)])\n",
    "y_test = holdout[\"label_bn\"]\n",
    "y_pred = [1 if i > 0.50 else 0 for i in cl_model.predict(df_emb_hold.values)]\n",
    "res, igr = clf_metric_AImp(y_test,y_pred, y_pred_prob, T_num)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"result.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.934177</td>\n",
       "      <td>0.598378</td>\n",
       "      <td>0.729489</td>\n",
       "      <td>1850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.138051</td>\n",
       "      <td>0.604061</td>\n",
       "      <td>0.224740</td>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.598925</td>\n",
       "      <td>0.598925</td>\n",
       "      <td>0.598925</td>\n",
       "      <td>0.598925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.536114</td>\n",
       "      <td>0.601220</td>\n",
       "      <td>0.477115</td>\n",
       "      <td>2047.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.857559</td>\n",
       "      <td>0.598925</td>\n",
       "      <td>0.680913</td>\n",
       "      <td>2047.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.934177  0.598378  0.729489  1850.000000\n",
       "1              0.138051  0.604061  0.224740   197.000000\n",
       "accuracy       0.598925  0.598925  0.598925     0.598925\n",
       "macro avg      0.536114  0.601220  0.477115  2047.000000\n",
       "weighted avg   0.857559  0.598925  0.680913  2047.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(holdout[\"label_bn\"], holdout[\"pred\"], output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(X=df_emb[[\"vec\" + str(i) for i in range(512)]  ].values, y=df_emb.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout[\"pred_logR\"] = clf.predict(df_emb_hold.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_logR    0    1\n",
      "label_bn           \n",
      "0          613  438\n",
      "1          102   80\n"
     ]
    }
   ],
   "source": [
    "data_crosstab = pd.crosstab(holdout[\"label_bn\"],\n",
    "                            holdout[\"pred_logR\"],\n",
    "                               margins = False)\n",
    "print(data_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5620437956204379"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(613 + 80)/holdout.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
