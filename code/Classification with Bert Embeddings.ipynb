{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26296fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f067521cc51c4893a4bdea858b8563e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c519a1fda54f8bbef0bcd6dd061157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2d3e95d8444bbe9fba5f073a3b6520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b6c11a6da84bc6909e98907c8a301f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da2e3cb69cf47a78d65f8ae35b929e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960ebe530aca45738866c3e2b34fbf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6640f7a2f2f44c26b00c5910333fa15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d638ba62074bea8a546013d9833f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd579dbd5f4447484e20b7107244952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aebe1a7e774962b11627b32df1fee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b17a73b3454e1f8e7a6fe13e33200b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0090e937b74bbb9df0192456163280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd5830e43324a65a5a082493d2c86a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff4136367cd4861bb500bcac53a3714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1a931d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (4.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (1.9.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (0.11.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (3.6.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sentence-transformers) (0.0.12)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.47)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from packaging->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: click in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.10.2-cp38-cp38-win_amd64.whl (226.6 MB)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=08c13faab392c09479b41da80e916639831423f1b974f04116d2c02d995c2673\n",
      "  Stored in directory: c:\\users\\tayfu\\appdata\\local\\pip\\cache\\wheels\\0c\\b6\\fb\\2289a932c365293ad865fc1fe9d2db694d5584241c6d670874\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: torch, sentencepiece, sentence-transformers\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0\n",
      "    Uninstalling torch-1.9.0:\n",
      "      Successfully uninstalled torch-1.9.0\n",
      "Successfully installed sentence-transformers-2.2.0 sentencepiece-0.1.96 torch-1.10.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8af54e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a894dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.', \n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608a4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/rel_ext_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d1acb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me the expiration date for my current cre...</td>\n",
       "      <td>expiration_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would you disconnect from my phone</td>\n",
       "      <td>sync_device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>could you please track my package</td>\n",
       "      <td>order_status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>any travel alerts for canada</td>\n",
       "      <td>travel_alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i want to report fraudulent activity on my ame...</td>\n",
       "      <td>report_fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           intent\n",
       "0  tell me the expiration date for my current cre...  expiration_date\n",
       "1                 would you disconnect from my phone      sync_device\n",
       "2                  could you please track my package     order_status\n",
       "3                       any travel alerts for canada     travel_alert\n",
       "4  i want to report fraudulent activity on my ame...     report_fraud"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(DATA_FOLDER +'train.csv', encoding='utf-8')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4cc8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hey</td>\n",
       "      <td>greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put laundry on my chore list</td>\n",
       "      <td>todo_list_update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>go into whisper mode</td>\n",
       "      <td>whisper_mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when do i need to change my motor oil again</td>\n",
       "      <td>oil_change_when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the insurance plan i am enrolled in</td>\n",
       "      <td>insurance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text            intent\n",
       "0                                          hey          greeting\n",
       "1                 put laundry on my chore list  todo_list_update\n",
       "2                         go into whisper mode      whisper_mode\n",
       "3  when do i need to change my motor oil again   oil_change_when\n",
       "4  what is the insurance plan i am enrolled in         insurance"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv(DATA_FOLDER +'val.csv', encoding='utf-8')\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493dec98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thanks so much ai</td>\n",
       "      <td>thank_you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i will be traveling to lima alert my bank</td>\n",
       "      <td>travel_notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say again please</td>\n",
       "      <td>repeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is needed to cook lasagna</td>\n",
       "      <td>ingredients_list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>give me the pressure for the tires on my car</td>\n",
       "      <td>tire_pressure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text               intent\n",
       "0                             thanks so much ai            thank_you\n",
       "1     i will be traveling to lima alert my bank  travel_notification\n",
       "2                              say again please               repeat\n",
       "3                what is needed to cook lasagna     ingredients_list\n",
       "4  give me the pressure for the tires on my car        tire_pressure"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(DATA_FOLDER +'test.csv', encoding='utf-8')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf4eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeds = model.encode(df_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b5dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_embeds = model.encode(df_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e047dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = model.encode(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163a26b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def classify_it(classifier):\n",
    "    clf = classifier.fit(train_embeds, df_train['intent'])\n",
    "    print(\"{} Train-Acc:{:.3f} Test-Acc:{:.3f} Validation-Acc:{:.3f}\".format(classifier.__class__.__name__, \n",
    "                          clf.score(train_embeds, df_train['intent']),\n",
    "                          clf.score(test_embeds, df_test['intent']),\n",
    "                          clf.score(valid_embeds, df_val['intent'])\n",
    "                         ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "463246a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Train-Acc:0.979 Test-Acc:0.936 Validation-Acc:0.937\n"
     ]
    }
   ],
   "source": [
    "classify_it(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ac0915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Train-Acc:1.000 Test-Acc:0.875 Validation-Acc:0.879\n"
     ]
    }
   ],
   "source": [
    "classify_it(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4181f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 LogisticRegression Train-Acc:0.913 Test-Acc:0.880 Validation-Acc:0.874\n",
      "0.1 LogisticRegression Train-Acc:0.928 Test-Acc:0.894 Validation-Acc:0.891\n",
      "1 LogisticRegression Train-Acc:0.979 Test-Acc:0.936 Validation-Acc:0.937\n",
      "10 LogisticRegression Train-Acc:0.999 Test-Acc:0.949 Validation-Acc:0.947\n",
      "100 LogisticRegression Train-Acc:1.000 Test-Acc:0.950 Validation-Acc:0.949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tayfu\\anaconda3\\envs\\nlu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    print(c, end=' ')\n",
    "    classify_it(LogisticRegression(C=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfff31b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 LogisticRegression Train-Acc:1.000 Test-Acc:0.950 Validation-Acc:0.950\n"
     ]
    }
   ],
   "source": [
    "for c in [200]:\n",
    "    print(c, end=' ')\n",
    "    classify_it(LogisticRegression(C=c, max_iter=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b764a6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 LogisticRegression Train-Acc:1.000 Test-Acc:0.949 Validation-Acc:0.950\n"
     ]
    }
   ],
   "source": [
    "for c in [1000]:\n",
    "    print(c, end=' ')\n",
    "    classify_it(LogisticRegression(C=c, max_iter=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a3ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
